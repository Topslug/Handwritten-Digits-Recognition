{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24b35752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from test_convnets import TestConvNet1, TestConvNet2, TestConvNet3, TestConvNet4, TestConvNet5\n",
    "from common.trainer import Trainer\n",
    "import pickle\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e62c97fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:1.9538229368862639\n",
      "=== epoch:1, train acc:0.186, test acc:0.166 ===\n",
      "train loss:1.9604157614234092\n",
      "train loss:1.7779411625215464\n",
      "train loss:1.6174898726400133\n",
      "train loss:1.4271209345035203\n",
      "train loss:1.4052383044365824\n",
      "train loss:1.3349234250774111\n",
      "train loss:1.1727055868977676\n",
      "train loss:1.1406616077421474\n",
      "train loss:0.913586021229454\n",
      "train loss:0.9525854898300044\n",
      "train loss:0.9443273909541925\n",
      "train loss:0.8054255834703187\n",
      "train loss:0.596445468538888\n",
      "train loss:0.6765618843390204\n",
      "train loss:0.6729268594526033\n",
      "train loss:0.6344262453983209\n",
      "train loss:0.7624792895647654\n",
      "train loss:0.6230597784544999\n",
      "train loss:0.6696680252735279\n",
      "train loss:0.5967346967824377\n",
      "train loss:0.480203493829838\n",
      "train loss:0.5169787696063406\n",
      "train loss:0.47962592579286983\n",
      "train loss:0.4675841682401035\n",
      "train loss:0.3633828638140175\n",
      "train loss:0.3756758771256203\n",
      "train loss:0.4528944022157125\n",
      "train loss:0.40446900835291677\n",
      "train loss:0.40724079169495814\n",
      "train loss:0.3906558467842347\n",
      "train loss:0.39695657414085594\n",
      "train loss:0.24372925504111728\n",
      "train loss:0.3079123262930293\n",
      "train loss:0.3532519402556072\n",
      "train loss:0.279277356357526\n",
      "train loss:0.328491395662709\n",
      "train loss:0.26160738718288973\n",
      "train loss:0.5319121488527064\n",
      "train loss:0.24678836012812627\n",
      "train loss:0.2826359125258238\n",
      "train loss:0.39619279610523894\n",
      "train loss:0.3419923294780311\n",
      "train loss:0.2645452267632243\n",
      "train loss:0.4425953553522466\n",
      "train loss:0.2857306886907429\n",
      "train loss:0.2622296889086045\n",
      "train loss:0.21237061347340208\n",
      "train loss:0.3835342453175247\n",
      "train loss:0.2893960654288988\n",
      "train loss:0.19040488368982028\n",
      "=== epoch:2, train acc:0.898, test acc:0.869 ===\n",
      "train loss:0.3633634005701454\n",
      "train loss:0.32772837918845577\n",
      "train loss:0.18682860470156937\n",
      "train loss:0.21225817975715203\n",
      "train loss:0.3243159349920494\n",
      "train loss:0.21294437749301484\n",
      "train loss:0.2402940462997336\n",
      "train loss:0.4404255479948918\n",
      "train loss:0.2425797083507467\n",
      "train loss:0.33376936314001876\n",
      "train loss:0.3506441828679367\n",
      "train loss:0.2404291412010563\n",
      "train loss:0.3340979265433177\n",
      "train loss:0.26492901608451824\n",
      "train loss:0.2399425348902611\n",
      "train loss:0.2925371437424944\n",
      "train loss:0.18119727945725114\n",
      "train loss:0.19698546442135156\n",
      "train loss:0.29161484517652747\n",
      "train loss:0.15124300875792082\n",
      "train loss:0.2528699458332314\n",
      "train loss:0.23854781617867635\n",
      "train loss:0.23902479229403015\n",
      "train loss:0.2701283603910859\n",
      "train loss:0.22756303071862163\n",
      "train loss:0.14349202767943411\n",
      "train loss:0.292353650044728\n",
      "train loss:0.2317712949763631\n",
      "train loss:0.1271726054924108\n",
      "train loss:0.15380646550562604\n",
      "train loss:0.27650890823219215\n",
      "train loss:0.17490148005925613\n",
      "train loss:0.24491165989168281\n",
      "train loss:0.17363424014594903\n",
      "train loss:0.20643628863358607\n",
      "train loss:0.17378522112208153\n",
      "train loss:0.10459133381463637\n",
      "train loss:0.1853906082528901\n",
      "train loss:0.33257673963502243\n",
      "train loss:0.1867696503336357\n",
      "train loss:0.20912256191132703\n",
      "train loss:0.13471471075965655\n",
      "train loss:0.2522808496860652\n",
      "train loss:0.24461800173896012\n",
      "train loss:0.2420021895807576\n",
      "train loss:0.21301589889063713\n",
      "train loss:0.17137921138236475\n",
      "train loss:0.20456597410348568\n",
      "train loss:0.18028013010081273\n",
      "train loss:0.195923451551353\n",
      "=== epoch:3, train acc:0.922, test acc:0.899 ===\n",
      "train loss:0.13736462526750579\n",
      "train loss:0.2680608189989701\n",
      "train loss:0.14108987365324915\n",
      "train loss:0.12290282661339759\n",
      "train loss:0.15051878627094567\n",
      "train loss:0.15343124711338518\n",
      "train loss:0.2782379676633377\n",
      "train loss:0.16928378549018208\n",
      "train loss:0.2811130230600083\n",
      "train loss:0.29644983396870145\n",
      "train loss:0.11049770310373837\n",
      "train loss:0.12105182685307052\n",
      "train loss:0.18882814358989633\n",
      "train loss:0.1792895662074687\n",
      "train loss:0.3189194848687297\n",
      "train loss:0.25829331191631943\n",
      "train loss:0.15085529315501237\n",
      "train loss:0.15328138819187923\n",
      "train loss:0.14017246906612887\n",
      "train loss:0.17404374844145962\n",
      "train loss:0.2986894670087281\n",
      "train loss:0.14416394785823583\n",
      "train loss:0.18317228722947476\n",
      "train loss:0.24242417410368383\n",
      "train loss:0.18115804934750732\n",
      "train loss:0.18297596177042869\n",
      "train loss:0.10804963417849286\n",
      "train loss:0.0981864424257692\n",
      "train loss:0.2254639661967358\n",
      "train loss:0.2182280005310238\n",
      "train loss:0.175032048322264\n",
      "train loss:0.2574361992529235\n",
      "train loss:0.14100974309247405\n",
      "train loss:0.11959408600232244\n",
      "train loss:0.12039477440332913\n",
      "train loss:0.13264416577029536\n",
      "train loss:0.11409949428846515\n",
      "train loss:0.09677188873683117\n",
      "train loss:0.10350409697279671\n",
      "train loss:0.14161414351228202\n",
      "train loss:0.13422733534608292\n",
      "train loss:0.12563537486392218\n",
      "train loss:0.19949191911769712\n",
      "train loss:0.25985352301046793\n",
      "train loss:0.19287464891650205\n",
      "train loss:0.21458652077271886\n",
      "train loss:0.16009768221336856\n",
      "train loss:0.11111010253494871\n",
      "train loss:0.1651578834686538\n",
      "train loss:0.11331815127216953\n",
      "=== epoch:4, train acc:0.946, test acc:0.919 ===\n",
      "train loss:0.17308577302211448\n",
      "train loss:0.1913607821855767\n",
      "train loss:0.21784697595199276\n",
      "train loss:0.18051054215237627\n",
      "train loss:0.19529948543382283\n",
      "train loss:0.10123351323916055\n",
      "train loss:0.10661723556782357\n",
      "train loss:0.23027715840057758\n",
      "train loss:0.15172834560138818\n",
      "train loss:0.11670311318541027\n",
      "train loss:0.07998010480707703\n",
      "train loss:0.10662835240694585\n",
      "train loss:0.0664908292530503\n",
      "train loss:0.10955795191724799\n",
      "train loss:0.12108959856757114\n",
      "train loss:0.13980884536066976\n",
      "train loss:0.11105976748960808\n",
      "train loss:0.09685932653932877\n",
      "train loss:0.12135271243176472\n",
      "train loss:0.12840080650057684\n",
      "train loss:0.12395635596379583\n",
      "train loss:0.1709427257015424\n",
      "train loss:0.07112388394217856\n",
      "train loss:0.1706412667271611\n",
      "train loss:0.11767755855060359\n",
      "train loss:0.11830525689447159\n",
      "train loss:0.0784109417152092\n",
      "train loss:0.08479588033746144\n",
      "train loss:0.11823228354041371\n",
      "train loss:0.2598738936488727\n",
      "train loss:0.07514463195682426\n",
      "train loss:0.09074441871532077\n",
      "train loss:0.06283549309265352\n",
      "train loss:0.06843800154024758\n",
      "train loss:0.17138381329708355\n",
      "train loss:0.1729720988425357\n",
      "train loss:0.20289164148847086\n",
      "train loss:0.11318959994189072\n",
      "train loss:0.098018988741276\n",
      "train loss:0.15392078799798967\n",
      "train loss:0.1382885324453646\n",
      "train loss:0.056176410613265164\n",
      "train loss:0.07396827482927171\n",
      "train loss:0.05917039384260781\n",
      "train loss:0.1310467997503143\n",
      "train loss:0.05778952797273619\n",
      "train loss:0.07483792842028537\n",
      "train loss:0.12183185106954468\n",
      "train loss:0.1412713301289597\n",
      "train loss:0.10037179099427355\n",
      "=== epoch:5, train acc:0.963, test acc:0.931 ===\n",
      "train loss:0.1021792347814306\n",
      "train loss:0.11595203330331749\n",
      "train loss:0.10940142861774106\n",
      "train loss:0.12579632282745368\n",
      "train loss:0.10681004443386892\n",
      "train loss:0.14097401176872623\n",
      "train loss:0.06557932006078189\n",
      "train loss:0.08870288387433552\n",
      "train loss:0.07321324751983732\n",
      "train loss:0.1277748496108121\n",
      "train loss:0.12963123025016116\n",
      "train loss:0.0923387023801375\n",
      "train loss:0.062193523702105916\n",
      "train loss:0.1724432558470488\n",
      "train loss:0.1212200256187285\n",
      "train loss:0.19771497486652007\n",
      "train loss:0.11538041934072128\n",
      "train loss:0.14234710019126184\n",
      "train loss:0.052168801772027186\n",
      "train loss:0.13065796480317257\n",
      "train loss:0.058382432022793675\n",
      "train loss:0.15672981052732882\n",
      "train loss:0.15139166130254303\n",
      "train loss:0.1262809484661971\n",
      "train loss:0.07496183299804543\n",
      "train loss:0.08848519064542185\n",
      "train loss:0.06397478266584412\n",
      "train loss:0.07012708494215616\n",
      "train loss:0.05584315893491049\n",
      "train loss:0.0857004144366939\n",
      "train loss:0.03917512254766611\n",
      "train loss:0.17029695721448782\n",
      "train loss:0.09038051369990878\n",
      "train loss:0.09155656313601718\n",
      "train loss:0.07804499276038408\n",
      "train loss:0.137066609619451\n",
      "train loss:0.09286918864015631\n",
      "train loss:0.09280481227455825\n",
      "train loss:0.09970797661067846\n",
      "train loss:0.0671853573052904\n",
      "train loss:0.06453930514269958\n",
      "train loss:0.07648112436333411\n",
      "train loss:0.08566418502270032\n",
      "train loss:0.0953365373746188\n",
      "train loss:0.05613629749142695\n",
      "train loss:0.07295287403719508\n",
      "train loss:0.054229553660385926\n",
      "train loss:0.08295367985864395\n",
      "train loss:0.06565521962830224\n",
      "train loss:0.09835224259825495\n",
      "=== epoch:6, train acc:0.971, test acc:0.929 ===\n",
      "train loss:0.08970323780140406\n",
      "train loss:0.052349528991276914\n",
      "train loss:0.07864502827001316\n",
      "train loss:0.0492511486809273\n",
      "train loss:0.07829450854083138\n",
      "train loss:0.0797607091271945\n",
      "train loss:0.06071952811345788\n",
      "train loss:0.03403619744583632\n",
      "train loss:0.1077457982317336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0771592331700317\n",
      "train loss:0.06769361283189405\n",
      "train loss:0.062411520579121804\n",
      "train loss:0.0747907582744618\n",
      "train loss:0.043406965925912165\n",
      "train loss:0.07980223051467095\n",
      "train loss:0.10429426158586441\n",
      "train loss:0.06395981339291582\n",
      "train loss:0.08097445794749164\n",
      "train loss:0.11553312899014469\n",
      "train loss:0.051430767217476886\n",
      "train loss:0.030835205106445412\n",
      "train loss:0.0428231991882899\n",
      "train loss:0.06663599667237911\n",
      "train loss:0.053870897767799096\n",
      "train loss:0.03767522807903296\n",
      "train loss:0.08367362383268594\n",
      "train loss:0.08522851612004068\n",
      "train loss:0.028378788998238997\n",
      "train loss:0.06687510720135642\n",
      "train loss:0.04214572195359194\n",
      "train loss:0.06541605487656323\n",
      "train loss:0.049070225126876664\n",
      "train loss:0.08280534081593523\n",
      "train loss:0.09215234861037758\n",
      "train loss:0.07032810818560613\n",
      "train loss:0.07287791141134509\n",
      "train loss:0.07631305780734093\n",
      "train loss:0.05109603485147552\n",
      "train loss:0.10276117358064768\n",
      "train loss:0.06504922530647939\n",
      "train loss:0.05939629481960255\n",
      "train loss:0.0725491021974384\n",
      "train loss:0.05744248287474803\n",
      "train loss:0.02607082946134442\n",
      "train loss:0.04298418639329976\n",
      "train loss:0.041398398622547426\n",
      "train loss:0.0924314759446688\n",
      "train loss:0.11755350833294133\n",
      "train loss:0.03389808653087463\n",
      "train loss:0.0547489897537517\n",
      "=== epoch:7, train acc:0.979, test acc:0.937 ===\n",
      "train loss:0.11874081610755137\n",
      "train loss:0.09357108697494632\n",
      "train loss:0.12036703809866417\n",
      "train loss:0.0427018563768396\n",
      "train loss:0.08230463805931781\n",
      "train loss:0.03741676481025452\n",
      "train loss:0.07138657682903253\n",
      "train loss:0.05395185082658382\n",
      "train loss:0.057404545648513355\n",
      "train loss:0.039919168960808535\n",
      "train loss:0.0513995642640192\n",
      "train loss:0.05279033570544114\n",
      "train loss:0.061329505438338525\n",
      "train loss:0.08217123321804799\n",
      "train loss:0.05188812786986774\n",
      "train loss:0.1374874449546818\n",
      "train loss:0.09587068803438052\n",
      "train loss:0.057585769091926045\n",
      "train loss:0.11116353925586717\n",
      "train loss:0.058642480058484485\n",
      "train loss:0.031134837504531835\n",
      "train loss:0.04394429636074209\n",
      "train loss:0.027721523154296546\n",
      "train loss:0.049941899428540736\n",
      "train loss:0.05087173566928017\n",
      "train loss:0.05833209521386915\n",
      "train loss:0.1032030195600175\n",
      "train loss:0.11134250779996645\n",
      "train loss:0.07454535794906829\n",
      "train loss:0.020986130913253215\n",
      "train loss:0.061203773029854115\n",
      "train loss:0.05693228590793163\n",
      "train loss:0.04490332945971104\n",
      "train loss:0.03832244518752124\n",
      "train loss:0.027750772970957103\n",
      "train loss:0.0725370490546807\n",
      "train loss:0.04714583613555414\n",
      "train loss:0.04119183200546801\n",
      "train loss:0.050610731890767965\n",
      "train loss:0.09506622357798122\n",
      "train loss:0.033409905975672304\n",
      "train loss:0.044105268630574734\n",
      "train loss:0.07019022324110451\n",
      "train loss:0.01804255394719823\n",
      "train loss:0.08133219439979475\n",
      "train loss:0.04534665998103424\n",
      "train loss:0.044816855465631106\n",
      "train loss:0.05869546924050466\n",
      "train loss:0.03180165451842412\n",
      "train loss:0.049681043742513704\n",
      "=== epoch:8, train acc:0.986, test acc:0.937 ===\n",
      "train loss:0.0262569829301702\n",
      "train loss:0.08032948646461445\n",
      "train loss:0.052725767868181596\n",
      "train loss:0.04200831106931752\n",
      "train loss:0.033919111714006134\n",
      "train loss:0.06168370420280382\n",
      "train loss:0.03866260486145885\n",
      "train loss:0.04115096130142734\n",
      "train loss:0.04244517160681572\n",
      "train loss:0.041799094990384776\n",
      "train loss:0.09430093232393887\n",
      "train loss:0.07063877296423443\n",
      "train loss:0.031134537034731277\n",
      "train loss:0.04538313886787584\n",
      "train loss:0.051178174337703386\n",
      "train loss:0.07660587082393742\n",
      "train loss:0.10362555423719395\n",
      "train loss:0.0526126985668506\n",
      "train loss:0.06222153995096346\n",
      "train loss:0.03596310381879042\n",
      "train loss:0.07063351322416084\n",
      "train loss:0.06829507586838071\n",
      "train loss:0.024749026295989976\n",
      "train loss:0.01944391687053556\n",
      "train loss:0.11454635575485309\n",
      "train loss:0.046431089996105825\n",
      "train loss:0.019006803139074477\n",
      "train loss:0.03423238594075126\n",
      "train loss:0.040342634959777815\n",
      "train loss:0.06053746331650418\n",
      "train loss:0.05010208461756334\n",
      "train loss:0.05632365254292895\n",
      "train loss:0.021664409599963824\n",
      "train loss:0.03759493021634569\n",
      "train loss:0.04966679444099251\n",
      "train loss:0.024213488222074083\n",
      "train loss:0.0567213497790702\n",
      "train loss:0.08474575412514015\n",
      "train loss:0.03738224419506004\n",
      "train loss:0.03529673366290317\n",
      "train loss:0.06309410039429608\n",
      "train loss:0.014541276319799535\n",
      "train loss:0.023827633477402636\n",
      "train loss:0.03769047214534567\n",
      "train loss:0.04774676109483191\n",
      "train loss:0.013040536804702983\n",
      "train loss:0.031450207555338276\n",
      "train loss:0.06809590100014165\n",
      "train loss:0.03840569044603552\n",
      "train loss:0.03784879458758787\n",
      "=== epoch:9, train acc:0.988, test acc:0.945 ===\n",
      "train loss:0.032168143205088755\n",
      "train loss:0.03248845652667053\n",
      "train loss:0.04384506828331572\n",
      "train loss:0.021285988452287904\n",
      "train loss:0.02422965809077147\n",
      "train loss:0.053031603316906296\n",
      "train loss:0.029646167596676397\n",
      "train loss:0.04021440187108878\n",
      "train loss:0.05217715937925977\n",
      "train loss:0.044091662136437615\n",
      "train loss:0.03061198769911101\n",
      "train loss:0.058773323162441965\n",
      "train loss:0.031131879668881344\n",
      "train loss:0.06404129974097417\n",
      "train loss:0.040165765841287\n",
      "train loss:0.08232465343036173\n",
      "train loss:0.03201469036203553\n",
      "train loss:0.037598131965704246\n",
      "train loss:0.03852229405056239\n",
      "train loss:0.03222193339034854\n",
      "train loss:0.029442114892959864\n",
      "train loss:0.024592956273125747\n",
      "train loss:0.018273337293157037\n",
      "train loss:0.0268792180114064\n",
      "train loss:0.038833380576089066\n",
      "train loss:0.04842541018099493\n",
      "train loss:0.06984929825064805\n",
      "train loss:0.0685311475761321\n",
      "train loss:0.023171855219260955\n",
      "train loss:0.01666408183533404\n",
      "train loss:0.024539305066230987\n",
      "train loss:0.047630176078183546\n",
      "train loss:0.0269252464543379\n",
      "train loss:0.04484146781091861\n",
      "train loss:0.024421585267743007\n",
      "train loss:0.06004005462608128\n",
      "train loss:0.012831918264739799\n",
      "train loss:0.022771691339949413\n",
      "train loss:0.03263905998033373\n",
      "train loss:0.03820848631292222\n",
      "train loss:0.036697072282191066\n",
      "train loss:0.020779219045826577\n",
      "train loss:0.032552389323200634\n",
      "train loss:0.021725823719609773\n",
      "train loss:0.045300492161850545\n",
      "train loss:0.02328683381045404\n",
      "train loss:0.06499057851503891\n",
      "train loss:0.018059885753571692\n",
      "train loss:0.03203807825497838\n",
      "train loss:0.028992377462479787\n",
      "=== epoch:10, train acc:0.99, test acc:0.95 ===\n",
      "train loss:0.06277628484080255\n",
      "train loss:0.0489677239233842\n",
      "train loss:0.02138093388969277\n",
      "train loss:0.04141778535644671\n",
      "train loss:0.03398151000620287\n",
      "train loss:0.02441876218281907\n",
      "train loss:0.036451930354631734\n",
      "train loss:0.03587987554999278\n",
      "train loss:0.045932869668095205\n",
      "train loss:0.04506626761921903\n",
      "train loss:0.022843555079076174\n",
      "train loss:0.0711440356525174\n",
      "train loss:0.03058418008472635\n",
      "train loss:0.02563313707566499\n",
      "train loss:0.026540850514292683\n",
      "train loss:0.014457625572453644\n",
      "train loss:0.022258583029569613\n",
      "train loss:0.03567855818331187\n",
      "train loss:0.02729456585714812\n",
      "train loss:0.01870656567903382\n",
      "train loss:0.02864615418512286\n",
      "train loss:0.02400819378598174\n",
      "train loss:0.010076188397341283\n",
      "train loss:0.014855826052837919\n",
      "train loss:0.042426410504921644\n",
      "train loss:0.03810508841026954\n",
      "train loss:0.016413274170938272\n",
      "train loss:0.03402604139448665\n",
      "train loss:0.012073575663669713\n",
      "train loss:0.03869861899882912\n",
      "train loss:0.01985820014857357\n",
      "train loss:0.010758472702114514\n",
      "train loss:0.03952055511230159\n",
      "train loss:0.02566639473267622\n",
      "train loss:0.022545100350307195\n",
      "train loss:0.03672409126682695\n",
      "train loss:0.03419261203660723\n",
      "train loss:0.021009815625807015\n",
      "train loss:0.02179279816078096\n",
      "train loss:0.05468564215058287\n",
      "train loss:0.019609458474288695\n",
      "train loss:0.033427056481206356\n",
      "train loss:0.019348025531605917\n",
      "train loss:0.026826385565486728\n",
      "train loss:0.02287946796118537\n",
      "train loss:0.01887940374842954\n",
      "train loss:0.05499518551140905\n",
      "train loss:0.014160252943744707\n",
      "train loss:0.01743622996456315\n",
      "train loss:0.019987441386194585\n",
      "=== epoch:11, train acc:0.993, test acc:0.947 ===\n",
      "train loss:0.03378285175893611\n",
      "train loss:0.017084259810425335\n",
      "train loss:0.027424579773381478\n",
      "train loss:0.017003808995928935\n",
      "train loss:0.023911725512065704\n",
      "train loss:0.03519551955936186\n",
      "train loss:0.01826733741406785\n",
      "train loss:0.02230899477388435\n",
      "train loss:0.019358323447644408\n",
      "train loss:0.025694603778931784\n",
      "train loss:0.016621690058365994\n",
      "train loss:0.0365239638049452\n",
      "train loss:0.014649342954925823\n",
      "train loss:0.04590272074283447\n",
      "train loss:0.045840777319513616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.021208590500104485\n",
      "train loss:0.017088352077577196\n",
      "train loss:0.0133840450720665\n",
      "train loss:0.027266791530223263\n",
      "train loss:0.017712426421968533\n",
      "train loss:0.008636349347248138\n",
      "train loss:0.018015433569919668\n",
      "train loss:0.014831039401121357\n",
      "train loss:0.019881541632322232\n",
      "train loss:0.04196083604160703\n",
      "train loss:0.02170005489122706\n",
      "train loss:0.02744391462775049\n",
      "train loss:0.026204771838185374\n",
      "train loss:0.014785403215060255\n",
      "train loss:0.02030744249978454\n",
      "train loss:0.02092960333800366\n",
      "train loss:0.010608052251527118\n",
      "train loss:0.01524227245117689\n",
      "train loss:0.009441304416163032\n",
      "train loss:0.024691367752097345\n",
      "train loss:0.024218444700346023\n",
      "train loss:0.015130009833642816\n",
      "train loss:0.02499948524867075\n",
      "train loss:0.011138872584387198\n",
      "train loss:0.01282498901519749\n",
      "train loss:0.02754620991183915\n",
      "train loss:0.017965676603190314\n",
      "train loss:0.045232306145181464\n",
      "train loss:0.011590825789007586\n",
      "train loss:0.011584219740611912\n",
      "train loss:0.013262691656986049\n",
      "train loss:0.008309042936397268\n",
      "train loss:0.023202783387848827\n",
      "train loss:0.016392082223443974\n",
      "train loss:0.022082661425442126\n",
      "=== epoch:12, train acc:0.996, test acc:0.954 ===\n",
      "train loss:0.04340377715688129\n",
      "train loss:0.012605943874990668\n",
      "train loss:0.013515701679747506\n",
      "train loss:0.006530023979814917\n",
      "train loss:0.011457842080643712\n",
      "train loss:0.024966773073563497\n",
      "train loss:0.010352567099869793\n",
      "train loss:0.01636355981422483\n",
      "train loss:0.013653264034458488\n",
      "train loss:0.021675820949031685\n",
      "train loss:0.025741483826546032\n",
      "train loss:0.011808737058792498\n",
      "train loss:0.010613725647431682\n",
      "train loss:0.025534099396850574\n",
      "train loss:0.011516607253927068\n",
      "train loss:0.028404821714525713\n",
      "train loss:0.02882235945874541\n",
      "train loss:0.008306876074663653\n",
      "train loss:0.022806706237588684\n",
      "train loss:0.015073225178218148\n",
      "train loss:0.008319160117287927\n",
      "train loss:0.03368448081040147\n",
      "train loss:0.02827834705842981\n",
      "train loss:0.016648197785932448\n",
      "train loss:0.015459742333078553\n",
      "train loss:0.012606206096785661\n",
      "train loss:0.015340005674194373\n",
      "train loss:0.009960915472398168\n",
      "train loss:0.009495933573507788\n",
      "train loss:0.015410463249903163\n",
      "train loss:0.015634480788430886\n",
      "train loss:0.009397344214245665\n",
      "train loss:0.011688257197467517\n",
      "train loss:0.011213892818369686\n",
      "train loss:0.015446024999889443\n",
      "train loss:0.0108238065838105\n",
      "train loss:0.01342078743297952\n",
      "train loss:0.012665414235721125\n",
      "train loss:0.007585231073207153\n",
      "train loss:0.01826502843341994\n",
      "train loss:0.01904532362413577\n",
      "train loss:0.007072841757584523\n",
      "train loss:0.011777853214657255\n",
      "train loss:0.02101986731338851\n",
      "train loss:0.010457421891086338\n",
      "train loss:0.013596373937138034\n",
      "train loss:0.010458330675651337\n",
      "train loss:0.013331528569973883\n",
      "train loss:0.017358292494213577\n",
      "train loss:0.019723548484499503\n",
      "=== epoch:13, train acc:0.994, test acc:0.948 ===\n",
      "train loss:0.020829472864483795\n",
      "train loss:0.012892477012894485\n",
      "train loss:0.012298898199048896\n",
      "train loss:0.010050694777421426\n",
      "train loss:0.014667565949028018\n",
      "train loss:0.007597069242824348\n",
      "train loss:0.011345164331587903\n",
      "train loss:0.016715600852970088\n",
      "train loss:0.013888368037294983\n",
      "train loss:0.014411948676246369\n",
      "train loss:0.01677853120513845\n",
      "train loss:0.016244199390749198\n",
      "train loss:0.01594137469257264\n",
      "train loss:0.007570156447708263\n",
      "train loss:0.016698685969229406\n",
      "train loss:0.025129065517225574\n",
      "train loss:0.01375307335036648\n",
      "train loss:0.01340839495171889\n",
      "train loss:0.014071585118820094\n",
      "train loss:0.018662390009025396\n",
      "train loss:0.006443269630378101\n",
      "train loss:0.011289964359343088\n",
      "train loss:0.012195865895829338\n",
      "train loss:0.013868447985042647\n",
      "train loss:0.008597329251227734\n",
      "train loss:0.013236659417375642\n",
      "train loss:0.04227538165998469\n",
      "train loss:0.007304025497863156\n",
      "train loss:0.012237993487894911\n",
      "train loss:0.00850989926905926\n",
      "train loss:0.0068884341563882475\n",
      "train loss:0.008331394549343254\n",
      "train loss:0.004811185928612293\n",
      "train loss:0.03233629229652858\n",
      "train loss:0.013598528884248555\n",
      "train loss:0.01584840974938043\n",
      "train loss:0.037937114301517826\n",
      "train loss:0.010587886036083616\n",
      "train loss:0.00878431444073746\n",
      "train loss:0.010274209982059846\n",
      "train loss:0.014112161923207179\n",
      "train loss:0.025636572734451756\n",
      "train loss:0.010230819983384256\n",
      "train loss:0.017295039430166845\n",
      "train loss:0.015499911283990671\n",
      "train loss:0.02132350130367884\n",
      "train loss:0.008749603404858957\n",
      "train loss:0.007024422628876513\n",
      "train loss:0.012579633297876435\n",
      "train loss:0.009980234447564665\n",
      "=== epoch:14, train acc:0.996, test acc:0.946 ===\n",
      "train loss:0.019257223931866504\n",
      "train loss:0.008780300235542896\n",
      "train loss:0.009996120899986517\n",
      "train loss:0.01669647817504709\n",
      "train loss:0.03013258162437415\n",
      "train loss:0.014358234143301086\n",
      "train loss:0.015412041204377884\n",
      "train loss:0.017856568071433404\n",
      "train loss:0.00622804197555759\n",
      "train loss:0.01185913807655935\n",
      "train loss:0.011738778807591624\n",
      "train loss:0.018660810480784044\n",
      "train loss:0.010693490169441265\n",
      "train loss:0.010252881973139305\n",
      "train loss:0.009156792854027505\n",
      "train loss:0.025966675854938233\n",
      "train loss:0.011036666839444036\n",
      "train loss:0.03891949072025229\n",
      "train loss:0.017171409832107104\n",
      "train loss:0.0244545544930708\n",
      "train loss:0.007833141747235022\n",
      "train loss:0.012676636147139377\n",
      "train loss:0.010919137883078009\n",
      "train loss:0.020743235037148734\n",
      "train loss:0.01108799907647146\n",
      "train loss:0.01781716517579773\n",
      "train loss:0.023563784660687776\n",
      "train loss:0.004753750023887663\n",
      "train loss:0.0087825053286811\n",
      "train loss:0.009843198854930207\n",
      "train loss:0.010032885903703707\n",
      "train loss:0.027219598222309852\n",
      "train loss:0.008485470195448519\n",
      "train loss:0.018833990055170977\n",
      "train loss:0.008874346523383451\n",
      "train loss:0.010414217858128096\n",
      "train loss:0.006528842938333855\n",
      "train loss:0.007645054799790172\n",
      "train loss:0.008595922855604348\n",
      "train loss:0.016730922231222526\n",
      "train loss:0.011548782528359357\n",
      "train loss:0.013842614701411723\n",
      "train loss:0.00622366839576033\n",
      "train loss:0.01893451875010742\n",
      "train loss:0.01779983986596421\n",
      "train loss:0.012482189753707946\n",
      "train loss:0.011258283109450882\n",
      "train loss:0.006896929991373884\n",
      "train loss:0.016741793925390526\n",
      "train loss:0.00848682077229705\n",
      "=== epoch:15, train acc:0.998, test acc:0.95 ===\n",
      "train loss:0.008884158967362478\n",
      "train loss:0.006588524314880416\n",
      "train loss:0.010307929795906412\n",
      "train loss:0.023809226970441494\n",
      "train loss:0.01195524978781675\n",
      "train loss:0.013133783683970652\n",
      "train loss:0.010990081314224251\n",
      "train loss:0.015350249912362406\n",
      "train loss:0.012408911728570216\n",
      "train loss:0.010469496772873257\n",
      "train loss:0.00392431708159214\n",
      "train loss:0.007945366832932952\n",
      "train loss:0.01238773150813973\n",
      "train loss:0.01957442179190617\n",
      "train loss:0.007822934739326963\n",
      "train loss:0.0068056667696331785\n",
      "train loss:0.007808251302917714\n",
      "train loss:0.00859216645636508\n",
      "train loss:0.007712024852758874\n",
      "train loss:0.010173780138466943\n",
      "train loss:0.01043553718447873\n",
      "train loss:0.007196369048463956\n",
      "train loss:0.007790628437754263\n",
      "train loss:0.0069294585124650655\n",
      "train loss:0.009061168944174637\n",
      "train loss:0.012104347038970915\n",
      "train loss:0.011517481990492266\n",
      "train loss:0.009806843923504768\n",
      "train loss:0.016516633033435636\n",
      "train loss:0.007201025942635406\n",
      "train loss:0.015253879635193817\n",
      "train loss:0.010599576454499954\n",
      "train loss:0.010122081059923415\n",
      "train loss:0.0077389796243893276\n",
      "train loss:0.004803900980120161\n",
      "train loss:0.006013070967625033\n",
      "train loss:0.013352387456540422\n",
      "train loss:0.005623470418394037\n",
      "train loss:0.005768392198807514\n",
      "train loss:0.015410986804989767\n",
      "train loss:0.006231538530734694\n",
      "train loss:0.006954156380652623\n",
      "train loss:0.009680942009693196\n",
      "train loss:0.01627579673971457\n",
      "train loss:0.01077324172662045\n",
      "train loss:0.006959927212741509\n",
      "train loss:0.009608735393904649\n",
      "train loss:0.010191369491728062\n",
      "train loss:0.006744182651612251\n",
      "train loss:0.004576319613685722\n",
      "=== epoch:16, train acc:1.0, test acc:0.947 ===\n",
      "train loss:0.006700955544293238\n",
      "train loss:0.00668149038189427\n",
      "train loss:0.01234459785681054\n",
      "train loss:0.009867418342176432\n",
      "train loss:0.008275468710380646\n",
      "train loss:0.020270480798884372\n",
      "train loss:0.0108037180851993\n",
      "train loss:0.008810141181184155\n",
      "train loss:0.005334543091960423\n",
      "train loss:0.013764721806410564\n",
      "train loss:0.01135552720870388\n",
      "train loss:0.0066854567019080414\n",
      "train loss:0.005525341181843001\n",
      "train loss:0.006695942323365511\n",
      "train loss:0.007668250156523487\n",
      "train loss:0.007548955817557116\n",
      "train loss:0.008469355665029625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.011327623310244506\n",
      "train loss:0.006978548481351826\n",
      "train loss:0.0048723552764228534\n",
      "train loss:0.007769137854979363\n",
      "train loss:0.008566818301569242\n",
      "train loss:0.008220058675785106\n",
      "train loss:0.00654897237415354\n",
      "train loss:0.007368771498339066\n",
      "train loss:0.013104019894784784\n",
      "train loss:0.021870598956856727\n",
      "train loss:0.008974685039259616\n",
      "train loss:0.010494631706809709\n",
      "train loss:0.00789437594668021\n",
      "train loss:0.010202133227530812\n",
      "train loss:0.00813053992620739\n",
      "train loss:0.003683781823258089\n",
      "train loss:0.005281367699365765\n",
      "train loss:0.009278986887235115\n",
      "train loss:0.0052596032661836965\n",
      "train loss:0.009579637788033618\n",
      "train loss:0.010799620219479248\n",
      "train loss:0.0053666230647979474\n",
      "train loss:0.004613629746454882\n",
      "train loss:0.003506593130950842\n",
      "train loss:0.004961046864960638\n",
      "train loss:0.00606502277109657\n",
      "train loss:0.006280959254148107\n",
      "train loss:0.00902202521510001\n",
      "train loss:0.005879224796109866\n",
      "train loss:0.012595040968325007\n",
      "train loss:0.005667496332506781\n",
      "train loss:0.010093349432740893\n",
      "train loss:0.005439390085240882\n",
      "=== epoch:17, train acc:0.999, test acc:0.948 ===\n",
      "train loss:0.003988232036600795\n",
      "train loss:0.0032507204653316733\n",
      "train loss:0.004330592167477221\n",
      "train loss:0.005366743989931445\n",
      "train loss:0.005588247764188008\n",
      "train loss:0.00390874161269522\n",
      "train loss:0.007352979334056114\n",
      "train loss:0.012432499736869768\n",
      "train loss:0.007074315748836974\n",
      "train loss:0.008852766192799202\n",
      "train loss:0.0023077868325775703\n",
      "train loss:0.013134117462924599\n",
      "train loss:0.006617854397299682\n",
      "train loss:0.004744111273278385\n",
      "train loss:0.003598154720553073\n",
      "train loss:0.005627689212141443\n",
      "train loss:0.0050466900043541285\n",
      "train loss:0.0016099807969368301\n",
      "train loss:0.006884162791182003\n",
      "train loss:0.0057978391280525485\n",
      "train loss:0.00893076241579667\n",
      "train loss:0.006493513574711074\n",
      "train loss:0.004479789631694743\n",
      "train loss:0.0032888184287184086\n",
      "train loss:0.013755093859472232\n",
      "train loss:0.013854787120533882\n",
      "train loss:0.020296708327223908\n",
      "train loss:0.01583201150844891\n",
      "train loss:0.002492718268346615\n",
      "train loss:0.011594426745267433\n",
      "train loss:0.008371664228670878\n",
      "train loss:0.008293949701128974\n",
      "train loss:0.004475029309977182\n",
      "train loss:0.010768120994580294\n",
      "train loss:0.0115915127903245\n",
      "train loss:0.009114700544080728\n",
      "train loss:0.0055019177975855526\n",
      "train loss:0.008437753760806768\n",
      "train loss:0.02683818894880638\n",
      "train loss:0.0087494645386589\n",
      "train loss:0.011246925063282731\n",
      "train loss:0.005152410269012732\n",
      "train loss:0.004344673934917032\n",
      "train loss:0.008668875271870408\n",
      "train loss:0.006300054595248026\n",
      "train loss:0.011771126650059503\n",
      "train loss:0.005431904213908195\n",
      "train loss:0.005381145643723977\n",
      "train loss:0.007056621295725322\n",
      "train loss:0.005021200659821491\n",
      "=== epoch:18, train acc:1.0, test acc:0.956 ===\n",
      "train loss:0.005923707551477468\n",
      "train loss:0.006418724562992528\n",
      "train loss:0.01020409802526362\n",
      "train loss:0.00670171178934179\n",
      "train loss:0.006833972524484522\n",
      "train loss:0.008835339864752557\n",
      "train loss:0.007205606461165055\n",
      "train loss:0.0037300892812450887\n",
      "train loss:0.007909169916174453\n",
      "train loss:0.008342371719729702\n",
      "train loss:0.009383277408552304\n",
      "train loss:0.008687048407070795\n",
      "train loss:0.010394187471253742\n",
      "train loss:0.010442729951510637\n",
      "train loss:0.012812764834315003\n",
      "train loss:0.0032769536188395495\n",
      "train loss:0.004900006993646716\n",
      "train loss:0.0040893105907363675\n",
      "train loss:0.010866302183489693\n",
      "train loss:0.011157925764191978\n",
      "train loss:0.005434405669773529\n",
      "train loss:0.005138579719607914\n",
      "train loss:0.007991947079530947\n",
      "train loss:0.009806286980402135\n",
      "train loss:0.003063751481781318\n",
      "train loss:0.007520989084618374\n",
      "train loss:0.009830870589976271\n",
      "train loss:0.0031993762050881044\n",
      "train loss:0.006309219298201725\n",
      "train loss:0.004524099224804751\n",
      "train loss:0.0038085124497037577\n",
      "train loss:0.002713351387475705\n",
      "train loss:0.007326063608382411\n",
      "train loss:0.006901277121445099\n",
      "train loss:0.0028335398339935686\n",
      "train loss:0.0025850935828837423\n",
      "train loss:0.009899926059341133\n",
      "train loss:0.0032209888989886814\n",
      "train loss:0.004050819597511393\n",
      "train loss:0.0037023651387128515\n",
      "train loss:0.003134317922111432\n",
      "train loss:0.003687339316410977\n",
      "train loss:0.01066117078178129\n",
      "train loss:0.012743038645464473\n",
      "train loss:0.005464620591137395\n",
      "train loss:0.005585676360806467\n",
      "train loss:0.005003743036785616\n",
      "train loss:0.008504048783379485\n",
      "train loss:0.005440003949588515\n",
      "train loss:0.003035360666878458\n",
      "=== epoch:19, train acc:0.999, test acc:0.952 ===\n",
      "train loss:0.0034719270913455085\n",
      "train loss:0.005923339729826529\n",
      "train loss:0.003499748217880266\n",
      "train loss:0.003527794048340347\n",
      "train loss:0.004666643906389104\n",
      "train loss:0.0021811577614402676\n",
      "train loss:0.003014559042117062\n",
      "train loss:0.0034763299459591368\n",
      "train loss:0.0054127171018262385\n",
      "train loss:0.0038975828461549596\n",
      "train loss:0.0048638991397328395\n",
      "train loss:0.008439695925133443\n",
      "train loss:0.00392911424590037\n",
      "train loss:0.0032886422119884767\n",
      "train loss:0.006839740887679659\n",
      "train loss:0.006293992770130718\n",
      "train loss:0.004192513740899795\n",
      "train loss:0.004372251311423457\n",
      "train loss:0.005548634282291598\n",
      "train loss:0.005578781540601112\n",
      "train loss:0.00617969566378812\n",
      "train loss:0.0068823505877842975\n",
      "train loss:0.00913908468131762\n",
      "train loss:0.008705918811605344\n",
      "train loss:0.006241584650951584\n",
      "train loss:0.002482408343417032\n",
      "train loss:0.00577321054200384\n",
      "train loss:0.011381026189485482\n",
      "train loss:0.0058174991859606786\n",
      "train loss:0.008304522695376184\n",
      "train loss:0.004777621291642917\n",
      "train loss:0.007221940431069041\n",
      "train loss:0.004823954712871112\n",
      "train loss:0.009323573050257853\n",
      "train loss:0.006573663615077853\n",
      "train loss:0.002986294206153075\n",
      "train loss:0.002844364458879709\n",
      "train loss:0.01031987438788359\n",
      "train loss:0.005638850558793512\n",
      "train loss:0.003046526489025873\n",
      "train loss:0.005960051150889175\n",
      "train loss:0.010074865202065979\n",
      "train loss:0.008851239505881216\n",
      "train loss:0.004127788648444738\n",
      "train loss:0.008888048218323615\n",
      "train loss:0.003092475431008246\n",
      "train loss:0.011670463179279018\n",
      "train loss:0.007177142676207796\n",
      "train loss:0.003720533095481928\n",
      "train loss:0.006330193841684344\n",
      "=== epoch:20, train acc:1.0, test acc:0.951 ===\n",
      "train loss:0.0051286578409443975\n",
      "train loss:0.005436017303051458\n",
      "train loss:0.005128881986205262\n",
      "train loss:0.002344034792501534\n",
      "train loss:0.003801773845830755\n",
      "train loss:0.005255002474913069\n",
      "train loss:0.005963728753790702\n",
      "train loss:0.0100944750436294\n",
      "train loss:0.0048030749362211935\n",
      "train loss:0.003430935635931193\n",
      "train loss:0.0051625279074738505\n",
      "train loss:0.0019589822761678422\n",
      "train loss:0.004849894712079824\n",
      "train loss:0.004876281822919334\n",
      "train loss:0.007523694521017092\n",
      "train loss:0.0032772691843288666\n",
      "train loss:0.0031154702587721985\n",
      "train loss:0.0041474647675861535\n",
      "train loss:0.0033887750892005897\n",
      "train loss:0.005074745450001028\n",
      "train loss:0.003421533574878885\n",
      "train loss:0.00559787513375429\n",
      "train loss:0.0033631051443293557\n",
      "train loss:0.007521719364857988\n",
      "train loss:0.0034608946155933974\n",
      "train loss:0.0028797279651368974\n",
      "train loss:0.0027856240423233085\n",
      "train loss:0.0034412658944627996\n",
      "train loss:0.007840038941503034\n",
      "train loss:0.0021849645561141232\n",
      "train loss:0.007773980279289415\n",
      "train loss:0.004479909958990616\n",
      "train loss:0.0050686188005607735\n",
      "train loss:0.0037709642333653526\n",
      "train loss:0.005332700512570077\n",
      "train loss:0.004178202951704641\n",
      "train loss:0.0021492450170152015\n",
      "train loss:0.008016309075420634\n",
      "train loss:0.002476423522745066\n",
      "train loss:0.00578689972928663\n",
      "train loss:0.0028644438771399635\n",
      "train loss:0.002209309417331457\n",
      "train loss:0.006158087527817672\n",
      "train loss:0.004050768806751191\n",
      "train loss:0.0029807600508809334\n",
      "train loss:0.0031950716572607726\n",
      "train loss:0.0032859753553813936\n",
      "train loss:0.0048013598537549485\n",
      "train loss:0.004266410869454419\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.948\n"
     ]
    }
   ],
   "source": [
    "network1 = TestConvNet1()\n",
    "trainer1 = Trainer(network1, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr':0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "\n",
    "trainer1.train()\n",
    "network1.save_params(\"params/test_convnet1_params.pkl\")\n",
    "\n",
    "with open(\"trainer1.pkl\", 'wb') as f:\n",
    "    pickle.dump(trainer1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0b718fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.0906658084992378\n",
      "=== epoch:1, train acc:0.199, test acc:0.137 ===\n",
      "train loss:1.9470901468503956\n",
      "train loss:1.8456635419000547\n",
      "train loss:1.6495271959293536\n",
      "train loss:1.5798935484482886\n",
      "train loss:1.349162025556265\n",
      "train loss:1.3125646156493709\n",
      "train loss:1.1762916346273284\n",
      "train loss:1.121615039824068\n",
      "train loss:1.0203378510743601\n",
      "train loss:0.9188905444821519\n",
      "train loss:0.7585134798212438\n",
      "train loss:0.6984481716080336\n",
      "train loss:0.7478363176467796\n",
      "train loss:0.6147523389385358\n",
      "train loss:0.7481301600636864\n",
      "train loss:0.591224832234301\n",
      "train loss:0.4533013094110018\n",
      "train loss:0.5495977410650174\n",
      "train loss:0.4899192161291317\n",
      "train loss:0.581068730133358\n",
      "train loss:0.36862363193248127\n",
      "train loss:0.35904421723973867\n",
      "train loss:0.3399170674530334\n",
      "train loss:0.34540742175137906\n",
      "train loss:0.30537497830664\n",
      "train loss:0.4113454710712523\n",
      "train loss:0.28675456659220133\n",
      "train loss:0.23657160497478763\n",
      "train loss:0.2326795306539969\n",
      "train loss:0.35665223010548325\n",
      "train loss:0.4655649398032031\n",
      "train loss:0.43507853772757005\n",
      "train loss:0.4579327865120267\n",
      "train loss:0.4369888713918773\n",
      "train loss:0.2263736185464759\n",
      "train loss:0.3291115337155916\n",
      "train loss:0.3801195298924203\n",
      "train loss:0.3099721322197957\n",
      "train loss:0.1861495055012988\n",
      "train loss:0.5160273844996277\n",
      "train loss:0.28408934472838004\n",
      "train loss:0.15203760503375896\n",
      "train loss:0.2565380200311458\n",
      "train loss:0.35981631030414746\n",
      "train loss:0.3332693314898434\n",
      "train loss:0.34366888289768815\n",
      "train loss:0.20393550971019947\n",
      "train loss:0.26118186775421387\n",
      "train loss:0.49889323968922644\n",
      "train loss:0.2898668932087315\n",
      "=== epoch:2, train acc:0.912, test acc:0.87 ===\n",
      "train loss:0.44763990437067386\n",
      "train loss:0.25484848999346765\n",
      "train loss:0.24254128068416328\n",
      "train loss:0.2185892848870565\n",
      "train loss:0.2250260002373346\n",
      "train loss:0.23830674941846708\n",
      "train loss:0.23895290121824314\n",
      "train loss:0.23856736941901102\n",
      "train loss:0.22723379580326244\n",
      "train loss:0.29452985607814136\n",
      "train loss:0.2528339954614601\n",
      "train loss:0.24009607866590774\n",
      "train loss:0.16210049226503603\n",
      "train loss:0.15458759526040067\n",
      "train loss:0.21808400474849587\n",
      "train loss:0.2971553913704895\n",
      "train loss:0.30476431151975814\n",
      "train loss:0.3110149869867116\n",
      "train loss:0.16066481037476596\n",
      "train loss:0.18536999287134612\n",
      "train loss:0.18868644777861818\n",
      "train loss:0.2626651811163417\n",
      "train loss:0.19696598797059028\n",
      "train loss:0.1625959236507182\n",
      "train loss:0.12717109972658\n",
      "train loss:0.2716982400178051\n",
      "train loss:0.2188711101007777\n",
      "train loss:0.0838242641504006\n",
      "train loss:0.14191328506204448\n",
      "train loss:0.24916811361665472\n",
      "train loss:0.2660337396986779\n",
      "train loss:0.2176188229262346\n",
      "train loss:0.13788870427128314\n",
      "train loss:0.23839866379272423\n",
      "train loss:0.23646980081065824\n",
      "train loss:0.17892618545453473\n",
      "train loss:0.09173537152550476\n",
      "train loss:0.16167390473086996\n",
      "train loss:0.175249227908244\n",
      "train loss:0.16038940726684764\n",
      "train loss:0.11442049758572873\n",
      "train loss:0.14967571157768741\n",
      "train loss:0.09800416796848749\n",
      "train loss:0.11526010037158052\n",
      "train loss:0.15799097435166826\n",
      "train loss:0.14804720051008657\n",
      "train loss:0.2918816142070551\n",
      "train loss:0.17575360137299653\n",
      "train loss:0.19630176975846056\n",
      "train loss:0.07781924557486729\n",
      "=== epoch:3, train acc:0.933, test acc:0.908 ===\n",
      "train loss:0.1393146002982893\n",
      "train loss:0.16949449025894595\n",
      "train loss:0.16857926737078707\n",
      "train loss:0.12483385198232956\n",
      "train loss:0.1774112078904921\n",
      "train loss:0.09594775893209136\n",
      "train loss:0.16887761638625343\n",
      "train loss:0.1636429939780163\n",
      "train loss:0.1361943476233296\n",
      "train loss:0.13042608954306648\n",
      "train loss:0.1432283585463043\n",
      "train loss:0.1388704547333993\n",
      "train loss:0.19318330911535614\n",
      "train loss:0.2134154688233839\n",
      "train loss:0.22672979446753325\n",
      "train loss:0.13491553323427882\n",
      "train loss:0.28663961076230304\n",
      "train loss:0.12501502955146904\n",
      "train loss:0.2832760377783602\n",
      "train loss:0.12115185998052196\n",
      "train loss:0.11567317444385987\n",
      "train loss:0.2738183483938452\n",
      "train loss:0.13990399603424808\n",
      "train loss:0.11687774121011285\n",
      "train loss:0.14230803287783578\n",
      "train loss:0.21729438249229285\n",
      "train loss:0.13058737983051058\n",
      "train loss:0.1023277426938884\n",
      "train loss:0.21279909256378068\n",
      "train loss:0.22411370728513988\n",
      "train loss:0.11211802914194031\n",
      "train loss:0.14965143235926237\n",
      "train loss:0.1013311925308534\n",
      "train loss:0.13100347488571973\n",
      "train loss:0.2084090719036434\n",
      "train loss:0.13843081012585107\n",
      "train loss:0.05710793708683206\n",
      "train loss:0.13850668302137006\n",
      "train loss:0.11254510581043586\n",
      "train loss:0.11517175783386004\n",
      "train loss:0.07938850076225273\n",
      "train loss:0.14168138038289516\n",
      "train loss:0.07339362834146068\n",
      "train loss:0.21304892435152023\n",
      "train loss:0.09043470839379106\n",
      "train loss:0.07766393756305817\n",
      "train loss:0.17074101750721207\n",
      "train loss:0.09781435423725394\n",
      "train loss:0.20605679901056514\n",
      "train loss:0.18002305798997598\n",
      "=== epoch:4, train acc:0.963, test acc:0.931 ===\n",
      "train loss:0.07885569431297658\n",
      "train loss:0.08512590810916493\n",
      "train loss:0.12819797352087028\n",
      "train loss:0.23842076789532368\n",
      "train loss:0.18746328821634428\n",
      "train loss:0.053335490299496593\n",
      "train loss:0.23718154690882426\n",
      "train loss:0.059053575862601744\n",
      "train loss:0.16772696938536336\n",
      "train loss:0.1476167342623241\n",
      "train loss:0.08838822765911662\n",
      "train loss:0.09094712118606509\n",
      "train loss:0.11690534431525554\n",
      "train loss:0.07259902671172917\n",
      "train loss:0.044679738597336496\n",
      "train loss:0.16923589277700274\n",
      "train loss:0.11227589264570574\n",
      "train loss:0.13846172477109525\n",
      "train loss:0.06459384601795684\n",
      "train loss:0.11818851974914808\n",
      "train loss:0.10113298151001167\n",
      "train loss:0.0742995043188611\n",
      "train loss:0.023290256279393344\n",
      "train loss:0.11144991476614409\n",
      "train loss:0.11502730827195493\n",
      "train loss:0.08653320744654996\n",
      "train loss:0.08205143291945406\n",
      "train loss:0.09955198848180036\n",
      "train loss:0.03469380049688513\n",
      "train loss:0.04159293563601519\n",
      "train loss:0.06049574605924746\n",
      "train loss:0.15352176828554634\n",
      "train loss:0.07626415244549176\n",
      "train loss:0.05652725329010051\n",
      "train loss:0.0665396837996855\n",
      "train loss:0.13673170116762473\n",
      "train loss:0.06298248336245446\n",
      "train loss:0.1262609687240632\n",
      "train loss:0.08605052601014065\n",
      "train loss:0.0882873474153854\n",
      "train loss:0.1139541429703799\n",
      "train loss:0.047024921244982455\n",
      "train loss:0.13548966762293524\n",
      "train loss:0.1354675640327786\n",
      "train loss:0.133076086995637\n",
      "train loss:0.09404689805369362\n",
      "train loss:0.09830504617555456\n",
      "train loss:0.05966855856894879\n",
      "train loss:0.06754628165175826\n",
      "train loss:0.09927326618266873\n",
      "=== epoch:5, train acc:0.973, test acc:0.94 ===\n",
      "train loss:0.059409550768156044\n",
      "train loss:0.08648254128690955\n",
      "train loss:0.034261290557877036\n",
      "train loss:0.06604274424885402\n",
      "train loss:0.04701543475324541\n",
      "train loss:0.059881993585058545\n",
      "train loss:0.10337924148888346\n",
      "train loss:0.06092767103015629\n",
      "train loss:0.07293585690188056\n",
      "train loss:0.0871200654200026\n",
      "train loss:0.08820601538046796\n",
      "train loss:0.06182675957102922\n",
      "train loss:0.11773370086626167\n",
      "train loss:0.049564789185278686\n",
      "train loss:0.0349795847640971\n",
      "train loss:0.13400664316571198\n",
      "train loss:0.07873032243086797\n",
      "train loss:0.08919793627489528\n",
      "train loss:0.058302951895458664\n",
      "train loss:0.03192845379116631\n",
      "train loss:0.036557234297026335\n",
      "train loss:0.03847353296178166\n",
      "train loss:0.08975221805304141\n",
      "train loss:0.04470851324129113\n",
      "train loss:0.04175143968827233\n",
      "train loss:0.029998387827948784\n",
      "train loss:0.0867641826479575\n",
      "train loss:0.12671154327474074\n",
      "train loss:0.08953614124846064\n",
      "train loss:0.027648686100347823\n",
      "train loss:0.07064863112477889\n",
      "train loss:0.07542666913425572\n",
      "train loss:0.0585176734415703\n",
      "train loss:0.04299875226421079\n",
      "train loss:0.052282913049397806\n",
      "train loss:0.03199230383734955\n",
      "train loss:0.05570912712564262\n",
      "train loss:0.07882641518770118\n",
      "train loss:0.04402440090746345\n",
      "train loss:0.02793057185155464\n",
      "train loss:0.1301760787950059\n",
      "train loss:0.01715846713555156\n",
      "train loss:0.02863826017551158\n",
      "train loss:0.08541751933188574\n",
      "train loss:0.10146816078920928\n",
      "train loss:0.026581831205033053\n",
      "train loss:0.041226820046041404\n",
      "train loss:0.17523160662699921\n",
      "train loss:0.07487709813098799\n",
      "train loss:0.022868962601149186\n",
      "=== epoch:6, train acc:0.979, test acc:0.946 ===\n",
      "train loss:0.06208453714206096\n",
      "train loss:0.05812063065849372\n",
      "train loss:0.033694461032979\n",
      "train loss:0.027140259551355933\n",
      "train loss:0.040209952161276964\n",
      "train loss:0.05146880024350302\n",
      "train loss:0.04800319917477676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.14616338044362942\n",
      "train loss:0.046505913849728936\n",
      "train loss:0.037100687846006696\n",
      "train loss:0.04116499003051907\n",
      "train loss:0.037244824429904934\n",
      "train loss:0.05924779165533166\n",
      "train loss:0.017026718153535906\n",
      "train loss:0.06234842116813833\n",
      "train loss:0.03153029118052863\n",
      "train loss:0.058943874510507276\n",
      "train loss:0.07250902272248444\n",
      "train loss:0.018876132786455047\n",
      "train loss:0.04894562252909292\n",
      "train loss:0.06937554341640916\n",
      "train loss:0.05270344608777048\n",
      "train loss:0.020938110910207353\n",
      "train loss:0.029978777937483346\n",
      "train loss:0.034797503802067455\n",
      "train loss:0.02735550391412181\n",
      "train loss:0.06282967426556234\n",
      "train loss:0.02084394119477176\n",
      "train loss:0.033352148601320665\n",
      "train loss:0.030721081204265848\n",
      "train loss:0.020388022909466924\n",
      "train loss:0.03317173193377147\n",
      "train loss:0.029548839466219598\n",
      "train loss:0.02994496916540719\n",
      "train loss:0.0119128651605335\n",
      "train loss:0.04129258709779883\n",
      "train loss:0.02580700524181229\n",
      "train loss:0.03858281269269473\n",
      "train loss:0.03529689659997519\n",
      "train loss:0.028831886907436897\n",
      "train loss:0.05652164461526968\n",
      "train loss:0.026560388677587143\n",
      "train loss:0.043486735913700995\n",
      "train loss:0.018229271676429206\n",
      "train loss:0.019074180603732362\n",
      "train loss:0.04637767974311321\n",
      "train loss:0.04114849849610328\n",
      "train loss:0.03962231047708435\n",
      "train loss:0.030306859295377606\n",
      "train loss:0.04772668465487153\n",
      "=== epoch:7, train acc:0.987, test acc:0.955 ===\n",
      "train loss:0.03542892447565902\n",
      "train loss:0.0641322937364661\n",
      "train loss:0.027427577254324362\n",
      "train loss:0.025816645254445655\n",
      "train loss:0.02949816765115207\n",
      "train loss:0.009194547254489755\n",
      "train loss:0.028078700006910453\n",
      "train loss:0.034706654612764606\n",
      "train loss:0.015238889327816038\n",
      "train loss:0.02186864697588418\n",
      "train loss:0.018792932865187562\n",
      "train loss:0.03114725265947984\n",
      "train loss:0.012944104803175038\n",
      "train loss:0.02388822644598148\n",
      "train loss:0.03432520617454361\n",
      "train loss:0.015181746876400058\n",
      "train loss:0.02454720938134222\n",
      "train loss:0.048484727671420556\n",
      "train loss:0.10395343016273668\n",
      "train loss:0.018953411916437596\n",
      "train loss:0.028578996314261588\n",
      "train loss:0.012112647211464553\n",
      "train loss:0.025402509162933355\n",
      "train loss:0.012660583050213135\n",
      "train loss:0.03689582796026423\n",
      "train loss:0.05339228137489884\n",
      "train loss:0.020336203800474618\n",
      "train loss:0.03867536639780823\n",
      "train loss:0.01756506519302982\n",
      "train loss:0.009263579522553455\n",
      "train loss:0.03974321209789579\n",
      "train loss:0.02675397573256427\n",
      "train loss:0.0671919066580128\n",
      "train loss:0.015298136448225214\n",
      "train loss:0.012432608655776209\n",
      "train loss:0.03217221626461455\n",
      "train loss:0.02252046322845185\n",
      "train loss:0.033023376620030576\n",
      "train loss:0.01604220188281933\n",
      "train loss:0.03583859991454922\n",
      "train loss:0.025023900749997368\n",
      "train loss:0.0336669725648081\n",
      "train loss:0.029888775959121868\n",
      "train loss:0.027307231582513664\n",
      "train loss:0.025114219276854116\n",
      "train loss:0.007894800228325132\n",
      "train loss:0.013757392633169501\n",
      "train loss:0.024242483435466977\n",
      "train loss:0.016216655265055283\n",
      "train loss:0.01417393596682505\n",
      "=== epoch:8, train acc:0.99, test acc:0.951 ===\n",
      "train loss:0.016339131127153426\n",
      "train loss:0.01759409832325224\n",
      "train loss:0.00810673476671125\n",
      "train loss:0.043385204508890655\n",
      "train loss:0.008558741457025943\n",
      "train loss:0.011523683822373206\n",
      "train loss:0.014484645589121008\n",
      "train loss:0.013281819252990556\n",
      "train loss:0.015372322294960812\n",
      "train loss:0.014666592737061812\n",
      "train loss:0.053477609818596485\n",
      "train loss:0.021246983100051447\n",
      "train loss:0.013224979596540969\n",
      "train loss:0.017412170618855093\n",
      "train loss:0.01572054494720414\n",
      "train loss:0.0249015265553618\n",
      "train loss:0.03942832592968077\n",
      "train loss:0.016485397307918682\n",
      "train loss:0.009724119806205196\n",
      "train loss:0.019785564631396663\n",
      "train loss:0.005957715112282531\n",
      "train loss:0.013010360996704249\n",
      "train loss:0.028719998741995868\n",
      "train loss:0.014084069256931654\n",
      "train loss:0.019921302975056173\n",
      "train loss:0.019244982151910416\n",
      "train loss:0.014814878804159637\n",
      "train loss:0.00723706079853713\n",
      "train loss:0.013549290558113578\n",
      "train loss:0.015164535944819299\n",
      "train loss:0.01792541610140903\n",
      "train loss:0.006883607444597654\n",
      "train loss:0.024197850095925327\n",
      "train loss:0.02226321801887958\n",
      "train loss:0.008032739829116951\n",
      "train loss:0.013845866935086744\n",
      "train loss:0.0072311394546212705\n",
      "train loss:0.014249818596833233\n",
      "train loss:0.018465021330799455\n",
      "train loss:0.021572572931248247\n",
      "train loss:0.01494094409286597\n",
      "train loss:0.01552514761035208\n",
      "train loss:0.021799357121222565\n",
      "train loss:0.010746327280285841\n",
      "train loss:0.019165781725307144\n",
      "train loss:0.008544231488556707\n",
      "train loss:0.008205049925461998\n",
      "train loss:0.008454646773008789\n",
      "train loss:0.04737641672202969\n",
      "train loss:0.020518580617797957\n",
      "=== epoch:9, train acc:0.995, test acc:0.959 ===\n",
      "train loss:0.02013713219132539\n",
      "train loss:0.007690061246912933\n",
      "train loss:0.05766767219999627\n",
      "train loss:0.014301000804235138\n",
      "train loss:0.008361886933551402\n",
      "train loss:0.01399224052911467\n",
      "train loss:0.01725707808573734\n",
      "train loss:0.009915409241874246\n",
      "train loss:0.0038743398704240107\n",
      "train loss:0.031271069038894345\n",
      "train loss:0.03639378372507049\n",
      "train loss:0.03302380262430604\n",
      "train loss:0.01845471535089799\n",
      "train loss:0.015189498122212439\n",
      "train loss:0.02206361146396052\n",
      "train loss:0.011033820232459291\n",
      "train loss:0.006747235068549271\n",
      "train loss:0.025848175825544745\n",
      "train loss:0.0177495184024679\n",
      "train loss:0.016957047317204738\n",
      "train loss:0.007862683516021506\n",
      "train loss:0.021249928515646572\n",
      "train loss:0.012955926445502901\n",
      "train loss:0.012594474847245478\n",
      "train loss:0.018154488728708396\n",
      "train loss:0.015806092094110224\n",
      "train loss:0.0250300044696697\n",
      "train loss:0.0053207007689032824\n",
      "train loss:0.008369039072593933\n",
      "train loss:0.004779187767249368\n",
      "train loss:0.011874306850687444\n",
      "train loss:0.010745507734254518\n",
      "train loss:0.00397816260777169\n",
      "train loss:0.009888262124089194\n",
      "train loss:0.007068341411174842\n",
      "train loss:0.059364401415352576\n",
      "train loss:0.013298412210884463\n",
      "train loss:0.016236855453850306\n",
      "train loss:0.003001156215502079\n",
      "train loss:0.019248897316061258\n",
      "train loss:0.014966222293482616\n",
      "train loss:0.009278040959273023\n",
      "train loss:0.009002473500598691\n",
      "train loss:0.013312179836001059\n",
      "train loss:0.02107094071837437\n",
      "train loss:0.012283000480906825\n",
      "train loss:0.00715484073692284\n",
      "train loss:0.03235255748191772\n",
      "train loss:0.007273186887795335\n",
      "train loss:0.015695590071677295\n",
      "=== epoch:10, train acc:0.999, test acc:0.962 ===\n",
      "train loss:0.0074846729258496\n",
      "train loss:0.01047920532098798\n",
      "train loss:0.009130020201050816\n",
      "train loss:0.002886760524687702\n",
      "train loss:0.012721091161866028\n",
      "train loss:0.008992335840237673\n",
      "train loss:0.01715761504576305\n",
      "train loss:0.01538611064082866\n",
      "train loss:0.008828639675657762\n",
      "train loss:0.00961697380987296\n",
      "train loss:0.008152938176011504\n",
      "train loss:0.013495273963163268\n",
      "train loss:0.007046462850976063\n",
      "train loss:0.00799025859469981\n",
      "train loss:0.02432049518476584\n",
      "train loss:0.00947466774325521\n",
      "train loss:0.004640165515621305\n",
      "train loss:0.0075698967947473465\n",
      "train loss:0.007986263587687828\n",
      "train loss:0.01785448925071583\n",
      "train loss:0.009157346310309731\n",
      "train loss:0.003747295629812017\n",
      "train loss:0.007464144147235571\n",
      "train loss:0.007310722798689962\n",
      "train loss:0.014241992716430391\n",
      "train loss:0.009758399754399955\n",
      "train loss:0.004513185877139201\n",
      "train loss:0.007374650134171722\n",
      "train loss:0.019606182976221017\n",
      "train loss:0.009010691262303597\n",
      "train loss:0.006721983378953464\n",
      "train loss:0.008873588968686598\n",
      "train loss:0.01609614807565242\n",
      "train loss:0.004602718889479177\n",
      "train loss:0.010111730812842055\n",
      "train loss:0.005959098505296601\n",
      "train loss:0.004397231377819858\n",
      "train loss:0.011801942980165665\n",
      "train loss:0.014337625027532892\n",
      "train loss:0.02542250766133118\n",
      "train loss:0.00910034431851945\n",
      "train loss:0.0040251972692669806\n",
      "train loss:0.002537152598623509\n",
      "train loss:0.0051319743932248685\n",
      "train loss:0.004451860532723335\n",
      "train loss:0.004938914103159455\n",
      "train loss:0.012264191580776563\n",
      "train loss:0.014219567644233815\n",
      "train loss:0.0052445250749898475\n",
      "train loss:0.0038266725567617727\n",
      "=== epoch:11, train acc:0.998, test acc:0.959 ===\n",
      "train loss:0.00578906058310889\n",
      "train loss:0.00438787853547305\n",
      "train loss:0.0019801648213427945\n",
      "train loss:0.011250708759881484\n",
      "train loss:0.006497829575687175\n",
      "train loss:0.008054506774365543\n",
      "train loss:0.004966326544982724\n",
      "train loss:0.006096729730846112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0037163963074804056\n",
      "train loss:0.008445097742965448\n",
      "train loss:0.005474217514103389\n",
      "train loss:0.011555162603892557\n",
      "train loss:0.0024429465405965594\n",
      "train loss:0.003823522708172255\n",
      "train loss:0.005527116237502021\n",
      "train loss:0.018894636801425682\n",
      "train loss:0.006437988268513883\n",
      "train loss:0.003871995299770924\n",
      "train loss:0.0027802891277058928\n",
      "train loss:0.004552723380258138\n",
      "train loss:0.0059182619409985475\n",
      "train loss:0.010935811127637236\n",
      "train loss:0.006588055149869433\n",
      "train loss:0.006520452217528902\n",
      "train loss:0.004831804784342383\n",
      "train loss:0.002413648578526035\n",
      "train loss:0.004724836245919193\n",
      "train loss:0.0065455713893065\n",
      "train loss:0.004170504572394226\n",
      "train loss:0.009685944035179434\n",
      "train loss:0.004092989593502531\n",
      "train loss:0.0030378153812900184\n",
      "train loss:0.004865464727131123\n",
      "train loss:0.003160675972628834\n",
      "train loss:0.008369204528208196\n",
      "train loss:0.013162159624653325\n",
      "train loss:0.0027786934666770265\n",
      "train loss:0.004417997544217333\n",
      "train loss:0.006571967796227718\n",
      "train loss:0.003511537281045561\n",
      "train loss:0.010006902654515178\n",
      "train loss:0.0054703736699368245\n",
      "train loss:0.0021639537417285862\n",
      "train loss:0.004377349953839104\n",
      "train loss:0.0046889082333957215\n",
      "train loss:0.0052539019095900205\n",
      "train loss:0.0053893793990751025\n",
      "train loss:0.0015852931148187621\n",
      "train loss:0.0026141192719731925\n",
      "train loss:0.005867326180224611\n",
      "=== epoch:12, train acc:1.0, test acc:0.958 ===\n",
      "train loss:0.004615609674244759\n",
      "train loss:0.002556024934179714\n",
      "train loss:0.004615452349986292\n",
      "train loss:0.005387598308191533\n",
      "train loss:0.008275283857233121\n",
      "train loss:0.0074497472465799046\n",
      "train loss:0.0028888124427006606\n",
      "train loss:0.003311238618981088\n",
      "train loss:0.0031332682734290128\n",
      "train loss:0.012420242353326307\n",
      "train loss:0.004865468364699076\n",
      "train loss:0.004697039155425309\n",
      "train loss:0.004962152578751611\n",
      "train loss:0.003699711709456845\n",
      "train loss:0.006119894714005191\n",
      "train loss:0.007753816967683357\n",
      "train loss:0.0027374297112297457\n",
      "train loss:0.0047121812779134424\n",
      "train loss:0.0029389357850194402\n",
      "train loss:0.0016807295831841942\n",
      "train loss:0.005997630856817776\n",
      "train loss:0.005120321993585926\n",
      "train loss:0.007861955551401706\n",
      "train loss:0.003153521633682479\n",
      "train loss:0.005827805038896741\n",
      "train loss:0.0020404849752822755\n",
      "train loss:0.0035632188681786413\n",
      "train loss:0.006214600750376551\n",
      "train loss:0.003413056300504305\n",
      "train loss:0.00203515497647446\n",
      "train loss:0.005580028060633077\n",
      "train loss:0.0031685687385635403\n",
      "train loss:0.006547130627525707\n",
      "train loss:0.006228027439055532\n",
      "train loss:0.002858701643217653\n",
      "train loss:0.004828024643288938\n",
      "train loss:0.0028961949945831016\n",
      "train loss:0.005242973097570023\n",
      "train loss:0.0018510861295664982\n",
      "train loss:0.0016283149687158556\n",
      "train loss:0.0020165677086914626\n",
      "train loss:0.004875118795672305\n",
      "train loss:0.002560544747649438\n",
      "train loss:0.02460795169281136\n",
      "train loss:0.003508583288536777\n",
      "train loss:0.005271545191475884\n",
      "train loss:0.0035466688204479806\n",
      "train loss:0.002513627110374678\n",
      "train loss:0.0030371527871884494\n",
      "train loss:0.002326712800228686\n",
      "=== epoch:13, train acc:0.999, test acc:0.959 ===\n",
      "train loss:0.001261604028552518\n",
      "train loss:0.00612634505645248\n",
      "train loss:0.006470282542458938\n",
      "train loss:0.0035552436470787686\n",
      "train loss:0.00475082145121554\n",
      "train loss:0.005031355071957891\n",
      "train loss:0.0022953463244609596\n",
      "train loss:0.008494704439003846\n",
      "train loss:0.002629323825200372\n",
      "train loss:0.004366256898679516\n",
      "train loss:0.0046160132323488316\n",
      "train loss:0.0028033812614291853\n",
      "train loss:0.003338911636956181\n",
      "train loss:0.001443744891167141\n",
      "train loss:0.007819024041850801\n",
      "train loss:0.009049842995558202\n",
      "train loss:0.007919015288528196\n",
      "train loss:0.0010399440497135736\n",
      "train loss:0.0031824100612716194\n",
      "train loss:0.006918687635026522\n",
      "train loss:0.005803288880028299\n",
      "train loss:0.0027964938326302574\n",
      "train loss:0.0022214886848589323\n",
      "train loss:0.010329818752375548\n",
      "train loss:0.00307242720577936\n",
      "train loss:0.005709856657494628\n",
      "train loss:0.0030660002634853344\n",
      "train loss:0.003013906093035798\n",
      "train loss:0.0018260356267132732\n",
      "train loss:0.0015831268104907934\n",
      "train loss:0.0019980998846292355\n",
      "train loss:0.004143397320286601\n",
      "train loss:0.005014998638967295\n",
      "train loss:0.00471839922535851\n",
      "train loss:0.0029626847227579374\n",
      "train loss:0.002400900188371616\n",
      "train loss:0.001516655862249713\n",
      "train loss:0.002989895384447341\n",
      "train loss:0.001028425327037997\n",
      "train loss:0.0015853103308777936\n",
      "train loss:0.006256693568635119\n",
      "train loss:0.00578055587991654\n",
      "train loss:0.003519115901159071\n",
      "train loss:0.00510790781334587\n",
      "train loss:0.002394521251401972\n",
      "train loss:0.0038261578914904185\n",
      "train loss:0.004047851251762609\n",
      "train loss:0.00432195843424276\n",
      "train loss:0.006906710008472183\n",
      "train loss:0.002634686070382664\n",
      "=== epoch:14, train acc:1.0, test acc:0.956 ===\n",
      "train loss:0.003092994408182082\n",
      "train loss:0.0035209306383624113\n",
      "train loss:0.004116455868427254\n",
      "train loss:0.003938326395835968\n",
      "train loss:0.006144580724819144\n",
      "train loss:0.002608369237484073\n",
      "train loss:0.0016366665151757382\n",
      "train loss:0.007127427374830716\n",
      "train loss:0.0028820052527664987\n",
      "train loss:0.00321208179221323\n",
      "train loss:0.0011600673569133629\n",
      "train loss:0.003476213648511134\n",
      "train loss:0.00454725288228894\n",
      "train loss:0.002537645574723228\n",
      "train loss:0.0032128332213212612\n",
      "train loss:0.005385390902878646\n",
      "train loss:0.0035666075775779103\n",
      "train loss:0.0031118586326555685\n",
      "train loss:0.001202893712206122\n",
      "train loss:0.0023865467673194656\n",
      "train loss:0.0017420003133864102\n",
      "train loss:0.004140495799527068\n",
      "train loss:0.0018625831632490585\n",
      "train loss:0.002665897589004525\n",
      "train loss:0.0016483084715001556\n",
      "train loss:0.0027354614810821925\n",
      "train loss:0.003170373126823427\n",
      "train loss:0.0026536680387980434\n",
      "train loss:0.003709343224269748\n",
      "train loss:0.0011809183052706074\n",
      "train loss:0.005445906590179822\n",
      "train loss:0.001127797019069623\n",
      "train loss:0.0014019818157815652\n",
      "train loss:0.004286241493387473\n",
      "train loss:0.007486930684246784\n",
      "train loss:0.0030075840869380043\n",
      "train loss:0.002913995652465784\n",
      "train loss:0.001711493901092541\n",
      "train loss:0.00466551782108178\n",
      "train loss:0.0028348211365816422\n",
      "train loss:0.002858007962911509\n",
      "train loss:0.0019889729887222034\n",
      "train loss:0.0020418738763956046\n",
      "train loss:0.0017934905397733317\n",
      "train loss:0.002291727809525875\n",
      "train loss:0.001831771344691057\n",
      "train loss:0.0009578128918956478\n",
      "train loss:0.0007732552597916338\n",
      "train loss:0.0033683574153623693\n",
      "train loss:0.0021086250844302304\n",
      "=== epoch:15, train acc:0.999, test acc:0.969 ===\n",
      "train loss:0.0014893673536174696\n",
      "train loss:0.0012590527041919225\n",
      "train loss:0.001866444263234476\n",
      "train loss:0.0023900825382520115\n",
      "train loss:0.0018559284165503653\n",
      "train loss:0.0016696945764098734\n",
      "train loss:0.009395019638316241\n",
      "train loss:0.0012473222498856538\n",
      "train loss:0.0009330083901418815\n",
      "train loss:0.0019752167264534305\n",
      "train loss:0.0031861076379272615\n",
      "train loss:0.0015112149345610244\n",
      "train loss:0.005490307745047086\n",
      "train loss:0.002631863820800432\n",
      "train loss:0.0015544365396478643\n",
      "train loss:0.0013927246692346847\n",
      "train loss:0.0011528670788229912\n",
      "train loss:0.002639584213285724\n",
      "train loss:0.0017413010522160247\n",
      "train loss:0.004541575409279114\n",
      "train loss:0.00158340838227092\n",
      "train loss:0.0011452144394785712\n",
      "train loss:0.0013976225372892596\n",
      "train loss:0.0012672134038676152\n",
      "train loss:0.0011326645769373623\n",
      "train loss:0.001419952049472193\n",
      "train loss:0.003669389164722281\n",
      "train loss:0.004397229768563035\n",
      "train loss:0.0021156307703204527\n",
      "train loss:0.0018428163257663156\n",
      "train loss:0.0015731988796784\n",
      "train loss:0.003629794859210393\n",
      "train loss:0.0009107326443371208\n",
      "train loss:0.002017511008567284\n",
      "train loss:0.0015845791875701224\n",
      "train loss:0.0029643408525902126\n",
      "train loss:0.0016583325815395574\n",
      "train loss:0.002509380145435654\n",
      "train loss:0.0013724997900228001\n",
      "train loss:0.0023905506901645206\n",
      "train loss:0.0032677935356462003\n",
      "train loss:0.0008066990885656274\n",
      "train loss:0.0023656061894727553\n",
      "train loss:0.002561990679375925\n",
      "train loss:0.0017333868828458782\n",
      "train loss:0.003915003082178454\n",
      "train loss:0.001032117973186441\n",
      "train loss:0.0028671119284850144\n",
      "train loss:0.002607509286463357\n",
      "train loss:0.0017550694429131644\n",
      "=== epoch:16, train acc:1.0, test acc:0.962 ===\n",
      "train loss:0.0008990500823316935\n",
      "train loss:0.001961192451189425\n",
      "train loss:0.00415356416556067\n",
      "train loss:0.0010409323885174453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0027774767908113614\n",
      "train loss:0.0008714010038811397\n",
      "train loss:0.001230197763656776\n",
      "train loss:0.0022243980738486336\n",
      "train loss:0.0015304695012233881\n",
      "train loss:0.0011534177567287035\n",
      "train loss:0.0018575743459569006\n",
      "train loss:0.0030711369356771732\n",
      "train loss:0.0014908470127985118\n",
      "train loss:0.002533319573331284\n",
      "train loss:0.0010974476255290844\n",
      "train loss:0.0018820770210908925\n",
      "train loss:0.00043187657033641426\n",
      "train loss:0.0005418041534367749\n",
      "train loss:0.00304367472653363\n",
      "train loss:0.0009744790387256475\n",
      "train loss:0.0008400784426058788\n",
      "train loss:0.0015694328688245463\n",
      "train loss:0.002128901906452199\n",
      "train loss:0.0008389664336180419\n",
      "train loss:0.0020072124058968855\n",
      "train loss:0.0012375105027841395\n",
      "train loss:0.0012326621778040456\n",
      "train loss:0.0002762179903581372\n",
      "train loss:0.0019438021969769342\n",
      "train loss:0.0015637523504251844\n",
      "train loss:0.0008405443802746812\n",
      "train loss:0.0012901859212411514\n",
      "train loss:0.0018601778747977188\n",
      "train loss:0.0014625543382997376\n",
      "train loss:0.0019034637177896866\n",
      "train loss:0.0010220939370129594\n",
      "train loss:0.0012413867120053162\n",
      "train loss:0.0005554375530773506\n",
      "train loss:0.0012600503753731986\n",
      "train loss:0.0006464895689896652\n",
      "train loss:0.0009224231003445886\n",
      "train loss:0.0013296433661686591\n",
      "train loss:0.0013336812213341708\n",
      "train loss:0.001924038839799657\n",
      "train loss:0.0008597361159278798\n",
      "train loss:0.000757230542120037\n",
      "train loss:0.001347567883359655\n",
      "train loss:0.0005253933975878355\n",
      "train loss:0.001377973186627136\n",
      "train loss:0.0015057995634758315\n",
      "=== epoch:17, train acc:1.0, test acc:0.966 ===\n",
      "train loss:0.001462721698924129\n",
      "train loss:0.0009236454543239155\n",
      "train loss:0.0006146967530629682\n",
      "train loss:0.002246271309653749\n",
      "train loss:0.00078250999201677\n",
      "train loss:0.0011218674970613575\n",
      "train loss:0.0010965175498055205\n",
      "train loss:0.0006305497883159909\n",
      "train loss:0.001245458464149331\n",
      "train loss:0.0003442371963367694\n",
      "train loss:0.0011776472437986171\n",
      "train loss:0.0007365005488412746\n",
      "train loss:0.0008031414621890666\n",
      "train loss:0.001001566614273813\n",
      "train loss:0.0010100101583769118\n",
      "train loss:0.0009749614698685798\n",
      "train loss:0.0015151430350529961\n",
      "train loss:0.0013632837154652273\n",
      "train loss:0.0017490639712263484\n",
      "train loss:0.0012090817452942771\n",
      "train loss:0.006794644453967405\n",
      "train loss:0.002327557205299574\n",
      "train loss:0.0008041392283134153\n",
      "train loss:0.0006812033235183501\n",
      "train loss:0.0010497860055887465\n",
      "train loss:0.0015931263660162365\n",
      "train loss:0.0013720122698244114\n",
      "train loss:0.0013621590027497166\n",
      "train loss:0.0019683340431211073\n",
      "train loss:0.004179358941944228\n",
      "train loss:0.0012672232618402548\n",
      "train loss:0.001706491725739384\n",
      "train loss:0.0006100741744961395\n",
      "train loss:0.0013937981288243235\n",
      "train loss:0.0009877756433637943\n",
      "train loss:0.0026642980230805226\n",
      "train loss:0.0003154892480851978\n",
      "train loss:0.0014254030409901741\n",
      "train loss:0.0009391862786491702\n",
      "train loss:0.000680568634572121\n",
      "train loss:0.0012348876933308502\n",
      "train loss:0.0009442459811761645\n",
      "train loss:0.0008502513220495829\n",
      "train loss:0.002441608698758736\n",
      "train loss:0.001318171098229565\n",
      "train loss:0.0015401060019537955\n",
      "train loss:0.001244248061022905\n",
      "train loss:0.0012475327905796443\n",
      "train loss:0.0010703235588445778\n",
      "train loss:0.0009393006593755697\n",
      "=== epoch:18, train acc:1.0, test acc:0.966 ===\n",
      "train loss:0.000957970628273982\n",
      "train loss:0.0009679839923191752\n",
      "train loss:0.00022570778321661885\n",
      "train loss:0.0017154482144171748\n",
      "train loss:0.00039514188430514225\n",
      "train loss:0.0007292077681835131\n",
      "train loss:0.00036771614362796426\n",
      "train loss:0.0005773799164542511\n",
      "train loss:0.001398565770052453\n",
      "train loss:0.0008762872284535672\n",
      "train loss:0.0006692257437105518\n",
      "train loss:0.0008963618867012805\n",
      "train loss:0.0009157688687578508\n",
      "train loss:0.000379031156282695\n",
      "train loss:0.0012771597989837988\n",
      "train loss:0.000675033640645817\n",
      "train loss:0.0035503953136398576\n",
      "train loss:0.0010172282266943421\n",
      "train loss:0.0010747145353625018\n",
      "train loss:0.0014877377323629516\n",
      "train loss:0.001215092001793553\n",
      "train loss:0.001669173512058846\n",
      "train loss:0.000993430076295044\n",
      "train loss:0.0012586106104538369\n",
      "train loss:0.0022139521515453908\n",
      "train loss:0.00047294979676930436\n",
      "train loss:0.001114279820241572\n",
      "train loss:0.0006993150153320187\n",
      "train loss:0.0005830469511887526\n",
      "train loss:0.00020503915985115425\n",
      "train loss:0.0009618540767164115\n",
      "train loss:0.0011857959095506992\n",
      "train loss:0.0012420182227554132\n",
      "train loss:0.0006361584321231371\n",
      "train loss:0.0012669112479965516\n",
      "train loss:0.0005379224689901071\n",
      "train loss:0.0006775875574581593\n",
      "train loss:0.00035213528519436303\n",
      "train loss:0.0009098773411114912\n",
      "train loss:0.0006464843204141102\n",
      "train loss:0.001068338369447987\n",
      "train loss:0.000606946755437979\n",
      "train loss:0.0009114986683336192\n",
      "train loss:0.0006832299429917735\n",
      "train loss:0.0009248011916914098\n",
      "train loss:0.001144854056561826\n",
      "train loss:0.0008800936332527752\n",
      "train loss:0.0006161757551077241\n",
      "train loss:0.000723511051857899\n",
      "train loss:0.00045130357518528684\n",
      "=== epoch:19, train acc:1.0, test acc:0.966 ===\n",
      "train loss:0.0006494668569193878\n",
      "train loss:0.0005570777086074868\n",
      "train loss:0.000523695879682019\n",
      "train loss:0.0008615961115272815\n",
      "train loss:0.001151311950947654\n",
      "train loss:0.000696301489230311\n",
      "train loss:0.0006289414199367868\n",
      "train loss:0.000563054361502465\n",
      "train loss:0.0012518448959765848\n",
      "train loss:0.0009087766852491679\n",
      "train loss:0.0004948459822009803\n",
      "train loss:0.0006850118842801017\n",
      "train loss:0.0013650504138485514\n",
      "train loss:0.0006411149943965438\n",
      "train loss:0.00039472074498596776\n",
      "train loss:0.0007760320513191107\n",
      "train loss:0.0009014691202085169\n",
      "train loss:0.0004697676291614931\n",
      "train loss:0.00037916578817728813\n",
      "train loss:0.0007162126812879162\n",
      "train loss:0.0011841390591827829\n",
      "train loss:0.0008218119690018001\n",
      "train loss:0.0004927458067163608\n",
      "train loss:0.0015576695868785226\n",
      "train loss:0.0007197042729758712\n",
      "train loss:0.0009449847806499469\n",
      "train loss:0.0009443473230059601\n",
      "train loss:0.0008407828111525414\n",
      "train loss:0.0005908102663611029\n",
      "train loss:0.0013556697925354902\n",
      "train loss:0.0004206191826846415\n",
      "train loss:0.0006606709935263421\n",
      "train loss:0.0011342335701791115\n",
      "train loss:0.0008312171126364967\n",
      "train loss:0.0003033521052749772\n",
      "train loss:0.0007430398032224314\n",
      "train loss:0.0006818185272193786\n",
      "train loss:0.0009910786489533917\n",
      "train loss:0.0007939559412654994\n",
      "train loss:0.000804187686870203\n",
      "train loss:0.0006144692083152684\n",
      "train loss:0.0005916777247491576\n",
      "train loss:0.001282724753304519\n",
      "train loss:0.000521679252829515\n",
      "train loss:0.0006948710502487978\n",
      "train loss:0.0006607449132045708\n",
      "train loss:0.0011566115437204464\n",
      "train loss:0.0007490441672046667\n",
      "train loss:0.0007947419480744667\n",
      "train loss:0.0006988869019137125\n",
      "=== epoch:20, train acc:1.0, test acc:0.967 ===\n",
      "train loss:0.0005835743935545198\n",
      "train loss:0.0006313039230017252\n",
      "train loss:0.0009214765292458453\n",
      "train loss:0.0006902726572254632\n",
      "train loss:0.0008388882751712974\n",
      "train loss:0.000763533845986024\n",
      "train loss:0.00035310059414850174\n",
      "train loss:0.0005650241078750559\n",
      "train loss:0.0007699885102699753\n",
      "train loss:0.0007142279768302807\n",
      "train loss:0.0006545767656042441\n",
      "train loss:0.000649889823003501\n",
      "train loss:0.0007225695925212462\n",
      "train loss:0.0007884893075201958\n",
      "train loss:0.0007028025332832804\n",
      "train loss:0.000527668860058634\n",
      "train loss:0.0006249051735289789\n",
      "train loss:0.0004881601241720552\n",
      "train loss:0.0006431522808237753\n",
      "train loss:0.0006541585928191871\n",
      "train loss:0.0005112964573550322\n",
      "train loss:0.0008447548625940637\n",
      "train loss:0.00045547669883109305\n",
      "train loss:0.000495534227995909\n",
      "train loss:0.0002280194474672543\n",
      "train loss:0.0004133684834859328\n",
      "train loss:0.0007251005347168188\n",
      "train loss:0.0008092076670723128\n",
      "train loss:0.0011411161047565916\n",
      "train loss:0.0004754353056858164\n",
      "train loss:0.0005994444295571405\n",
      "train loss:0.0008010504414056682\n",
      "train loss:0.0007709348816647264\n",
      "train loss:0.0007341983223345083\n",
      "train loss:0.0005691935697131643\n",
      "train loss:0.0008492905186459536\n",
      "train loss:0.0008160653806240955\n",
      "train loss:0.0006506781693688392\n",
      "train loss:0.0003575979771833225\n",
      "train loss:0.0007451250265825549\n",
      "train loss:0.0007143793961595418\n",
      "train loss:0.0004202835198461953\n",
      "train loss:0.0013735512750932314\n",
      "train loss:0.0008983235431741135\n",
      "train loss:0.0005551380861325739\n",
      "train loss:0.00047009626959933\n",
      "train loss:0.00034947184572120467\n",
      "train loss:0.0004456747614466746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0007872117320902521\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.965\n"
     ]
    }
   ],
   "source": [
    "network2 = TestConvNet2()\n",
    "trainer2 = Trainer(network2, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr':0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "\n",
    "trainer2.train()\n",
    "network2.save_params(\"params/test_convnet2_params.pkl\")\n",
    "\n",
    "with open(\"trainer2.pkl\", 'wb') as f:\n",
    "    pickle.dump(trainer2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7360c2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.068308813555473\n",
      "=== epoch:1, train acc:0.207, test acc:0.214 ===\n",
      "train loss:1.9658015917493747\n",
      "train loss:1.944837739124967\n",
      "train loss:1.6239540142634674\n",
      "train loss:1.5996917934399904\n",
      "train loss:1.5437775882598959\n",
      "train loss:1.2788979505489348\n",
      "train loss:1.2144247465035938\n",
      "train loss:1.0506941896135542\n",
      "train loss:1.013306639866435\n",
      "train loss:0.8692129695528272\n",
      "train loss:0.6778222622848117\n",
      "train loss:0.6982794194384723\n",
      "train loss:0.5707425395952704\n",
      "train loss:0.6010688916892373\n",
      "train loss:0.7034506701777846\n",
      "train loss:0.5556195282894876\n",
      "train loss:0.6645989547546169\n",
      "train loss:0.2644735299602632\n",
      "train loss:0.5081896201143811\n",
      "train loss:0.5275176038024757\n",
      "train loss:0.3702594480794727\n",
      "train loss:0.5288464604892751\n",
      "train loss:0.5018112196296439\n",
      "train loss:0.4692217439335205\n",
      "train loss:0.573615374681632\n",
      "train loss:0.29600940008234367\n",
      "train loss:0.5898419928810591\n",
      "train loss:0.3245324485334395\n",
      "train loss:0.24861520879795596\n",
      "train loss:0.34262675054554165\n",
      "train loss:0.2677833452296547\n",
      "train loss:0.33687630662988644\n",
      "train loss:0.38829150175845234\n",
      "train loss:0.3606016054665819\n",
      "train loss:0.2048126363743789\n",
      "train loss:0.3707597502172531\n",
      "train loss:0.3532588493524507\n",
      "train loss:0.2347741344372139\n",
      "train loss:0.5676005396117811\n",
      "train loss:0.38804702228556226\n",
      "train loss:0.23153813518963431\n",
      "train loss:0.22897335667465726\n",
      "train loss:0.19601162496645547\n",
      "train loss:0.30976263682396016\n",
      "train loss:0.35105231420144667\n",
      "train loss:0.15782239880791837\n",
      "train loss:0.21535683026732616\n",
      "train loss:0.32409260950324464\n",
      "train loss:0.3101077407985435\n",
      "train loss:0.4020453874974028\n",
      "=== epoch:2, train acc:0.908, test acc:0.876 ===\n",
      "train loss:0.25807917690780874\n",
      "train loss:0.22349058229803895\n",
      "train loss:0.16300415100141244\n",
      "train loss:0.2589079819553434\n",
      "train loss:0.2963009700035631\n",
      "train loss:0.17496604784042583\n",
      "train loss:0.2820094244366355\n",
      "train loss:0.36208065640962867\n",
      "train loss:0.21942890831704032\n",
      "train loss:0.27223779546786264\n",
      "train loss:0.1099211096397966\n",
      "train loss:0.154749584472293\n",
      "train loss:0.2750525845588811\n",
      "train loss:0.2706039243697148\n",
      "train loss:0.2708917402353119\n",
      "train loss:0.2084998255196396\n",
      "train loss:0.15715906490631296\n",
      "train loss:0.16513185106649528\n",
      "train loss:0.20740797899110228\n",
      "train loss:0.14969604157744723\n",
      "train loss:0.1277017661852927\n",
      "train loss:0.14277933783893823\n",
      "train loss:0.17300460599831147\n",
      "train loss:0.22157888631476408\n",
      "train loss:0.21812516473873494\n",
      "train loss:0.19769682869874436\n",
      "train loss:0.23990185766889124\n",
      "train loss:0.3329627960895255\n",
      "train loss:0.31251529736415956\n",
      "train loss:0.24614558176534082\n",
      "train loss:0.1286082125057542\n",
      "train loss:0.20027772399843194\n",
      "train loss:0.18453431385246805\n",
      "train loss:0.1669033782104467\n",
      "train loss:0.15376451557291143\n",
      "train loss:0.21384199336134352\n",
      "train loss:0.29215847275182494\n",
      "train loss:0.22261659245523774\n",
      "train loss:0.18048345179508687\n",
      "train loss:0.1747218832379907\n",
      "train loss:0.2053680794756154\n",
      "train loss:0.20312373154852348\n",
      "train loss:0.19063709633474482\n",
      "train loss:0.13256491744556256\n",
      "train loss:0.19246807352253337\n",
      "train loss:0.15962986969281864\n",
      "train loss:0.2762269263821827\n",
      "train loss:0.10879244564031669\n",
      "train loss:0.18365121669415718\n",
      "train loss:0.09397440190635656\n",
      "=== epoch:3, train acc:0.945, test acc:0.912 ===\n",
      "train loss:0.13426690030208885\n",
      "train loss:0.15688859036487274\n",
      "train loss:0.18595912442403267\n",
      "train loss:0.11779344592067818\n",
      "train loss:0.2979412078710879\n",
      "train loss:0.13433725644648745\n",
      "train loss:0.07270108270848377\n",
      "train loss:0.0959625135189313\n",
      "train loss:0.2170572047294473\n",
      "train loss:0.13506030040875966\n",
      "train loss:0.10875980808500248\n",
      "train loss:0.11342419754566853\n",
      "train loss:0.14831616809150863\n",
      "train loss:0.08220605929753505\n",
      "train loss:0.1342016853045634\n",
      "train loss:0.16284924055610858\n",
      "train loss:0.05372449063866955\n",
      "train loss:0.12147916315799293\n",
      "train loss:0.1297643493317619\n",
      "train loss:0.1148857253711728\n",
      "train loss:0.09980671478307025\n",
      "train loss:0.1109982463086937\n",
      "train loss:0.11432004760188796\n",
      "train loss:0.09446553626701101\n",
      "train loss:0.11310557419907451\n",
      "train loss:0.06140733315695423\n",
      "train loss:0.22781772842400605\n",
      "train loss:0.06797271654278264\n",
      "train loss:0.08246308464018495\n",
      "train loss:0.1038044031741488\n",
      "train loss:0.1070976689137402\n",
      "train loss:0.1074317943464726\n",
      "train loss:0.10961099279318294\n",
      "train loss:0.08735411253178231\n",
      "train loss:0.02631840539024939\n",
      "train loss:0.10793856966804231\n",
      "train loss:0.05662194444513861\n",
      "train loss:0.14971122350785557\n",
      "train loss:0.1541070794593963\n",
      "train loss:0.15350344085980028\n",
      "train loss:0.08191531598946414\n",
      "train loss:0.14956138763229126\n",
      "train loss:0.04518963353971217\n",
      "train loss:0.11687074675760917\n",
      "train loss:0.06436719543213916\n",
      "train loss:0.06950518154421567\n",
      "train loss:0.05298999804891365\n",
      "train loss:0.15225606632900168\n",
      "train loss:0.10665163036188588\n",
      "train loss:0.20259583479590437\n",
      "=== epoch:4, train acc:0.962, test acc:0.95 ===\n",
      "train loss:0.11169946321655147\n",
      "train loss:0.11555760799187961\n",
      "train loss:0.0627201889141761\n",
      "train loss:0.07558270812678825\n",
      "train loss:0.08046443013370158\n",
      "train loss:0.12344627942165286\n",
      "train loss:0.11195622953349771\n",
      "train loss:0.1487819188069948\n",
      "train loss:0.037249215354900424\n",
      "train loss:0.1214722011344223\n",
      "train loss:0.1113989894937199\n",
      "train loss:0.02928383762301494\n",
      "train loss:0.17380341046396108\n",
      "train loss:0.051974479824861204\n",
      "train loss:0.17054343586347628\n",
      "train loss:0.09417782691038427\n",
      "train loss:0.09142550188678569\n",
      "train loss:0.03811161934330345\n",
      "train loss:0.10237092566352221\n",
      "train loss:0.11439235945345459\n",
      "train loss:0.03787367636574047\n",
      "train loss:0.12693247832920737\n",
      "train loss:0.08514542448973753\n",
      "train loss:0.125605734153728\n",
      "train loss:0.0686498766813819\n",
      "train loss:0.033394370067404325\n",
      "train loss:0.013665641776922567\n",
      "train loss:0.06319339445146033\n",
      "train loss:0.03950705338929533\n",
      "train loss:0.040192947675015356\n",
      "train loss:0.04507779846685823\n",
      "train loss:0.05546496735394486\n",
      "train loss:0.03867779435339254\n",
      "train loss:0.052037103203579974\n",
      "train loss:0.056871916018984316\n",
      "train loss:0.022645856479885807\n",
      "train loss:0.05783616176847458\n",
      "train loss:0.021600384335853203\n",
      "train loss:0.04046818802903064\n",
      "train loss:0.10387462550269824\n",
      "train loss:0.04071323879537525\n",
      "train loss:0.051198969310647345\n",
      "train loss:0.033220141088353534\n",
      "train loss:0.07458426213156841\n",
      "train loss:0.02662540384154023\n",
      "train loss:0.06528628576809763\n",
      "train loss:0.10549049606470282\n",
      "train loss:0.017763988746464038\n",
      "train loss:0.11683090508885259\n",
      "train loss:0.019816303053524487\n",
      "=== epoch:5, train acc:0.974, test acc:0.95 ===\n",
      "train loss:0.08814972116202698\n",
      "train loss:0.04178262882594378\n",
      "train loss:0.02943503359080492\n",
      "train loss:0.02397849810268373\n",
      "train loss:0.02961728840821804\n",
      "train loss:0.03366587973231481\n",
      "train loss:0.047653537128393486\n",
      "train loss:0.07629492864730773\n",
      "train loss:0.02546787281060819\n",
      "train loss:0.05139061549441535\n",
      "train loss:0.06677712626440319\n",
      "train loss:0.047024299142034404\n",
      "train loss:0.09503244155525531\n",
      "train loss:0.1470946574100951\n",
      "train loss:0.07248198268075623\n",
      "train loss:0.04555621413708034\n",
      "train loss:0.04909784297932717\n",
      "train loss:0.07263332520544231\n",
      "train loss:0.00894799110509315\n",
      "train loss:0.0934143221823725\n",
      "train loss:0.05832918841225777\n",
      "train loss:0.12072559906689286\n",
      "train loss:0.05907515279798937\n",
      "train loss:0.15256410788704078\n",
      "train loss:0.02077856423424328\n",
      "train loss:0.09097010613097607\n",
      "train loss:0.08554046550466918\n",
      "train loss:0.03242161270904763\n",
      "train loss:0.012483290346850388\n",
      "train loss:0.10966034996382076\n",
      "train loss:0.048916703108929066\n",
      "train loss:0.06305859162818275\n",
      "train loss:0.08795107612996649\n",
      "train loss:0.0943573320097757\n",
      "train loss:0.03374053471221677\n",
      "train loss:0.040698649450060416\n",
      "train loss:0.030908716428640345\n",
      "train loss:0.08928035884424391\n",
      "train loss:0.07485009799463997\n",
      "train loss:0.10232427327640452\n",
      "train loss:0.0786254040944489\n",
      "train loss:0.037145723662616974\n",
      "train loss:0.06268644565989448\n",
      "train loss:0.028668566441315022\n",
      "train loss:0.0662214999930089\n",
      "train loss:0.047144707670224634\n",
      "train loss:0.03683592730357316\n",
      "train loss:0.035516126062107654\n",
      "train loss:0.03535785254803299\n",
      "train loss:0.024471166334092822\n",
      "=== epoch:6, train acc:0.978, test acc:0.954 ===\n",
      "train loss:0.028532219775959867\n",
      "train loss:0.05985760773922007\n",
      "train loss:0.052814326137903225\n",
      "train loss:0.03552562481499654\n",
      "train loss:0.057691091015423274\n",
      "train loss:0.016149776247896527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.055350622966058305\n",
      "train loss:0.061559785602858755\n",
      "train loss:0.07570177454813816\n",
      "train loss:0.03527629643184575\n",
      "train loss:0.03994957737385847\n",
      "train loss:0.049155847416834667\n",
      "train loss:0.04236440834500197\n",
      "train loss:0.04414321367295344\n",
      "train loss:0.0199141769495505\n",
      "train loss:0.069705136292936\n",
      "train loss:0.09153629913305802\n",
      "train loss:0.10639156023163053\n",
      "train loss:0.03356025696861389\n",
      "train loss:0.05222151847599558\n",
      "train loss:0.10517701738391541\n",
      "train loss:0.04982806448233392\n",
      "train loss:0.05405579227899453\n",
      "train loss:0.061078115166987156\n",
      "train loss:0.03547090641013495\n",
      "train loss:0.038320859162651336\n",
      "train loss:0.03661968164895697\n",
      "train loss:0.034475032254164845\n",
      "train loss:0.03713199769362042\n",
      "train loss:0.03330099047308943\n",
      "train loss:0.02557587266880699\n",
      "train loss:0.014043097520604168\n",
      "train loss:0.010952388880740106\n",
      "train loss:0.03016834964156847\n",
      "train loss:0.0318937296745252\n",
      "train loss:0.05816554598397982\n",
      "train loss:0.05152061782189967\n",
      "train loss:0.025867056729892292\n",
      "train loss:0.022685079931863212\n",
      "train loss:0.01956629581328646\n",
      "train loss:0.03306451429646007\n",
      "train loss:0.01285567803784144\n",
      "train loss:0.03880320361706241\n",
      "train loss:0.04604323494120159\n",
      "train loss:0.05219937858322102\n",
      "train loss:0.07493850282697884\n",
      "train loss:0.01981720125420064\n",
      "train loss:0.029455118981337666\n",
      "train loss:0.028953807910871866\n",
      "train loss:0.014224765104769284\n",
      "=== epoch:7, train acc:0.979, test acc:0.95 ===\n",
      "train loss:0.014339235369992022\n",
      "train loss:0.018969780013067237\n",
      "train loss:0.016493558752112714\n",
      "train loss:0.0471117164736939\n",
      "train loss:0.03127746341139275\n",
      "train loss:0.014674827103327997\n",
      "train loss:0.04721760940493569\n",
      "train loss:0.01203561375754456\n",
      "train loss:0.058549965189322734\n",
      "train loss:0.042382735636197155\n",
      "train loss:0.04252466584130394\n",
      "train loss:0.03135496748963076\n",
      "train loss:0.03847593571560608\n",
      "train loss:0.006835696939948098\n",
      "train loss:0.04289924662676304\n",
      "train loss:0.029959751986901803\n",
      "train loss:0.01499272795693416\n",
      "train loss:0.05289668275134114\n",
      "train loss:0.08867873385637763\n",
      "train loss:0.018057051569921812\n",
      "train loss:0.005304606977795062\n",
      "train loss:0.09211637934605095\n",
      "train loss:0.02399883536494694\n",
      "train loss:0.023877516258337405\n",
      "train loss:0.011883018371409421\n",
      "train loss:0.014395807431474741\n",
      "train loss:0.053592635274588754\n",
      "train loss:0.03011747679045281\n",
      "train loss:0.031554701184966165\n",
      "train loss:0.02008009144040029\n",
      "train loss:0.015167095164469593\n",
      "train loss:0.03636523016777642\n",
      "train loss:0.045035739074776454\n",
      "train loss:0.009301091744261423\n",
      "train loss:0.06755958856108184\n",
      "train loss:0.017015304121707143\n",
      "train loss:0.017069608017191616\n",
      "train loss:0.03645814321745422\n",
      "train loss:0.0051150635635266225\n",
      "train loss:0.03807246339832346\n",
      "train loss:0.07319088233420964\n",
      "train loss:0.004803690408741423\n",
      "train loss:0.020922879668018594\n",
      "train loss:0.08490242901562864\n",
      "train loss:0.013802465776746532\n",
      "train loss:0.013167270769600845\n",
      "train loss:0.018221285581814583\n",
      "train loss:0.030247283224910593\n",
      "train loss:0.013460162006552106\n",
      "train loss:0.017566691628969143\n",
      "=== epoch:8, train acc:0.991, test acc:0.955 ===\n",
      "train loss:0.028746002469701208\n",
      "train loss:0.017850898826553004\n",
      "train loss:0.018333992602486658\n",
      "train loss:0.03969362687559386\n",
      "train loss:0.010000647215617782\n",
      "train loss:0.015941852902602253\n",
      "train loss:0.019378132912970327\n",
      "train loss:0.01382729614061675\n",
      "train loss:0.07524613592296496\n",
      "train loss:0.024656482034329453\n",
      "train loss:0.022691851403299212\n",
      "train loss:0.011054928429738244\n",
      "train loss:0.01791753045270786\n",
      "train loss:0.013344862543019498\n",
      "train loss:0.041459797458311964\n",
      "train loss:0.03139269440907308\n",
      "train loss:0.019924935991963356\n",
      "train loss:0.009222075935747918\n",
      "train loss:0.01282593036351795\n",
      "train loss:0.032022206339634936\n",
      "train loss:0.027743451191874473\n",
      "train loss:0.00927407576783406\n",
      "train loss:0.014544575002227564\n",
      "train loss:0.005915764174706306\n",
      "train loss:0.014629509309350702\n",
      "train loss:0.023292719365649958\n",
      "train loss:0.012929589384852598\n",
      "train loss:0.012422839701654491\n",
      "train loss:0.05170716543594495\n",
      "train loss:0.008909113083464712\n",
      "train loss:0.010614232684057137\n",
      "train loss:0.012140990446132285\n",
      "train loss:0.009274895796551844\n",
      "train loss:0.01562647546283325\n",
      "train loss:0.009596912299747603\n",
      "train loss:0.0593225977391279\n",
      "train loss:0.04774985934763186\n",
      "train loss:0.010673026333494779\n",
      "train loss:0.011011073695867346\n",
      "train loss:0.011340452097881369\n",
      "train loss:0.018888818048082658\n",
      "train loss:0.0460087633164637\n",
      "train loss:0.009017985556377476\n",
      "train loss:0.004999658108521655\n",
      "train loss:0.04413220625889335\n",
      "train loss:0.005983895488375455\n",
      "train loss:0.009905446385118331\n",
      "train loss:0.02605621080061594\n",
      "train loss:0.01138096329482057\n",
      "train loss:0.019069715344557668\n",
      "=== epoch:9, train acc:0.995, test acc:0.963 ===\n",
      "train loss:0.0037807906121316605\n",
      "train loss:0.03648524661550815\n",
      "train loss:0.005716561787055647\n",
      "train loss:0.020204658545630742\n",
      "train loss:0.008021305574825322\n",
      "train loss:0.007710736522510502\n",
      "train loss:0.06693329543037724\n",
      "train loss:0.007237763749843813\n",
      "train loss:0.06518866330657676\n",
      "train loss:0.012570105186422258\n",
      "train loss:0.03700330767032615\n",
      "train loss:0.003799037183916936\n",
      "train loss:0.021227706118042623\n",
      "train loss:0.03870940368104034\n",
      "train loss:0.02905912248683622\n",
      "train loss:0.02901805167992542\n",
      "train loss:0.01803868375255727\n",
      "train loss:0.022784333501004738\n",
      "train loss:0.03270782226896749\n",
      "train loss:0.03383761218879932\n",
      "train loss:0.023131648617682944\n",
      "train loss:0.010239469625589017\n",
      "train loss:0.020230515407985736\n",
      "train loss:0.006517291816176438\n",
      "train loss:0.03303074816275604\n",
      "train loss:0.017259146473508756\n",
      "train loss:0.008408820194557097\n",
      "train loss:0.029247927368984728\n",
      "train loss:0.018745257857546965\n",
      "train loss:0.016291494867908457\n",
      "train loss:0.011292134309818751\n",
      "train loss:0.015514037364193283\n",
      "train loss:0.02083817164745852\n",
      "train loss:0.004893268740115533\n",
      "train loss:0.01817570653924624\n",
      "train loss:0.017159945318520373\n",
      "train loss:0.015896583926674035\n",
      "train loss:0.0033032865860443076\n",
      "train loss:0.007715750498308474\n",
      "train loss:0.007496461923901072\n",
      "train loss:0.005326615858508854\n",
      "train loss:0.00381810819371106\n",
      "train loss:0.019431417567361463\n",
      "train loss:0.00299178290496531\n",
      "train loss:0.023548104647065016\n",
      "train loss:0.010124686328921734\n",
      "train loss:0.02077200858253316\n",
      "train loss:0.03203957639532255\n",
      "train loss:0.007135580062146502\n",
      "train loss:0.03547901563866232\n",
      "=== epoch:10, train acc:0.994, test acc:0.961 ===\n",
      "train loss:0.005054443326181938\n",
      "train loss:0.03063409265326416\n",
      "train loss:0.02498331612703527\n",
      "train loss:0.01158674530682548\n",
      "train loss:0.017740494245979743\n",
      "train loss:0.01573509602476936\n",
      "train loss:0.0047359182093819965\n",
      "train loss:0.02047121266078454\n",
      "train loss:0.020738263094912942\n",
      "train loss:0.006168633224005679\n",
      "train loss:0.003819162856714785\n",
      "train loss:0.008725500678694717\n",
      "train loss:0.016716441976547296\n",
      "train loss:0.017343255608933107\n",
      "train loss:0.014947572064989565\n",
      "train loss:0.01924351804553113\n",
      "train loss:0.005726186442529615\n",
      "train loss:0.008871682104171531\n",
      "train loss:0.013246943452846051\n",
      "train loss:0.0033131853832887633\n",
      "train loss:0.009429646848892493\n",
      "train loss:0.00467623290183764\n",
      "train loss:0.0206897426785359\n",
      "train loss:0.01190174320986937\n",
      "train loss:0.013685940139428525\n",
      "train loss:0.016538162471747248\n",
      "train loss:0.013892463024204414\n",
      "train loss:0.012391510306576575\n",
      "train loss:0.01540494802894435\n",
      "train loss:0.006697939512774189\n",
      "train loss:0.008018230241331742\n",
      "train loss:0.011097539735994389\n",
      "train loss:0.005389194826702935\n",
      "train loss:0.01181010579971104\n",
      "train loss:0.004653329876410549\n",
      "train loss:0.00648288703303247\n",
      "train loss:0.01603900235899962\n",
      "train loss:0.012795556400240115\n",
      "train loss:0.002872765449358218\n",
      "train loss:0.015314210285350991\n",
      "train loss:0.006398764656370288\n",
      "train loss:0.009999010880058872\n",
      "train loss:0.013007441916952607\n",
      "train loss:0.006168410671752821\n",
      "train loss:0.0011681122546838203\n",
      "train loss:0.009966666606116286\n",
      "train loss:0.006146267658318224\n",
      "train loss:0.010017349196378611\n",
      "train loss:0.0019658955588883215\n",
      "train loss:0.0036868102216158116\n",
      "=== epoch:11, train acc:0.997, test acc:0.957 ===\n",
      "train loss:0.017588627597387153\n",
      "train loss:0.013207573189716033\n",
      "train loss:0.0034435550085221882\n",
      "train loss:0.017666459150575\n",
      "train loss:0.006907854527760591\n",
      "train loss:0.0022052386981157627\n",
      "train loss:0.004587338971699462\n",
      "train loss:0.012540329960465814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006297228117682773\n",
      "train loss:0.017441101971472476\n",
      "train loss:0.003949947416688145\n",
      "train loss:0.0029750660871111236\n",
      "train loss:0.007475399663226288\n",
      "train loss:0.0018328893069304271\n",
      "train loss:0.0028976076210781576\n",
      "train loss:0.014363861292922527\n",
      "train loss:0.002802284079137668\n",
      "train loss:0.009507850675140369\n",
      "train loss:0.01006397109458976\n",
      "train loss:0.006142479152238412\n",
      "train loss:0.014472190812820862\n",
      "train loss:0.0017815401875175129\n",
      "train loss:0.014572704852382372\n",
      "train loss:0.002490088357605906\n",
      "train loss:0.0027584988304501703\n",
      "train loss:0.007330455317425583\n",
      "train loss:0.004655663419881206\n",
      "train loss:0.007858661812565048\n",
      "train loss:0.005713790494002176\n",
      "train loss:0.002473117099587843\n",
      "train loss:0.010791528606150508\n",
      "train loss:0.003540632664846501\n",
      "train loss:0.0016440320488003183\n",
      "train loss:0.007156225717552204\n",
      "train loss:0.0009676514049788972\n",
      "train loss:0.0020487029330563825\n",
      "train loss:0.011277430296344178\n",
      "train loss:0.007707084926078224\n",
      "train loss:0.0012701084159244447\n",
      "train loss:0.0019460029523350464\n",
      "train loss:0.004785404293019505\n",
      "train loss:0.002800133829004449\n",
      "train loss:0.009243140349273595\n",
      "train loss:0.001890541581234237\n",
      "train loss:0.005864137494977861\n",
      "train loss:0.0017044248080651373\n",
      "train loss:0.02257670824777751\n",
      "train loss:0.004310404602604474\n",
      "train loss:0.008253464174168453\n",
      "train loss:0.0030634723629385\n",
      "=== epoch:12, train acc:0.999, test acc:0.964 ===\n",
      "train loss:0.0019509953561684292\n",
      "train loss:0.006000714681052073\n",
      "train loss:0.002689976535152514\n",
      "train loss:0.0076125498557205705\n",
      "train loss:0.004450064289499842\n",
      "train loss:0.006644463514035867\n",
      "train loss:0.007513092491580724\n",
      "train loss:0.003355566900149435\n",
      "train loss:0.0030984581084428074\n",
      "train loss:0.0009288394242020348\n",
      "train loss:0.0023974374312844666\n",
      "train loss:0.0023918695216526152\n",
      "train loss:0.0013760317253411335\n",
      "train loss:0.0017272064094929825\n",
      "train loss:0.012067658664579317\n",
      "train loss:0.001572060801910652\n",
      "train loss:0.0037309168129123255\n",
      "train loss:0.008561506015294366\n",
      "train loss:0.002092665374604518\n",
      "train loss:0.0033483622590427075\n",
      "train loss:0.010775669912904214\n",
      "train loss:0.003108092883087717\n",
      "train loss:0.0023812889028213377\n",
      "train loss:0.0015253280592954824\n",
      "train loss:0.0035063755820478604\n",
      "train loss:0.0009922132587653612\n",
      "train loss:0.00458884171469955\n",
      "train loss:0.0018682697965840644\n",
      "train loss:0.004771819396300252\n",
      "train loss:0.00430678566968644\n",
      "train loss:0.006249705377435729\n",
      "train loss:0.0014021702880155128\n",
      "train loss:0.0029579577199897555\n",
      "train loss:0.0018776290372568656\n",
      "train loss:0.0019456247048236733\n",
      "train loss:0.0029656430537408534\n",
      "train loss:0.00268821001869264\n",
      "train loss:0.004426174646403492\n",
      "train loss:0.0023303882344894843\n",
      "train loss:0.007288125181705439\n",
      "train loss:0.0015037703223698354\n",
      "train loss:0.003869549345469001\n",
      "train loss:0.010033334092321626\n",
      "train loss:0.0014310294446873944\n",
      "train loss:0.0030620790918948694\n",
      "train loss:0.0020835119098180656\n",
      "train loss:0.010287264825397466\n",
      "train loss:0.002124885987140715\n",
      "train loss:0.002864284087297852\n",
      "train loss:0.004658619322873093\n",
      "=== epoch:13, train acc:0.998, test acc:0.964 ===\n",
      "train loss:0.0013250450189276587\n",
      "train loss:0.005033577601702277\n",
      "train loss:0.0007205788426543402\n",
      "train loss:0.0017514792041325227\n",
      "train loss:0.010135787671934236\n",
      "train loss:0.007179909665564584\n",
      "train loss:0.0006779186376689553\n",
      "train loss:0.004475510112036531\n",
      "train loss:0.006503149210060719\n",
      "train loss:0.003277271297263991\n",
      "train loss:0.003536201790117769\n",
      "train loss:0.011901980670793465\n",
      "train loss:0.00870594604932361\n",
      "train loss:0.0013277677880092755\n",
      "train loss:0.0022036037010450043\n",
      "train loss:0.004761126145396069\n",
      "train loss:0.005948606588773294\n",
      "train loss:0.010228716764037417\n",
      "train loss:0.0027225658554511593\n",
      "train loss:0.000665861812051929\n",
      "train loss:0.0031096112170966796\n",
      "train loss:0.005784912657424305\n",
      "train loss:0.0025461176160802845\n",
      "train loss:0.003696421140553263\n",
      "train loss:0.0028749829460651692\n",
      "train loss:0.001448425781577117\n",
      "train loss:0.0035674790198825658\n",
      "train loss:0.010767724020936554\n",
      "train loss:0.0022137893899601907\n",
      "train loss:0.005693043291909895\n",
      "train loss:0.006895793346767815\n",
      "train loss:0.00178727995015545\n",
      "train loss:0.000988499290482905\n",
      "train loss:0.0016953639328696785\n",
      "train loss:0.0017211435262834728\n",
      "train loss:0.0031588845792009106\n",
      "train loss:0.0014654148411518942\n",
      "train loss:0.00605546473319651\n",
      "train loss:0.003773180074505226\n",
      "train loss:0.003695128784175264\n",
      "train loss:0.0026345257279776313\n",
      "train loss:0.0021785759698681618\n",
      "train loss:0.00048798808353784024\n",
      "train loss:0.00608277145697787\n",
      "train loss:0.0033903587858882594\n",
      "train loss:0.003337199352435615\n",
      "train loss:0.0011075766896243347\n",
      "train loss:0.0023899928493129794\n",
      "train loss:0.00588237747505953\n",
      "train loss:0.0003732029606742017\n",
      "=== epoch:14, train acc:0.998, test acc:0.964 ===\n",
      "train loss:0.0068861943551908065\n",
      "train loss:0.003938452642386016\n",
      "train loss:0.0018611673895692728\n",
      "train loss:0.008518012623003026\n",
      "train loss:0.003057588138135043\n",
      "train loss:0.001828905384374978\n",
      "train loss:0.006962835084299287\n",
      "train loss:0.00207186893833671\n",
      "train loss:0.003563539872337584\n",
      "train loss:0.006118099612461101\n",
      "train loss:0.002833370513571268\n",
      "train loss:0.0021908875386990275\n",
      "train loss:0.005099746498585842\n",
      "train loss:0.004773364574433468\n",
      "train loss:0.00248437673492454\n",
      "train loss:0.001683057063705863\n",
      "train loss:0.001950727411999988\n",
      "train loss:0.001799109021746189\n",
      "train loss:0.0014536826134995654\n",
      "train loss:0.0014040754517080725\n",
      "train loss:0.0016656088258663532\n",
      "train loss:0.0007156016416274978\n",
      "train loss:0.0015481672281046108\n",
      "train loss:0.0016876503250325685\n",
      "train loss:0.0018588258600668924\n",
      "train loss:0.007969190321628284\n",
      "train loss:0.006036270578139637\n",
      "train loss:0.002065910223959571\n",
      "train loss:0.0031059774283393555\n",
      "train loss:0.0007375154063103469\n",
      "train loss:0.000838995168811435\n",
      "train loss:0.004182728884875962\n",
      "train loss:0.0032080040509031675\n",
      "train loss:0.007583355425417871\n",
      "train loss:0.0009637602852867891\n",
      "train loss:0.0014077909168382688\n",
      "train loss:0.0016390604145153109\n",
      "train loss:0.004458142330141468\n",
      "train loss:0.001750561656701335\n",
      "train loss:0.0021010052166410068\n",
      "train loss:0.0005246922910294566\n",
      "train loss:0.0016575373755861752\n",
      "train loss:0.0009431761354536389\n",
      "train loss:0.003452099979943426\n",
      "train loss:0.0022475874781936246\n",
      "train loss:0.005712850881408357\n",
      "train loss:0.00034638700643049554\n",
      "train loss:0.0005019007882153072\n",
      "train loss:0.0026673015362985203\n",
      "train loss:0.001183038579951664\n",
      "=== epoch:15, train acc:0.999, test acc:0.969 ===\n",
      "train loss:0.004014940544795007\n",
      "train loss:0.0006925765661670253\n",
      "train loss:0.0028114475499120884\n",
      "train loss:0.0003368245900243664\n",
      "train loss:0.0026356709793462496\n",
      "train loss:0.0018539444494651035\n",
      "train loss:0.0056510525099675735\n",
      "train loss:0.00115062828669724\n",
      "train loss:0.002935708892609608\n",
      "train loss:0.0008915700514733193\n",
      "train loss:0.0041428084445800095\n",
      "train loss:0.002091815709139361\n",
      "train loss:0.004114057787952591\n",
      "train loss:0.0019025553324582456\n",
      "train loss:0.0003106043417108902\n",
      "train loss:0.004716836828484133\n",
      "train loss:0.0025598044069126053\n",
      "train loss:0.0040553653270797374\n",
      "train loss:0.0016724585197411697\n",
      "train loss:0.0016249236769451544\n",
      "train loss:0.0005725555279758634\n",
      "train loss:0.0035666818343775943\n",
      "train loss:0.0024123663797549237\n",
      "train loss:0.003065513072347777\n",
      "train loss:0.0013479018266667833\n",
      "train loss:0.011217237098181095\n",
      "train loss:0.0013493649010944727\n",
      "train loss:0.0012449704081433836\n",
      "train loss:0.0024902468420338175\n",
      "train loss:0.0009496618294732678\n",
      "train loss:0.0029001955436935155\n",
      "train loss:0.0030837436524604332\n",
      "train loss:0.0010152867456529454\n",
      "train loss:0.00042508134063080314\n",
      "train loss:0.002250503844013102\n",
      "train loss:0.0015363618963843651\n",
      "train loss:0.0019149404876289949\n",
      "train loss:0.0020395605626782674\n",
      "train loss:0.0015551987357265479\n",
      "train loss:0.0020854010588722974\n",
      "train loss:0.001320883965577815\n",
      "train loss:0.0017268171171619352\n",
      "train loss:0.0015611113587656383\n",
      "train loss:0.003023646527306713\n",
      "train loss:0.0028462266406396332\n",
      "train loss:0.005565509214984824\n",
      "train loss:0.001462111881001169\n",
      "train loss:0.0006830669653432621\n",
      "train loss:0.001554532812498529\n",
      "train loss:0.0008094855442757864\n",
      "=== epoch:16, train acc:0.999, test acc:0.961 ===\n",
      "train loss:0.0018412829428867611\n",
      "train loss:0.0031996501645402938\n",
      "train loss:0.006210555830744405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0012083813500578806\n",
      "train loss:0.004721931464091941\n",
      "train loss:0.0032384287509186534\n",
      "train loss:0.0015141893477918123\n",
      "train loss:0.001013684737673888\n",
      "train loss:0.0013367029406592464\n",
      "train loss:0.0011413398167859526\n",
      "train loss:0.001709309650319249\n",
      "train loss:0.0009842459991290962\n",
      "train loss:0.0011475466777273245\n",
      "train loss:0.0017186793159325927\n",
      "train loss:0.001562751996534726\n",
      "train loss:0.0014541219028455785\n",
      "train loss:0.0019743594736837495\n",
      "train loss:0.0016892678527379113\n",
      "train loss:0.0034262500695074914\n",
      "train loss:0.0014988982532689705\n",
      "train loss:0.00217080086437352\n",
      "train loss:0.0020942654803525257\n",
      "train loss:0.0012175514381804493\n",
      "train loss:0.0006770141841459956\n",
      "train loss:0.0007882304520846802\n",
      "train loss:0.00041877525831790415\n",
      "train loss:0.000787478551633367\n",
      "train loss:0.000851595444412101\n",
      "train loss:0.0008189789406768678\n",
      "train loss:0.00023093950035566512\n",
      "train loss:0.0014864396582050816\n",
      "train loss:0.0018204826980889736\n",
      "train loss:0.001081291153625273\n",
      "train loss:0.0011014522238881827\n",
      "train loss:0.0009241120189777314\n",
      "train loss:0.002200162106009727\n",
      "train loss:0.0005553729658191211\n",
      "train loss:0.00037382050324872863\n",
      "train loss:0.0008235997764289844\n",
      "train loss:0.0005169707830995348\n",
      "train loss:0.0003425206848139709\n",
      "train loss:0.0006651422493556386\n",
      "train loss:0.003101482918499323\n",
      "train loss:0.0006383124401673094\n",
      "train loss:0.00017919508051249144\n",
      "train loss:0.0003152012164523563\n",
      "train loss:0.0031667514661114717\n",
      "train loss:0.0013814593868235437\n",
      "train loss:0.001198342039025788\n",
      "train loss:0.0022441903003439035\n",
      "=== epoch:17, train acc:1.0, test acc:0.964 ===\n",
      "train loss:0.0011932221478223445\n",
      "train loss:0.00013908773974376693\n",
      "train loss:0.0014213455466844287\n",
      "train loss:0.0019472430043791524\n",
      "train loss:0.0012007962345244672\n",
      "train loss:0.0011593944621504934\n",
      "train loss:0.000424426812141743\n",
      "train loss:0.0008684532610370098\n",
      "train loss:0.00019116128631000744\n",
      "train loss:0.0008898980002293135\n",
      "train loss:0.0006355790379419077\n",
      "train loss:0.00023679968562366697\n",
      "train loss:0.0007276110745326939\n",
      "train loss:0.000889539790917247\n",
      "train loss:0.0007136414018528474\n",
      "train loss:0.0008467143969032925\n",
      "train loss:0.0020215422433578754\n",
      "train loss:0.000785401844661754\n",
      "train loss:0.00041800980302262344\n",
      "train loss:0.001609767294825269\n",
      "train loss:0.0003150491911819212\n",
      "train loss:0.0012713901080217526\n",
      "train loss:0.0007421214823269928\n",
      "train loss:0.0010836698430285662\n",
      "train loss:0.0012850101991890692\n",
      "train loss:0.0007460010478468426\n",
      "train loss:0.0012951296272368977\n",
      "train loss:0.0009491973308112368\n",
      "train loss:0.0004156429856351455\n",
      "train loss:0.0005358463079893832\n",
      "train loss:0.0009671248589894919\n",
      "train loss:0.0010429613395104783\n",
      "train loss:0.0005820545673650045\n",
      "train loss:0.00013313863547113802\n",
      "train loss:0.0009614062004642363\n",
      "train loss:0.0001882886912295732\n",
      "train loss:0.0003915960523602931\n",
      "train loss:0.00015909842078328282\n",
      "train loss:0.0002491533961279651\n",
      "train loss:0.0002588154499027263\n",
      "train loss:0.0007862473435967363\n",
      "train loss:0.0001778080685451722\n",
      "train loss:0.000254498054811097\n",
      "train loss:0.001149642784632523\n",
      "train loss:0.0004272896063992248\n",
      "train loss:0.0009555672179638849\n",
      "train loss:0.00195642299891685\n",
      "train loss:0.0003383295233933007\n",
      "train loss:0.0003757452175646887\n",
      "train loss:0.0005964137875950216\n",
      "=== epoch:18, train acc:1.0, test acc:0.965 ===\n",
      "train loss:0.00028396682858347394\n",
      "train loss:0.0007655748560345878\n",
      "train loss:0.0004727291539629196\n",
      "train loss:0.0005340989317486171\n",
      "train loss:0.0003077365882305084\n",
      "train loss:0.000280381875970273\n",
      "train loss:0.0004867590584790149\n",
      "train loss:0.0011701964769696427\n",
      "train loss:0.0005882388488389641\n",
      "train loss:0.0004777331513819172\n",
      "train loss:4.918070150553987e-05\n",
      "train loss:0.0005202517768499964\n",
      "train loss:0.0003699874909006143\n",
      "train loss:0.001134769407006884\n",
      "train loss:0.00034086061881797805\n",
      "train loss:0.00017622819032682945\n",
      "train loss:0.0006752328058663579\n",
      "train loss:0.00019540482291989237\n",
      "train loss:0.00041099124945929543\n",
      "train loss:0.00023083685177679585\n",
      "train loss:0.00034451502191607913\n",
      "train loss:0.00023087661725584692\n",
      "train loss:0.0002790532891823967\n",
      "train loss:0.00028674487723079627\n",
      "train loss:0.0005939535895727654\n",
      "train loss:0.0008686977806763353\n",
      "train loss:0.0003564744814565458\n",
      "train loss:9.236750304209225e-05\n",
      "train loss:0.0005913788853363738\n",
      "train loss:0.000311368101719238\n",
      "train loss:0.00040932974998908694\n",
      "train loss:0.0006467723081735039\n",
      "train loss:0.0001593971393732421\n",
      "train loss:0.00037889002284030804\n",
      "train loss:0.0004700313062283956\n",
      "train loss:0.0016624496616944766\n",
      "train loss:0.0007986456584847153\n",
      "train loss:0.0009447714672785942\n",
      "train loss:0.0007360935914793908\n",
      "train loss:0.00027075560171443784\n",
      "train loss:5.371695999568244e-05\n",
      "train loss:0.00041272764280251786\n",
      "train loss:0.0007227043594252065\n",
      "train loss:0.0003240467117311157\n",
      "train loss:0.0004772829516457432\n",
      "train loss:0.0007498204672429206\n",
      "train loss:0.0003651302936353537\n",
      "train loss:0.00019177211499731155\n",
      "train loss:0.00034480733940940063\n",
      "train loss:0.0004994275453584668\n",
      "=== epoch:19, train acc:1.0, test acc:0.965 ===\n",
      "train loss:0.0005916578451885223\n",
      "train loss:0.00024745066058859036\n",
      "train loss:0.0005446905916611644\n",
      "train loss:0.0003405654018248241\n",
      "train loss:0.0001916394766441519\n",
      "train loss:0.00016505285928246544\n",
      "train loss:0.0004742388802184399\n",
      "train loss:0.0005457080306200124\n",
      "train loss:0.00029214568613744016\n",
      "train loss:0.0003982928145824055\n",
      "train loss:0.0004497069921442706\n",
      "train loss:0.0003057025030810822\n",
      "train loss:0.00012975077392745214\n",
      "train loss:0.00019519551837856854\n",
      "train loss:0.00021843878231069913\n",
      "train loss:0.00011686668754003237\n",
      "train loss:0.0006962950661833754\n",
      "train loss:0.000405742388271948\n",
      "train loss:0.0004640590275341469\n",
      "train loss:0.00019812465565985292\n",
      "train loss:0.00034532423667250445\n",
      "train loss:0.0005490813350527574\n",
      "train loss:0.0003968171352669104\n",
      "train loss:0.0005414090193129189\n",
      "train loss:0.0005429895737523539\n",
      "train loss:0.00024845133019320824\n",
      "train loss:0.00018844942985031014\n",
      "train loss:0.00028992133603587627\n",
      "train loss:0.00023988658505003736\n",
      "train loss:0.0001485914188420672\n",
      "train loss:0.000132199537869778\n",
      "train loss:0.0003818944536183122\n",
      "train loss:0.00021404710967944725\n",
      "train loss:0.0003517736695728773\n",
      "train loss:0.0011029245334565646\n",
      "train loss:0.00035597195287278795\n",
      "train loss:0.0006057640799493484\n",
      "train loss:0.00026354674945055384\n",
      "train loss:0.00030220522793541896\n",
      "train loss:0.00016457361112506876\n",
      "train loss:0.00022430616114362027\n",
      "train loss:0.0003033925948081747\n",
      "train loss:0.0002551094473029219\n",
      "train loss:0.0003149557452510058\n",
      "train loss:0.0002897237221875787\n",
      "train loss:0.0001686401723601873\n",
      "train loss:0.0007905762851877088\n",
      "train loss:0.00021010553858236497\n",
      "train loss:0.00022809054997017817\n",
      "train loss:0.0005884320584556214\n",
      "=== epoch:20, train acc:1.0, test acc:0.964 ===\n",
      "train loss:0.000578175683431504\n",
      "train loss:0.00032429028941370196\n",
      "train loss:0.00030056650964324074\n",
      "train loss:0.00012414325287118843\n",
      "train loss:0.00012589521016725803\n",
      "train loss:0.00023074919961324483\n",
      "train loss:0.00031609978810228154\n",
      "train loss:0.0005034343567258365\n",
      "train loss:0.00014268186565659624\n",
      "train loss:0.0002642987059118891\n",
      "train loss:0.0006549310169966213\n",
      "train loss:0.00034596961048211897\n",
      "train loss:0.00013410332920563942\n",
      "train loss:0.0009822196682638508\n",
      "train loss:0.0005784473932422622\n",
      "train loss:0.00045012828936254705\n",
      "train loss:0.00024454272127067425\n",
      "train loss:0.00016575098688406494\n",
      "train loss:0.0005682800444448218\n",
      "train loss:0.0003129506304601553\n",
      "train loss:0.0004837894583779938\n",
      "train loss:0.00023078586866024056\n",
      "train loss:0.0002695790019482812\n",
      "train loss:0.0010368281080243408\n",
      "train loss:0.00016387383638147095\n",
      "train loss:0.0003468086248422083\n",
      "train loss:0.0002773473184378884\n",
      "train loss:0.0002864484062410089\n",
      "train loss:0.00017957213463324945\n",
      "train loss:0.00021831042611239286\n",
      "train loss:0.0003022649776788127\n",
      "train loss:0.00011950222737840512\n",
      "train loss:0.0004332995707773984\n",
      "train loss:0.00025746195079602097\n",
      "train loss:0.00021612566382324435\n",
      "train loss:0.0009063466301876599\n",
      "train loss:4.2274921023156534e-05\n",
      "train loss:0.0004074348119366475\n",
      "train loss:0.00014096945274521088\n",
      "train loss:0.00018602352947738102\n",
      "train loss:0.0002667460187398793\n",
      "train loss:0.00014821909154166677\n",
      "train loss:0.0006130105822440687\n",
      "train loss:0.00020992756576513661\n",
      "train loss:0.00044488581758353365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0008111332884630323\n",
      "train loss:6.391943737187893e-05\n",
      "train loss:0.00017342080537944456\n",
      "train loss:0.000558839978619379\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.968\n"
     ]
    }
   ],
   "source": [
    "network3 = TestConvNet3()\n",
    "trainer3 = Trainer(network3, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr':0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "\n",
    "trainer3.train()\n",
    "network3.save_params(\"params/test_convnet3_params.pkl\")\n",
    "\n",
    "with open(\"trainer3.pkl\", 'wb') as f:\n",
    "    pickle.dump(trainer3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e2bcd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.041828004693469\n",
      "=== epoch:1, train acc:0.147, test acc:0.151 ===\n",
      "train loss:1.869977004153955\n",
      "train loss:1.6857547173589977\n",
      "train loss:1.6711422763304453\n",
      "train loss:1.457368693135547\n",
      "train loss:1.2170449140686592\n",
      "train loss:1.0972152734666707\n",
      "train loss:1.0028233622778693\n",
      "train loss:0.742499060850539\n",
      "train loss:0.6021927724605802\n",
      "train loss:0.7617281908864422\n",
      "train loss:0.4966125634068472\n",
      "train loss:0.5687216003793677\n",
      "train loss:0.6466252840141058\n",
      "train loss:0.5903965291271597\n",
      "train loss:0.4788851155657077\n",
      "train loss:0.39749248739670107\n",
      "train loss:0.4386628932011327\n",
      "train loss:0.32281161036681527\n",
      "train loss:0.42397479410266414\n",
      "train loss:0.4899120318466851\n",
      "train loss:0.24205281638502416\n",
      "train loss:0.5420516465056098\n",
      "train loss:0.30856906233644577\n",
      "train loss:0.5064025166764072\n",
      "train loss:0.3544105770548604\n",
      "train loss:0.3050118119223852\n",
      "train loss:0.41770586877201843\n",
      "train loss:0.46132415669893917\n",
      "train loss:0.4376472086509156\n",
      "train loss:0.4571731285826243\n",
      "train loss:0.45306903609425603\n",
      "train loss:0.657226468593969\n",
      "train loss:0.4028730214199563\n",
      "train loss:0.46626398591991575\n",
      "train loss:0.29086457321453735\n",
      "train loss:0.3929192858745529\n",
      "train loss:0.2910202375974847\n",
      "train loss:0.2293982066636085\n",
      "train loss:0.25049676366722745\n",
      "train loss:0.21765461476186207\n",
      "train loss:0.29170294577812544\n",
      "train loss:0.2106632471303042\n",
      "train loss:0.2474836799575963\n",
      "train loss:0.2007733606463924\n",
      "train loss:0.28587399293840127\n",
      "train loss:0.16262740580473825\n",
      "train loss:0.20221794960237255\n",
      "train loss:0.2480590436563997\n",
      "train loss:0.1272282191977027\n",
      "train loss:0.29103047704323637\n",
      "=== epoch:2, train acc:0.914, test acc:0.891 ===\n",
      "train loss:0.3023418173963834\n",
      "train loss:0.4675064466232579\n",
      "train loss:0.27142144497551457\n",
      "train loss:0.16797566300290054\n",
      "train loss:0.3016231082852249\n",
      "train loss:0.12037989808464537\n",
      "train loss:0.3527044838163211\n",
      "train loss:0.1886692038737547\n",
      "train loss:0.1425075550824259\n",
      "train loss:0.27020831259804867\n",
      "train loss:0.2142299071734736\n",
      "train loss:0.21301899052401943\n",
      "train loss:0.2607652870343265\n",
      "train loss:0.17059458723242663\n",
      "train loss:0.12823578345878867\n",
      "train loss:0.2848195412957965\n",
      "train loss:0.21661777309963273\n",
      "train loss:0.19759007838758383\n",
      "train loss:0.2081216908524103\n",
      "train loss:0.17722602034385154\n",
      "train loss:0.3161919563533523\n",
      "train loss:0.09290155044546154\n",
      "train loss:0.12212835780781571\n",
      "train loss:0.21729574779605876\n",
      "train loss:0.23767445099960802\n",
      "train loss:0.17319128456477187\n",
      "train loss:0.11734118711935845\n",
      "train loss:0.07054383447117507\n",
      "train loss:0.20955665946543497\n",
      "train loss:0.17580448570201931\n",
      "train loss:0.1405693535616365\n",
      "train loss:0.1837164685270874\n",
      "train loss:0.12292102842513417\n",
      "train loss:0.1146034519798794\n",
      "train loss:0.20746534692290125\n",
      "train loss:0.07114261079038908\n",
      "train loss:0.0910684467152168\n",
      "train loss:0.09981141998415176\n",
      "train loss:0.10565085842184384\n",
      "train loss:0.11266983553679764\n",
      "train loss:0.21837254008542492\n",
      "train loss:0.2085951860724859\n",
      "train loss:0.06815839141067633\n",
      "train loss:0.1253066858039876\n",
      "train loss:0.05346658319631168\n",
      "train loss:0.13524520677016633\n",
      "train loss:0.04793881466221806\n",
      "train loss:0.09473173162574218\n",
      "train loss:0.08761859594438359\n",
      "train loss:0.1652567276738959\n",
      "=== epoch:3, train acc:0.95, test acc:0.916 ===\n",
      "train loss:0.16000357308119656\n",
      "train loss:0.22566132163860503\n",
      "train loss:0.06696385762106598\n",
      "train loss:0.1274000605740735\n",
      "train loss:0.06866268937045711\n",
      "train loss:0.12900047917399018\n",
      "train loss:0.13562495637582625\n",
      "train loss:0.07513530534764604\n",
      "train loss:0.0363118980300811\n",
      "train loss:0.2224283439952441\n",
      "train loss:0.10026630464417269\n",
      "train loss:0.09817318756433706\n",
      "train loss:0.05530379134395487\n",
      "train loss:0.08803534109606087\n",
      "train loss:0.16264750027199437\n",
      "train loss:0.08883868294523087\n",
      "train loss:0.07549909078009749\n",
      "train loss:0.14406642764681038\n",
      "train loss:0.04531909690288878\n",
      "train loss:0.06331110573239687\n",
      "train loss:0.13403089285043715\n",
      "train loss:0.08185291717188671\n",
      "train loss:0.07859533054740746\n",
      "train loss:0.06335791520053137\n",
      "train loss:0.1465833319017044\n",
      "train loss:0.18095574685196048\n",
      "train loss:0.08084704851009854\n",
      "train loss:0.04707447374551275\n",
      "train loss:0.06724518583034925\n",
      "train loss:0.06726779130395083\n",
      "train loss:0.04015834292607184\n",
      "train loss:0.041671303224461304\n",
      "train loss:0.06391140080906677\n",
      "train loss:0.023114559369932296\n",
      "train loss:0.14833497947186355\n",
      "train loss:0.0496352563957586\n",
      "train loss:0.074787875188984\n",
      "train loss:0.0647337535432228\n",
      "train loss:0.04044035094931411\n",
      "train loss:0.06611161620888206\n",
      "train loss:0.10678588706689399\n",
      "train loss:0.017552053470314865\n",
      "train loss:0.04406440406788329\n",
      "train loss:0.10810207448895101\n",
      "train loss:0.024987359554909924\n",
      "train loss:0.05527893642816188\n",
      "train loss:0.03556747282177057\n",
      "train loss:0.03713339861282509\n",
      "train loss:0.056631532259809186\n",
      "train loss:0.07045233668147284\n",
      "=== epoch:4, train acc:0.973, test acc:0.95 ===\n",
      "train loss:0.03663787311417067\n",
      "train loss:0.03076904976680701\n",
      "train loss:0.09177908412284375\n",
      "train loss:0.05649654173840191\n",
      "train loss:0.052712288889069904\n",
      "train loss:0.03492039458413604\n",
      "train loss:0.038009982621195905\n",
      "train loss:0.07018478763116558\n",
      "train loss:0.04535983796314229\n",
      "train loss:0.020076363695809098\n",
      "train loss:0.11930773103479715\n",
      "train loss:0.013625805649119027\n",
      "train loss:0.028186252402834584\n",
      "train loss:0.05453872027279615\n",
      "train loss:0.042833762233751134\n",
      "train loss:0.025151367994719925\n",
      "train loss:0.021315221186018158\n",
      "train loss:0.06919773824354067\n",
      "train loss:0.039116950140910746\n",
      "train loss:0.04995662754339789\n",
      "train loss:0.044519102348910565\n",
      "train loss:0.04997394421127861\n",
      "train loss:0.04639917414298325\n",
      "train loss:0.06276797637230061\n",
      "train loss:0.1709223784747643\n",
      "train loss:0.021985709372664516\n",
      "train loss:0.13966592394178476\n",
      "train loss:0.06965142792591\n",
      "train loss:0.1513131065304822\n",
      "train loss:0.05044370124123861\n",
      "train loss:0.031586722055734075\n",
      "train loss:0.0796346527909038\n",
      "train loss:0.030499525233665108\n",
      "train loss:0.031659746124483946\n",
      "train loss:0.05076082634397158\n",
      "train loss:0.06345598140556466\n",
      "train loss:0.04280926227066434\n",
      "train loss:0.046192696643712144\n",
      "train loss:0.07385899349028442\n",
      "train loss:0.06506942164147342\n",
      "train loss:0.08317689552999752\n",
      "train loss:0.05539068759103216\n",
      "train loss:0.024362930375415086\n",
      "train loss:0.031121894394082843\n",
      "train loss:0.03130508644459964\n",
      "train loss:0.06583564457736664\n",
      "train loss:0.02589559067392809\n",
      "train loss:0.12051407905737124\n",
      "train loss:0.025899735832780633\n",
      "train loss:0.02724948414939254\n",
      "=== epoch:5, train acc:0.978, test acc:0.952 ===\n",
      "train loss:0.020506494708959388\n",
      "train loss:0.04232040249705978\n",
      "train loss:0.034651081184440685\n",
      "train loss:0.02411900835234923\n",
      "train loss:0.10543066129311958\n",
      "train loss:0.023343264480607195\n",
      "train loss:0.03526703509253669\n",
      "train loss:0.010365698304439857\n",
      "train loss:0.06771496754996359\n",
      "train loss:0.0584041276860044\n",
      "train loss:0.013648516950737306\n",
      "train loss:0.04028098811266094\n",
      "train loss:0.0401083246920673\n",
      "train loss:0.11168058794734347\n",
      "train loss:0.019419195827810275\n",
      "train loss:0.05581774474613746\n",
      "train loss:0.055716649262828655\n",
      "train loss:0.026904168724538526\n",
      "train loss:0.010847939879605036\n",
      "train loss:0.041470746654296085\n",
      "train loss:0.03804041365291854\n",
      "train loss:0.05072241629308466\n",
      "train loss:0.01160098077044431\n",
      "train loss:0.023890942922510736\n",
      "train loss:0.010947176469597274\n",
      "train loss:0.04237712049924788\n",
      "train loss:0.013453463529765692\n",
      "train loss:0.03858747189899585\n",
      "train loss:0.07102543692698941\n",
      "train loss:0.023102973254370794\n",
      "train loss:0.021295473872858826\n",
      "train loss:0.015347913299429673\n",
      "train loss:0.013169460319328016\n",
      "train loss:0.018040877441802564\n",
      "train loss:0.0249460273653881\n",
      "train loss:0.02587764490801432\n",
      "train loss:0.03899232291062744\n",
      "train loss:0.011987278133882779\n",
      "train loss:0.03041671534974115\n",
      "train loss:0.03289261796005514\n",
      "train loss:0.02120267429745453\n",
      "train loss:0.008132686407939434\n",
      "train loss:0.026077843580741434\n",
      "train loss:0.02033881704509238\n",
      "train loss:0.045033336864045544\n",
      "train loss:0.04149750970791374\n",
      "train loss:0.0140342406621573\n",
      "train loss:0.03365678931038705\n",
      "train loss:0.05760806237348033\n",
      "train loss:0.02923337849908036\n",
      "=== epoch:6, train acc:0.979, test acc:0.946 ===\n",
      "train loss:0.016737317220211635\n",
      "train loss:0.009475995708165038\n",
      "train loss:0.011426088263670165\n",
      "train loss:0.037702752106636594\n",
      "train loss:0.02946024145794734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.026363571951131384\n",
      "train loss:0.004674947672017025\n",
      "train loss:0.03735470901824027\n",
      "train loss:0.02209869036702797\n",
      "train loss:0.02010606573040895\n",
      "train loss:0.03822539405194589\n",
      "train loss:0.007106242986662463\n",
      "train loss:0.021487925024825386\n",
      "train loss:0.008134057776592206\n",
      "train loss:0.013705269891420542\n",
      "train loss:0.012760413901457183\n",
      "train loss:0.005782665709479812\n",
      "train loss:0.02235565810275566\n",
      "train loss:0.014173068245305986\n",
      "train loss:0.0075499547982460545\n",
      "train loss:0.05081982657262865\n",
      "train loss:0.020840639877774812\n",
      "train loss:0.040044423575297\n",
      "train loss:0.02275033930986589\n",
      "train loss:0.013089490987164387\n",
      "train loss:0.006247663761789589\n",
      "train loss:0.004869338933322851\n",
      "train loss:0.0038668092786862825\n",
      "train loss:0.01964341537902928\n",
      "train loss:0.024303117324383824\n",
      "train loss:0.01973253354158236\n",
      "train loss:0.008091875254135244\n",
      "train loss:0.032420273401746684\n",
      "train loss:0.02884119150038262\n",
      "train loss:0.04631200570547569\n",
      "train loss:0.013683245642452808\n",
      "train loss:0.004767699795609971\n",
      "train loss:0.02203103742463928\n",
      "train loss:0.025742697951776437\n",
      "train loss:0.010301650007773113\n",
      "train loss:0.008478977276490513\n",
      "train loss:0.014964678773620461\n",
      "train loss:0.00831593722742131\n",
      "train loss:0.006429817991508291\n",
      "train loss:0.01578206401402839\n",
      "train loss:0.025799384745199862\n",
      "train loss:0.016948382403759964\n",
      "train loss:0.0445531563378407\n",
      "train loss:0.03887580662186435\n",
      "train loss:0.018045221837065976\n",
      "=== epoch:7, train acc:0.99, test acc:0.966 ===\n",
      "train loss:0.02142139875960106\n",
      "train loss:0.008827528891955939\n",
      "train loss:0.017096179714425275\n",
      "train loss:0.009885977473537226\n",
      "train loss:0.031380112105479745\n",
      "train loss:0.01644292416376605\n",
      "train loss:0.003564460802136686\n",
      "train loss:0.009478369358242405\n",
      "train loss:0.035131453344833335\n",
      "train loss:0.021859115631178545\n",
      "train loss:0.018089960921219728\n",
      "train loss:0.007441651080850359\n",
      "train loss:0.022905906322680546\n",
      "train loss:0.006581368743974371\n",
      "train loss:0.004776219543877451\n",
      "train loss:0.021013101303331904\n",
      "train loss:0.028511408304230317\n",
      "train loss:0.0200271838457655\n",
      "train loss:0.010213701744044219\n",
      "train loss:0.016102894487760092\n",
      "train loss:0.03324197488501158\n",
      "train loss:0.019755459771261044\n",
      "train loss:0.011111689695238468\n",
      "train loss:0.011398097819908559\n",
      "train loss:0.005188205706931739\n",
      "train loss:0.005806105170417453\n",
      "train loss:0.008161965087380296\n",
      "train loss:0.005840386649094642\n",
      "train loss:0.013800873992426885\n",
      "train loss:0.015115251144468983\n",
      "train loss:0.007887294119666356\n",
      "train loss:0.01132386069941487\n",
      "train loss:0.013692377720962025\n",
      "train loss:0.004022513434731683\n",
      "train loss:0.014637738916690752\n",
      "train loss:0.0057286966074127366\n",
      "train loss:0.0016689650797522713\n",
      "train loss:0.00229500905937052\n",
      "train loss:0.0089014526970258\n",
      "train loss:0.0200165283093783\n",
      "train loss:0.003870783565364181\n",
      "train loss:0.018801959312318536\n",
      "train loss:0.00981328618714007\n",
      "train loss:0.005866020001670933\n",
      "train loss:0.006930104807207154\n",
      "train loss:0.005146350841146543\n",
      "train loss:0.00908963429878376\n",
      "train loss:0.02942895230507716\n",
      "train loss:0.04730138491352383\n",
      "train loss:0.044290124474988125\n",
      "=== epoch:8, train acc:0.995, test acc:0.961 ===\n",
      "train loss:0.010505287729241322\n",
      "train loss:0.008629309886792651\n",
      "train loss:0.039465658270382266\n",
      "train loss:0.04409406061743108\n",
      "train loss:0.00508683848066492\n",
      "train loss:0.006532970719734078\n",
      "train loss:0.006065150107020092\n",
      "train loss:0.0088173958278701\n",
      "train loss:0.02039444323793741\n",
      "train loss:0.01473975785532702\n",
      "train loss:0.007398473945120327\n",
      "train loss:0.010839329475419013\n",
      "train loss:0.006084466064626677\n",
      "train loss:0.001662228133898603\n",
      "train loss:0.009645031093335161\n",
      "train loss:0.012133685824022147\n",
      "train loss:0.010531842001636678\n",
      "train loss:0.003529685469303763\n",
      "train loss:0.003379235925980217\n",
      "train loss:0.007391479268615002\n",
      "train loss:0.0060886953610244186\n",
      "train loss:0.0014452549489917435\n",
      "train loss:0.0026894404464786834\n",
      "train loss:0.005426186378060666\n",
      "train loss:0.0021658627321543998\n",
      "train loss:0.01484258964825763\n",
      "train loss:0.0017440724247102008\n",
      "train loss:0.002865409830065999\n",
      "train loss:0.006811900341136729\n",
      "train loss:0.014410752815942682\n",
      "train loss:0.013594073393533086\n",
      "train loss:0.0016618853720392938\n",
      "train loss:0.00349294263864617\n",
      "train loss:0.0068416983612077905\n",
      "train loss:0.013062040460944148\n",
      "train loss:0.007834101086359051\n",
      "train loss:0.004848650503446686\n",
      "train loss:0.022935917139603378\n",
      "train loss:0.01496406814757444\n",
      "train loss:0.008244728455130676\n",
      "train loss:0.005955180741611733\n",
      "train loss:0.0024655777067186997\n",
      "train loss:0.004902392544488027\n",
      "train loss:0.007867504022637162\n",
      "train loss:0.013331188357012717\n",
      "train loss:0.00923218620818412\n",
      "train loss:0.01470159476592247\n",
      "train loss:0.005214257398412546\n",
      "train loss:0.0051092781685838475\n",
      "train loss:0.02526685763247489\n",
      "=== epoch:9, train acc:0.994, test acc:0.956 ===\n",
      "train loss:0.01618057075869495\n",
      "train loss:0.0030514447232006642\n",
      "train loss:0.01369758717095957\n",
      "train loss:0.001953864610309793\n",
      "train loss:0.010165893699999455\n",
      "train loss:0.006895860829523413\n",
      "train loss:0.008457190067932115\n",
      "train loss:0.005541247348140707\n",
      "train loss:0.004921942505377374\n",
      "train loss:0.01482597699558756\n",
      "train loss:0.004966837299885489\n",
      "train loss:0.005409815421311541\n",
      "train loss:0.013383431473416776\n",
      "train loss:0.005921617778431622\n",
      "train loss:0.007352568602450648\n",
      "train loss:0.004190342232250254\n",
      "train loss:0.010048971506707386\n",
      "train loss:0.0008446271976398491\n",
      "train loss:0.014044086337132354\n",
      "train loss:0.004686808103177143\n",
      "train loss:0.001100360067158772\n",
      "train loss:0.002365108136848938\n",
      "train loss:0.004457930352721043\n",
      "train loss:0.002261930495716667\n",
      "train loss:0.0015009498267113857\n",
      "train loss:0.013615905870167956\n",
      "train loss:0.002233235607379375\n",
      "train loss:0.005826078518286163\n",
      "train loss:0.0015474507835891793\n",
      "train loss:0.015328444846172809\n",
      "train loss:0.008689562575852143\n",
      "train loss:0.007453846037220533\n",
      "train loss:0.003215424584551487\n",
      "train loss:0.0022651445784436777\n",
      "train loss:0.0010160339601656247\n",
      "train loss:0.0007471900756638256\n",
      "train loss:0.014731569758468333\n",
      "train loss:0.0032287795605959774\n",
      "train loss:0.002364528143226215\n",
      "train loss:0.0028538628557835282\n",
      "train loss:0.0049395944447522735\n",
      "train loss:0.004466612672528734\n",
      "train loss:0.006114382770668423\n",
      "train loss:0.0014734798209719393\n",
      "train loss:0.011427202071767116\n",
      "train loss:0.0009445530769370979\n",
      "train loss:0.001163100728115825\n",
      "train loss:0.002627897295446493\n",
      "train loss:0.006821667919760907\n",
      "train loss:0.004569559888306056\n",
      "=== epoch:10, train acc:0.997, test acc:0.962 ===\n",
      "train loss:0.0025134254309916574\n",
      "train loss:0.0017601060064493298\n",
      "train loss:0.002166018872574547\n",
      "train loss:0.0017816115551342417\n",
      "train loss:0.0002910986906353341\n",
      "train loss:0.0033506573581794387\n",
      "train loss:0.0027864599100351616\n",
      "train loss:0.005128450158624501\n",
      "train loss:0.008543723073718045\n",
      "train loss:0.007390046250560275\n",
      "train loss:0.0013797000666840812\n",
      "train loss:0.00466344099946659\n",
      "train loss:0.002214434291389728\n",
      "train loss:0.010879428580665585\n",
      "train loss:0.0023993207030339565\n",
      "train loss:0.0006464336105900309\n",
      "train loss:0.001207252406207471\n",
      "train loss:0.0012728539229655952\n",
      "train loss:0.0060372924514438256\n",
      "train loss:0.001976932313774441\n",
      "train loss:0.0012983689597999384\n",
      "train loss:0.00274907125387212\n",
      "train loss:0.0012096613978899045\n",
      "train loss:0.0019974288034927553\n",
      "train loss:0.00347704785670199\n",
      "train loss:0.0022718505456366888\n",
      "train loss:0.00027322476951080715\n",
      "train loss:0.0029665842640127418\n",
      "train loss:0.001699500002926732\n",
      "train loss:0.00245651903983318\n",
      "train loss:0.0019999035639832402\n",
      "train loss:0.006142552614197108\n",
      "train loss:0.0012949234659852039\n",
      "train loss:0.00011480288527022886\n",
      "train loss:0.0029689193142771035\n",
      "train loss:0.0039771841233414915\n",
      "train loss:0.001200406600484406\n",
      "train loss:0.0013976273896448618\n",
      "train loss:0.001320759360750027\n",
      "train loss:0.0018952090785899498\n",
      "train loss:0.0026134419575580842\n",
      "train loss:0.0008844780444434888\n",
      "train loss:0.0032155226103136062\n",
      "train loss:0.003057793836892307\n",
      "train loss:0.0045642181630489\n",
      "train loss:0.006073766644032209\n",
      "train loss:0.0028081812678524775\n",
      "train loss:0.0010352809084908806\n",
      "train loss:0.006944409907824653\n",
      "train loss:0.006348955292975378\n",
      "=== epoch:11, train acc:0.995, test acc:0.959 ===\n",
      "train loss:0.0021147309750490085\n",
      "train loss:0.0042856198175662205\n",
      "train loss:0.0009067889445570979\n",
      "train loss:0.0016364306195771566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002175582050965694\n",
      "train loss:0.00149897723128882\n",
      "train loss:0.001199721849712464\n",
      "train loss:0.0056286810117960155\n",
      "train loss:0.0017107445508697397\n",
      "train loss:0.0016325258551827223\n",
      "train loss:0.000884313119252942\n",
      "train loss:0.002760092220439975\n",
      "train loss:0.0010406708866848434\n",
      "train loss:0.0008647051895189637\n",
      "train loss:0.00041225188623663213\n",
      "train loss:0.002327591115658381\n",
      "train loss:0.0013202573493686907\n",
      "train loss:0.002538145412976649\n",
      "train loss:0.0064246877167654605\n",
      "train loss:0.00017276280850011868\n",
      "train loss:0.0028813783392615117\n",
      "train loss:0.0025179578480800996\n",
      "train loss:0.0009843194764788336\n",
      "train loss:0.0006665525439848452\n",
      "train loss:0.0023633364331894337\n",
      "train loss:0.002762115783262756\n",
      "train loss:0.0015152364402836707\n",
      "train loss:0.0012879826590363262\n",
      "train loss:0.0010628685305372914\n",
      "train loss:0.001792496067405006\n",
      "train loss:0.0013964316891837373\n",
      "train loss:0.0023209905514827134\n",
      "train loss:0.0020678729310841257\n",
      "train loss:0.0034427449966775926\n",
      "train loss:0.008642635694524526\n",
      "train loss:0.0046770800537971205\n",
      "train loss:0.009540401120160384\n",
      "train loss:0.0032629297726952454\n",
      "train loss:0.0022515678746773547\n",
      "train loss:0.0032685591265176842\n",
      "train loss:0.0006273502115304715\n",
      "train loss:0.006011065580138792\n",
      "train loss:0.005883396176832445\n",
      "train loss:0.004119995474071141\n",
      "train loss:0.0027455810865850373\n",
      "train loss:0.011277153935114938\n",
      "train loss:0.005834265491095991\n",
      "train loss:0.004350662166577414\n",
      "train loss:0.007595228302334083\n",
      "train loss:0.0018065524084622472\n",
      "=== epoch:12, train acc:0.999, test acc:0.967 ===\n",
      "train loss:0.004730557139617588\n",
      "train loss:0.006758262693226345\n",
      "train loss:0.0011123093385059124\n",
      "train loss:0.0025704137656137505\n",
      "train loss:0.0040471071318350215\n",
      "train loss:0.007950298720518209\n",
      "train loss:0.0027934279033650917\n",
      "train loss:0.007210696916767654\n",
      "train loss:0.0006221900866560916\n",
      "train loss:0.0021573421626483623\n",
      "train loss:0.004401977102580054\n",
      "train loss:0.005090032695410216\n",
      "train loss:0.003097186085954825\n",
      "train loss:0.0037921017450716706\n",
      "train loss:0.0035437554163943825\n",
      "train loss:0.004396031112694296\n",
      "train loss:0.0027666801208839215\n",
      "train loss:0.002264351227097159\n",
      "train loss:0.0034858312068758008\n",
      "train loss:0.0022828852872816044\n",
      "train loss:0.0027212073175555524\n",
      "train loss:0.0016420822259629478\n",
      "train loss:0.0015738974038850787\n",
      "train loss:0.004516425599275367\n",
      "train loss:0.0008387559649013076\n",
      "train loss:0.005947179354138469\n",
      "train loss:0.001517999660755042\n",
      "train loss:0.009346290960504216\n",
      "train loss:0.002536977877802652\n",
      "train loss:0.007217755928572129\n",
      "train loss:0.006733373768105521\n",
      "train loss:0.003642446418076167\n",
      "train loss:0.004101328793403018\n",
      "train loss:0.0008934628423148121\n",
      "train loss:0.00046579518374612516\n",
      "train loss:0.0013834487423649024\n",
      "train loss:0.0006649920895996295\n",
      "train loss:0.0013535552185252918\n",
      "train loss:0.0006171952884866513\n",
      "train loss:0.0010725697173440496\n",
      "train loss:0.0031190364929326885\n",
      "train loss:0.0018934977024556003\n",
      "train loss:0.0006571587478765259\n",
      "train loss:0.0026090544178439994\n",
      "train loss:0.003938014788128466\n",
      "train loss:0.0023705112997814025\n",
      "train loss:0.00016533264025811483\n",
      "train loss:0.0030964444861883733\n",
      "train loss:0.0032482517383468786\n",
      "train loss:0.0034358332982077824\n",
      "=== epoch:13, train acc:1.0, test acc:0.968 ===\n",
      "train loss:0.001199501188791727\n",
      "train loss:0.0020222818379738478\n",
      "train loss:0.00021714756319915328\n",
      "train loss:0.00044668771135734345\n",
      "train loss:0.0008954728183495703\n",
      "train loss:0.0014076252598198946\n",
      "train loss:0.0008476176555055899\n",
      "train loss:0.002095550919910968\n",
      "train loss:0.001437209682603688\n",
      "train loss:0.001995997532645937\n",
      "train loss:0.0027067553265143016\n",
      "train loss:0.001197341857940682\n",
      "train loss:0.0025037554932866983\n",
      "train loss:0.0027087294865888304\n",
      "train loss:0.0006092751216606879\n",
      "train loss:0.003056834005543427\n",
      "train loss:0.005525157295348503\n",
      "train loss:0.0010667742567060509\n",
      "train loss:0.004767978792308289\n",
      "train loss:0.005235139605600799\n",
      "train loss:0.010998056726925463\n",
      "train loss:0.0022694762330542828\n",
      "train loss:0.0007163664547599444\n",
      "train loss:0.0004449912574626244\n",
      "train loss:0.004426117352515273\n",
      "train loss:0.012280859562263628\n",
      "train loss:0.0025220126411513253\n",
      "train loss:0.0017000061685154017\n",
      "train loss:0.0002704042221689968\n",
      "train loss:0.0008387896919911126\n",
      "train loss:0.003452119855616305\n",
      "train loss:0.005153187041541603\n",
      "train loss:0.00415188204511307\n",
      "train loss:0.007163176173015862\n",
      "train loss:0.005127868062649504\n",
      "train loss:0.003043905914023632\n",
      "train loss:0.009525940450762282\n",
      "train loss:0.0028978471226760462\n",
      "train loss:0.004669899892708897\n",
      "train loss:0.004974762778145279\n",
      "train loss:0.0034316985397641947\n",
      "train loss:0.0017647771625798217\n",
      "train loss:0.008158576046505868\n",
      "train loss:0.0031411960534977394\n",
      "train loss:0.004243227672624073\n",
      "train loss:0.0034542655708181273\n",
      "train loss:0.0027853762046604097\n",
      "train loss:0.0031553401280931814\n",
      "train loss:0.004427655046589148\n",
      "train loss:0.0010990205998259363\n",
      "=== epoch:14, train acc:0.994, test acc:0.964 ===\n",
      "train loss:0.00757062225805316\n",
      "train loss:0.002126834720415034\n",
      "train loss:0.05192539328255445\n",
      "train loss:0.011846589452385559\n",
      "train loss:0.00513815002614099\n",
      "train loss:0.004865613367912948\n",
      "train loss:0.01667792607811873\n",
      "train loss:0.0012824962491134707\n",
      "train loss:0.00460315261984344\n",
      "train loss:0.002849174928686114\n",
      "train loss:0.007579164737986782\n",
      "train loss:0.0022200652609769105\n",
      "train loss:0.0033228439587289537\n",
      "train loss:0.0004414710517034579\n",
      "train loss:0.03537613135900753\n",
      "train loss:0.003398314633984125\n",
      "train loss:0.0018675131656253243\n",
      "train loss:0.0032970772723922566\n",
      "train loss:0.000423134807049931\n",
      "train loss:0.0032154383475523794\n",
      "train loss:0.008721417399686661\n",
      "train loss:0.0012345573619695737\n",
      "train loss:0.02876279591948251\n",
      "train loss:0.0008391907582523039\n",
      "train loss:0.002144832082472589\n",
      "train loss:0.010495706926592813\n",
      "train loss:0.008069720745274105\n",
      "train loss:0.010364804155518381\n",
      "train loss:0.0056791472697480085\n",
      "train loss:0.0022268916294066036\n",
      "train loss:0.004126390481438116\n",
      "train loss:0.0039406312661007655\n",
      "train loss:0.009112610434068974\n",
      "train loss:0.0067679689517195695\n",
      "train loss:0.008327773723434642\n",
      "train loss:0.005089927876223536\n",
      "train loss:0.006829647828109846\n",
      "train loss:0.005905236303861499\n",
      "train loss:0.001552619269235485\n",
      "train loss:0.0034410424441901726\n",
      "train loss:0.0021626140056606315\n",
      "train loss:0.0011333623803222268\n",
      "train loss:0.00632443610148759\n",
      "train loss:0.0008189381383321724\n",
      "train loss:0.008878277760174781\n",
      "train loss:0.00779033835830786\n",
      "train loss:0.004529406264535567\n",
      "train loss:0.004925605845349074\n",
      "train loss:0.0006097459752820443\n",
      "train loss:0.017672926829726644\n",
      "=== epoch:15, train acc:0.993, test acc:0.966 ===\n",
      "train loss:0.0010261087168601864\n",
      "train loss:0.001593496589009008\n",
      "train loss:0.0030860277271835533\n",
      "train loss:0.010045066525209317\n",
      "train loss:0.010335864141037886\n",
      "train loss:0.005062212660607868\n",
      "train loss:0.0039358439280308\n",
      "train loss:0.0052595333751819864\n",
      "train loss:0.006180517293243946\n",
      "train loss:0.0027720762639102925\n",
      "train loss:0.0090563964317143\n",
      "train loss:0.0031827819859503183\n",
      "train loss:0.001444438855563046\n",
      "train loss:0.003822376167859973\n",
      "train loss:0.003470052513797221\n",
      "train loss:0.014707130632802696\n",
      "train loss:0.0027570421582419884\n",
      "train loss:0.009389209207664511\n",
      "train loss:0.008051775139248242\n",
      "train loss:0.002664492412948069\n",
      "train loss:0.006573531542037886\n",
      "train loss:0.0013321804898555024\n",
      "train loss:0.002088801595208382\n",
      "train loss:0.002431358980676054\n",
      "train loss:0.0038931313641905195\n",
      "train loss:0.0019119176860077287\n",
      "train loss:0.002478185980236692\n",
      "train loss:0.002611853112559304\n",
      "train loss:0.001492450271356308\n",
      "train loss:0.009468983660235115\n",
      "train loss:0.001580019913907204\n",
      "train loss:0.002213487856434003\n",
      "train loss:0.001322897853433913\n",
      "train loss:0.00016321846739649208\n",
      "train loss:0.002175866950308877\n",
      "train loss:0.0037554183068668145\n",
      "train loss:0.0036191286597886687\n",
      "train loss:0.00018238739626208836\n",
      "train loss:0.004079910066793374\n",
      "train loss:0.0015680708228486126\n",
      "train loss:0.0019074980798395376\n",
      "train loss:0.002768716005720436\n",
      "train loss:0.002298596217669824\n",
      "train loss:0.0025739867183428955\n",
      "train loss:0.0012689997807680544\n",
      "train loss:0.0015250140571961058\n",
      "train loss:0.006978423303047649\n",
      "train loss:0.0007915484479354859\n",
      "train loss:0.0017870702726058348\n",
      "train loss:0.0019146076537794258\n",
      "=== epoch:16, train acc:0.996, test acc:0.958 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0022852531792136176\n",
      "train loss:0.0005056054854349509\n",
      "train loss:0.00046103609517262446\n",
      "train loss:0.0027679499974791882\n",
      "train loss:0.0013011412242432308\n",
      "train loss:0.001228852309933089\n",
      "train loss:0.0019388381221081233\n",
      "train loss:0.002321022625026508\n",
      "train loss:0.004964675049211994\n",
      "train loss:0.0036116604827483873\n",
      "train loss:0.009121444931003208\n",
      "train loss:0.002024156812454973\n",
      "train loss:0.003807198368500537\n",
      "train loss:0.002463659387641628\n",
      "train loss:0.0009031363863964705\n",
      "train loss:0.0033739415593198063\n",
      "train loss:0.0011518010194775667\n",
      "train loss:0.0011344715441595594\n",
      "train loss:0.0010000372709246103\n",
      "train loss:0.0025398865936103743\n",
      "train loss:0.0030838461031086123\n",
      "train loss:0.005911445797405798\n",
      "train loss:0.0028379625088334774\n",
      "train loss:0.002316341437634548\n",
      "train loss:0.003384587451169834\n",
      "train loss:0.001750315926395423\n",
      "train loss:0.0015047436695121957\n",
      "train loss:0.00184320391200887\n",
      "train loss:0.002881441198201989\n",
      "train loss:0.002129299286404643\n",
      "train loss:0.0020289980893697162\n",
      "train loss:0.004588501937584081\n",
      "train loss:0.001541109342560914\n",
      "train loss:0.006098525737115679\n",
      "train loss:0.001974397875063613\n",
      "train loss:0.0015825623678460312\n",
      "train loss:0.0003883139041795853\n",
      "train loss:0.0011787059531610548\n",
      "train loss:0.02773386863676161\n",
      "train loss:0.0012026627642712814\n",
      "train loss:0.0029756800009575384\n",
      "train loss:0.0025548956314640596\n",
      "train loss:0.0005363162614034761\n",
      "train loss:0.0007770146447392036\n",
      "train loss:0.0005669152929969434\n",
      "train loss:0.0016383895536022373\n",
      "train loss:0.0002780610121171752\n",
      "train loss:0.0014619169903701058\n",
      "train loss:0.005063411254162688\n",
      "train loss:0.0015886569921749214\n",
      "=== epoch:17, train acc:0.998, test acc:0.957 ===\n",
      "train loss:0.0005381786538188257\n",
      "train loss:0.002144622037989043\n",
      "train loss:0.0024769181985126345\n",
      "train loss:0.0009818564809530356\n",
      "train loss:0.0007318432883315738\n",
      "train loss:0.0006132700377724311\n",
      "train loss:0.0006591551908063739\n",
      "train loss:0.00010511726071881068\n",
      "train loss:0.00113403921352441\n",
      "train loss:0.0010302236954480438\n",
      "train loss:0.0027201969831258423\n",
      "train loss:0.0009261850092799477\n",
      "train loss:0.0023369746349512855\n",
      "train loss:0.001859617221551422\n",
      "train loss:0.0003428359543709539\n",
      "train loss:0.0007570966990638632\n",
      "train loss:0.001276196805466469\n",
      "train loss:0.014007089159984078\n",
      "train loss:0.001680197361901732\n",
      "train loss:0.0016407394135423972\n",
      "train loss:0.0014835383393606305\n",
      "train loss:0.001940314093560722\n",
      "train loss:0.0002539961539095402\n",
      "train loss:0.002263681551035102\n",
      "train loss:0.0035012767833213702\n",
      "train loss:0.0020402618537279952\n",
      "train loss:0.0010782659891876928\n",
      "train loss:0.0015403369810659791\n",
      "train loss:0.001368548612368762\n",
      "train loss:0.0001751760296816813\n",
      "train loss:0.0008563712984569245\n",
      "train loss:0.0006783130890771591\n",
      "train loss:0.00010134303099181279\n",
      "train loss:0.0022137906869871644\n",
      "train loss:0.002039730250256476\n",
      "train loss:0.0014974166964826625\n",
      "train loss:0.00041211734780015807\n",
      "train loss:0.00014280157809469976\n",
      "train loss:0.00023319003344458896\n",
      "train loss:0.0009676949777876318\n",
      "train loss:0.0008983966905336574\n",
      "train loss:0.00023816871885540776\n",
      "train loss:0.0012453444768174059\n",
      "train loss:0.0008220252120231398\n",
      "train loss:0.0003175497098819249\n",
      "train loss:0.0003826632413620817\n",
      "train loss:0.0001994444979710429\n",
      "train loss:0.0028090115620889246\n",
      "train loss:0.0007320820493027186\n",
      "train loss:6.215843378168155e-05\n",
      "=== epoch:18, train acc:0.999, test acc:0.966 ===\n",
      "train loss:0.00047248268547229344\n",
      "train loss:0.0022652590487051596\n",
      "train loss:0.0011914453120460975\n",
      "train loss:0.0005520874412576687\n",
      "train loss:0.0017115266021604611\n",
      "train loss:0.000675456987381637\n",
      "train loss:5.7254264020625035e-05\n",
      "train loss:0.0019431852657309367\n",
      "train loss:0.00026811069339830585\n",
      "train loss:0.0019260552082139193\n",
      "train loss:0.0013702649996740076\n",
      "train loss:0.0005472744403338651\n",
      "train loss:0.0008088065124474497\n",
      "train loss:0.0007163525284059653\n",
      "train loss:0.00016964574214580662\n",
      "train loss:0.0002771998366458724\n",
      "train loss:0.00028776428672653567\n",
      "train loss:0.0003947609391068046\n",
      "train loss:0.0007672088171433911\n",
      "train loss:0.00013939365139130618\n",
      "train loss:0.0006930820333153173\n",
      "train loss:0.00023980762324621712\n",
      "train loss:7.313689958596837e-05\n",
      "train loss:0.00043349136738456606\n",
      "train loss:0.0010186771209126078\n",
      "train loss:7.221028471009945e-05\n",
      "train loss:0.00018611412707334404\n",
      "train loss:0.00048729083347751815\n",
      "train loss:0.00044975469365666034\n",
      "train loss:9.259523723435258e-05\n",
      "train loss:0.0007035783152345238\n",
      "train loss:0.00015346762685670577\n",
      "train loss:0.0003927553903821598\n",
      "train loss:0.0003698579381866092\n",
      "train loss:0.000479916782013072\n",
      "train loss:0.0006902925378275642\n",
      "train loss:0.0011809941250124215\n",
      "train loss:0.00015933175744154302\n",
      "train loss:0.0001961453478351071\n",
      "train loss:0.0002276564939841633\n",
      "train loss:0.0014355920921771176\n",
      "train loss:0.0003976533046642897\n",
      "train loss:0.0003392520936634594\n",
      "train loss:0.00041066790142786354\n",
      "train loss:9.666526431667054e-05\n",
      "train loss:0.0004530412324567664\n",
      "train loss:0.00021365065318497436\n",
      "train loss:0.00010730100676615366\n",
      "train loss:0.0004944512043070524\n",
      "train loss:0.0001384871117256026\n",
      "=== epoch:19, train acc:1.0, test acc:0.965 ===\n",
      "train loss:0.0002520815145890782\n",
      "train loss:0.0004429810598059643\n",
      "train loss:0.00017062482168082513\n",
      "train loss:0.0008804801668341864\n",
      "train loss:0.00044720375007397485\n",
      "train loss:0.0007378506858138301\n",
      "train loss:0.0005812429131443191\n",
      "train loss:0.00018971524102960296\n",
      "train loss:0.00011470480458823191\n",
      "train loss:6.772708315130138e-05\n",
      "train loss:0.00023323157210477653\n",
      "train loss:1.677328939055848e-05\n",
      "train loss:0.00030315629749336605\n",
      "train loss:4.321815878100945e-05\n",
      "train loss:0.00022068990500643211\n",
      "train loss:0.0001935179909719395\n",
      "train loss:0.00019931807703431196\n",
      "train loss:0.00022641096133926763\n",
      "train loss:0.00012659894569450674\n",
      "train loss:2.8793408743702886e-05\n",
      "train loss:0.0003181901953653717\n",
      "train loss:6.999539512301622e-05\n",
      "train loss:0.0001211799128123902\n",
      "train loss:0.00011827968002590926\n",
      "train loss:0.00019814575078852602\n",
      "train loss:0.00012451504885781028\n",
      "train loss:9.557063143678522e-05\n",
      "train loss:7.549288013224161e-05\n",
      "train loss:0.00013535793908531403\n",
      "train loss:2.9486297838205222e-05\n",
      "train loss:0.0001570380783994404\n",
      "train loss:5.5224085329023434e-05\n",
      "train loss:0.0003178849751543882\n",
      "train loss:0.0001922471733495256\n",
      "train loss:0.00031398288379417145\n",
      "train loss:0.0003743089893844646\n",
      "train loss:5.558867213574946e-05\n",
      "train loss:0.00029031469065135746\n",
      "train loss:0.00017487336777985988\n",
      "train loss:0.00020264021428596855\n",
      "train loss:0.00014839322706806704\n",
      "train loss:0.00010334296608154046\n",
      "train loss:0.0001775698661260446\n",
      "train loss:9.677954530059446e-05\n",
      "train loss:0.00013149660104833956\n",
      "train loss:4.339768048870366e-05\n",
      "train loss:0.0004216542357060315\n",
      "train loss:0.00011523461392209993\n",
      "train loss:6.495646898422826e-05\n",
      "train loss:4.863989983891745e-05\n",
      "=== epoch:20, train acc:1.0, test acc:0.97 ===\n",
      "train loss:9.706003980193277e-05\n",
      "train loss:0.0003584049615352942\n",
      "train loss:0.0001204103100776272\n",
      "train loss:0.00011858137351547763\n",
      "train loss:0.00010631898295791935\n",
      "train loss:0.0003545482669927014\n",
      "train loss:7.928592460673914e-05\n",
      "train loss:8.234806420961846e-05\n",
      "train loss:0.00013602131511506515\n",
      "train loss:0.00025502165090471844\n",
      "train loss:0.00028010904956261585\n",
      "train loss:0.00014909443301310387\n",
      "train loss:8.119497921211053e-05\n",
      "train loss:0.00020246119865264023\n",
      "train loss:0.0002894906234537386\n",
      "train loss:0.00013240994407173382\n",
      "train loss:0.00011938134922659792\n",
      "train loss:0.00015546226936649044\n",
      "train loss:0.0003495067903267209\n",
      "train loss:0.00027886079772755336\n",
      "train loss:5.4281459662519755e-05\n",
      "train loss:0.000195921523741081\n",
      "train loss:0.0001946827457016144\n",
      "train loss:7.12823753426463e-05\n",
      "train loss:0.00020547869399579292\n",
      "train loss:0.0002054875934377012\n",
      "train loss:0.0004529453108576372\n",
      "train loss:3.440026130544814e-05\n",
      "train loss:1.2374783523909072e-05\n",
      "train loss:0.0001367213048773946\n",
      "train loss:3.717147352836967e-05\n",
      "train loss:0.00010373711862388219\n",
      "train loss:5.418845698562345e-05\n",
      "train loss:0.00010159455302087482\n",
      "train loss:0.00010128184413364065\n",
      "train loss:3.4947616704308933e-05\n",
      "train loss:7.58294634592118e-05\n",
      "train loss:7.013969609316183e-05\n",
      "train loss:7.731512561156985e-05\n",
      "train loss:0.000134971487457667\n",
      "train loss:0.0001563181655879517\n",
      "train loss:0.00012036433016236221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:9.286747597253737e-05\n",
      "train loss:8.410447601703385e-05\n",
      "train loss:4.6459629849104686e-05\n",
      "train loss:0.00012967565207061186\n",
      "train loss:6.772007461848676e-05\n",
      "train loss:5.8987517689963966e-05\n",
      "train loss:8.156944931807471e-05\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.972\n"
     ]
    }
   ],
   "source": [
    "network4 = TestConvNet4()\n",
    "trainer4 = Trainer(network4, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr':0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "\n",
    "trainer4.train()\n",
    "network4.save_params(\"params/test_convnet4_params.pkl\")\n",
    "with open(\"trainer4.pkl\", 'wb') as f:\n",
    "    pickle.dump(trainer4, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55f321e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.213658025062665\n",
      "=== epoch:1, train acc:0.216, test acc:0.216 ===\n",
      "train loss:2.0847656994813843\n",
      "train loss:1.9482181575328352\n",
      "train loss:2.01131541877812\n",
      "train loss:1.931758455876902\n",
      "train loss:1.8244726279484995\n",
      "train loss:1.7632556993850879\n",
      "train loss:1.6190097000413588\n",
      "train loss:1.3386443102865528\n",
      "train loss:1.1585260320897393\n",
      "train loss:1.074420301459539\n",
      "train loss:1.1198281032886157\n",
      "train loss:0.9746973100275862\n",
      "train loss:0.761789942464248\n",
      "train loss:0.5661327458817521\n",
      "train loss:0.6729180915257718\n",
      "train loss:0.7947589853939406\n",
      "train loss:0.6077677585734655\n",
      "train loss:0.6345563063425308\n",
      "train loss:0.5523569438050007\n",
      "train loss:0.3095574078998766\n",
      "train loss:0.23627233640667467\n",
      "train loss:0.5097188397266718\n",
      "train loss:0.502695908531983\n",
      "train loss:0.3832918068416686\n",
      "train loss:0.3332752117783427\n",
      "train loss:0.31245938256786787\n",
      "train loss:0.2600637894742728\n",
      "train loss:0.3671345423634639\n",
      "train loss:0.29198559221788517\n",
      "train loss:0.42227913678863677\n",
      "train loss:0.4294240181021398\n",
      "train loss:0.33518891914404747\n",
      "train loss:0.3241841160796099\n",
      "train loss:0.24302067755659088\n",
      "train loss:0.4684528056555633\n",
      "train loss:0.2230763461262491\n",
      "train loss:0.42808578534197517\n",
      "train loss:0.22666980483054366\n",
      "train loss:0.2079534250780088\n",
      "train loss:0.27372145367661166\n",
      "train loss:0.38442188530559435\n",
      "train loss:0.34761698401167196\n",
      "train loss:0.3721156506386877\n",
      "train loss:0.33795018608544647\n",
      "train loss:0.33192981593283866\n",
      "train loss:0.1970665188202032\n",
      "train loss:0.33299042261935113\n",
      "train loss:0.25191785511021697\n",
      "train loss:0.31370660857723914\n",
      "train loss:0.2284502806875755\n",
      "=== epoch:2, train acc:0.922, test acc:0.907 ===\n",
      "train loss:0.1698123886789259\n",
      "train loss:0.21221398481211692\n",
      "train loss:0.14740488011767242\n",
      "train loss:0.18013288498221092\n",
      "train loss:0.1445964272473417\n",
      "train loss:0.22125991456058633\n",
      "train loss:0.228202411938199\n",
      "train loss:0.2124238794406722\n",
      "train loss:0.18922561257573464\n",
      "train loss:0.14642746495973974\n",
      "train loss:0.19879734514070033\n",
      "train loss:0.16562530625726105\n",
      "train loss:0.1798678481344766\n",
      "train loss:0.1339798140331816\n",
      "train loss:0.15469074944493447\n",
      "train loss:0.10599905911596846\n",
      "train loss:0.18667598182632553\n",
      "train loss:0.08718621072474791\n",
      "train loss:0.14929447232354057\n",
      "train loss:0.15608772668338045\n",
      "train loss:0.16393383227112476\n",
      "train loss:0.08025290615437036\n",
      "train loss:0.10134438716373034\n",
      "train loss:0.07001282814665517\n",
      "train loss:0.07046554723948435\n",
      "train loss:0.05111176518388876\n",
      "train loss:0.0981563181090528\n",
      "train loss:0.15110059943737192\n",
      "train loss:0.07860922579014201\n",
      "train loss:0.14599298873430355\n",
      "train loss:0.030557187357415062\n",
      "train loss:0.07350646351563218\n",
      "train loss:0.0421818226958548\n",
      "train loss:0.17272512411903512\n",
      "train loss:0.1599853032071163\n",
      "train loss:0.05028646861102283\n",
      "train loss:0.14645726876458287\n",
      "train loss:0.17139194125521975\n",
      "train loss:0.09887578839934019\n",
      "train loss:0.06505395794534806\n",
      "train loss:0.06947832561921209\n",
      "train loss:0.055648574357009435\n",
      "train loss:0.1805547103256485\n",
      "train loss:0.03713846190274446\n",
      "train loss:0.06201376682050453\n",
      "train loss:0.17576203727675452\n",
      "train loss:0.12247619460979109\n",
      "train loss:0.10478924488158965\n",
      "train loss:0.15975644869611177\n",
      "train loss:0.11665630941052849\n",
      "=== epoch:3, train acc:0.957, test acc:0.947 ===\n",
      "train loss:0.13620403766339398\n",
      "train loss:0.08719964625534579\n",
      "train loss:0.1504425475159243\n",
      "train loss:0.06639709283975433\n",
      "train loss:0.11391891579167397\n",
      "train loss:0.08611563710158537\n",
      "train loss:0.10531636250654101\n",
      "train loss:0.08953685586148039\n",
      "train loss:0.1245101091293093\n",
      "train loss:0.0820015390705456\n",
      "train loss:0.08479416373004782\n",
      "train loss:0.1258794318323702\n",
      "train loss:0.039160251314917474\n",
      "train loss:0.08811751397698521\n",
      "train loss:0.09784218239644327\n",
      "train loss:0.033873002468175636\n",
      "train loss:0.10362092707137699\n",
      "train loss:0.1734879119398441\n",
      "train loss:0.0660974581165089\n",
      "train loss:0.027936304752068545\n",
      "train loss:0.06485186159411932\n",
      "train loss:0.06675792947367681\n",
      "train loss:0.03451520774498705\n",
      "train loss:0.21384116702202152\n",
      "train loss:0.027669169716481465\n",
      "train loss:0.06157801866480183\n",
      "train loss:0.03098740236426642\n",
      "train loss:0.11746745821814908\n",
      "train loss:0.05148311224764442\n",
      "train loss:0.034198171899793565\n",
      "train loss:0.1379834950662524\n",
      "train loss:0.16894784376512015\n",
      "train loss:0.0556669334713386\n",
      "train loss:0.07255107138716832\n",
      "train loss:0.046985280388338\n",
      "train loss:0.07783046328269089\n",
      "train loss:0.028102417645612738\n",
      "train loss:0.028874652403948306\n",
      "train loss:0.046423925462192976\n",
      "train loss:0.03772851542570111\n",
      "train loss:0.03867809183655055\n",
      "train loss:0.09261575008020648\n",
      "train loss:0.028295998928477097\n",
      "train loss:0.030078579148953753\n",
      "train loss:0.09179057111062566\n",
      "train loss:0.08351947558523792\n",
      "train loss:0.0154988370346574\n",
      "train loss:0.057923733848526684\n",
      "train loss:0.10614750085424265\n",
      "train loss:0.02711159520094121\n",
      "=== epoch:4, train acc:0.975, test acc:0.957 ===\n",
      "train loss:0.017392836175856897\n",
      "train loss:0.04026377625130253\n",
      "train loss:0.07117281775086999\n",
      "train loss:0.10837084336299752\n",
      "train loss:0.10244692679595796\n",
      "train loss:0.08811649101250138\n",
      "train loss:0.09923171437847841\n",
      "train loss:0.04683273641820785\n",
      "train loss:0.08114645380625271\n",
      "train loss:0.03493405994936431\n",
      "train loss:0.03261968776679973\n",
      "train loss:0.02589873990493691\n",
      "train loss:0.059563503518986434\n",
      "train loss:0.039678139270755315\n",
      "train loss:0.02055153774491183\n",
      "train loss:0.0271588329225326\n",
      "train loss:0.09623288938142105\n",
      "train loss:0.07644467531013462\n",
      "train loss:0.051670415374487064\n",
      "train loss:0.020861661234951204\n",
      "train loss:0.027782697871029768\n",
      "train loss:0.15599198388283253\n",
      "train loss:0.08456220447713393\n",
      "train loss:0.06630230774470487\n",
      "train loss:0.01775699637266734\n",
      "train loss:0.06849607256824271\n",
      "train loss:0.04868423941001799\n",
      "train loss:0.06998600582062726\n",
      "train loss:0.07998979607088269\n",
      "train loss:0.10459193884986943\n",
      "train loss:0.07607648669220196\n",
      "train loss:0.0654232173797297\n",
      "train loss:0.06433513091562865\n",
      "train loss:0.01962224006829805\n",
      "train loss:0.04247092330656175\n",
      "train loss:0.035985398580689984\n",
      "train loss:0.044766960667933724\n",
      "train loss:0.05974118275875309\n",
      "train loss:0.025098048495531246\n",
      "train loss:0.02473948839329621\n",
      "train loss:0.016987239053880564\n",
      "train loss:0.03946086294733911\n",
      "train loss:0.015955315746454153\n",
      "train loss:0.024192114255884464\n",
      "train loss:0.08556923836635943\n",
      "train loss:0.01704484300970476\n",
      "train loss:0.038799080540399954\n",
      "train loss:0.007786507944369953\n",
      "train loss:0.027004263667901252\n",
      "train loss:0.014708286360474188\n",
      "=== epoch:5, train acc:0.987, test acc:0.962 ===\n",
      "train loss:0.02067311094288703\n",
      "train loss:0.012758421677724691\n",
      "train loss:0.022671113332778502\n",
      "train loss:0.0916840507939771\n",
      "train loss:0.022235854933009228\n",
      "train loss:0.0942044962824686\n",
      "train loss:0.010930960966202923\n",
      "train loss:0.019123011336890518\n",
      "train loss:0.05885930114353363\n",
      "train loss:0.037174900474870924\n",
      "train loss:0.03168989513961269\n",
      "train loss:0.08359271323794201\n",
      "train loss:0.02940656738433714\n",
      "train loss:0.02916643467509148\n",
      "train loss:0.04156378723678192\n",
      "train loss:0.09841199200079571\n",
      "train loss:0.03051529096726791\n",
      "train loss:0.033145383837198\n",
      "train loss:0.07065880086811527\n",
      "train loss:0.014720819029270691\n",
      "train loss:0.031960350405577445\n",
      "train loss:0.07040824425926694\n",
      "train loss:0.013094962488955557\n",
      "train loss:0.06253840075217657\n",
      "train loss:0.04816130452962059\n",
      "train loss:0.04350526471334635\n",
      "train loss:0.02088444344622987\n",
      "train loss:0.0443300372927646\n",
      "train loss:0.053714468001499156\n",
      "train loss:0.04140243323025092\n",
      "train loss:0.01450701226278197\n",
      "train loss:0.03415002726682783\n",
      "train loss:0.044712125882656995\n",
      "train loss:0.025645023776190636\n",
      "train loss:0.03180370517962649\n",
      "train loss:0.0037865543943458\n",
      "train loss:0.03369054719304935\n",
      "train loss:0.0693647096346659\n",
      "train loss:0.07291188322787107\n",
      "train loss:0.12331240608473908\n",
      "train loss:0.030661819242651683\n",
      "train loss:0.0231214544450784\n",
      "train loss:0.02531363892850794\n",
      "train loss:0.01879543449463025\n",
      "train loss:0.017434121683392863\n",
      "train loss:0.03328926424176568\n",
      "train loss:0.018019448991852184\n",
      "train loss:0.01979184568054727\n",
      "train loss:0.023133083107955022\n",
      "train loss:0.018801385880100423\n",
      "=== epoch:6, train acc:0.984, test acc:0.961 ===\n",
      "train loss:0.01742989326969961\n",
      "train loss:0.03991371498619347\n",
      "train loss:0.02506357683227941\n",
      "train loss:0.02835160264863886\n",
      "train loss:0.013305959715238734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005512804956678146\n",
      "train loss:0.10649447278354728\n",
      "train loss:0.013421455244226988\n",
      "train loss:0.02413580769040935\n",
      "train loss:0.05110619413004017\n",
      "train loss:0.022292523831046934\n",
      "train loss:0.059463396710497135\n",
      "train loss:0.040392104463643275\n",
      "train loss:0.062141399961287425\n",
      "train loss:0.020332993051160944\n",
      "train loss:0.00714241437417572\n",
      "train loss:0.07850709400278974\n",
      "train loss:0.04986843586989283\n",
      "train loss:0.01139798593477012\n",
      "train loss:0.07745867330562625\n",
      "train loss:0.043889029192619916\n",
      "train loss:0.04500172671800878\n",
      "train loss:0.01386827003137929\n",
      "train loss:0.03749627309894639\n",
      "train loss:0.00888443044546487\n",
      "train loss:0.012308462955591149\n",
      "train loss:0.03787712117532514\n",
      "train loss:0.041474663613962265\n",
      "train loss:0.07374588146168679\n",
      "train loss:0.04561984950503462\n",
      "train loss:0.012728239109847961\n",
      "train loss:0.01627917710914289\n",
      "train loss:0.023288419706740223\n",
      "train loss:0.0379095139741664\n",
      "train loss:0.04164604530216817\n",
      "train loss:0.006479403100865748\n",
      "train loss:0.012521737380551885\n",
      "train loss:0.047250198234882884\n",
      "train loss:0.01357399077674476\n",
      "train loss:0.07228022429847573\n",
      "train loss:0.014350606426718608\n",
      "train loss:0.016419620194470016\n",
      "train loss:0.012061536340298528\n",
      "train loss:0.014423544635936274\n",
      "train loss:0.012622549088042376\n",
      "train loss:0.007668157969787541\n",
      "train loss:0.04707394675931854\n",
      "train loss:0.04200878316223775\n",
      "train loss:0.01940660247113616\n",
      "train loss:0.008670034604855239\n",
      "=== epoch:7, train acc:0.994, test acc:0.967 ===\n",
      "train loss:0.01506703843560599\n",
      "train loss:0.02648218353071349\n",
      "train loss:0.014991707685977518\n",
      "train loss:0.025886120349930996\n",
      "train loss:0.00999211094469558\n",
      "train loss:0.01799536773738469\n",
      "train loss:0.011184233456477642\n",
      "train loss:0.013859756242889045\n",
      "train loss:0.005325131878940817\n",
      "train loss:0.03108596463473144\n",
      "train loss:0.005368845552248849\n",
      "train loss:0.006987507791589615\n",
      "train loss:0.022198332577756833\n",
      "train loss:0.018790855366974987\n",
      "train loss:0.004463550626677205\n",
      "train loss:0.011973972866062034\n",
      "train loss:0.012766637636894385\n",
      "train loss:0.017315982252218195\n",
      "train loss:0.06264290533851852\n",
      "train loss:0.03449143132866806\n",
      "train loss:0.0061610306890053325\n",
      "train loss:0.041002434991059315\n",
      "train loss:0.009003880976580307\n",
      "train loss:0.00782781782683082\n",
      "train loss:0.015324448105266418\n",
      "train loss:0.009618844349984302\n",
      "train loss:0.014988029495272517\n",
      "train loss:0.008108719662046373\n",
      "train loss:0.00480344379444082\n",
      "train loss:0.008973525697169788\n",
      "train loss:0.016302417829631908\n",
      "train loss:0.0065244783184959946\n",
      "train loss:0.004291063129533899\n",
      "train loss:0.0032472105918849494\n",
      "train loss:0.08882720773632233\n",
      "train loss:0.011908951670267927\n",
      "train loss:0.0324784676461532\n",
      "train loss:0.009765514297082209\n",
      "train loss:0.017655009286326743\n",
      "train loss:0.004686894311794295\n",
      "train loss:0.009426407814918766\n",
      "train loss:0.01507535114237829\n",
      "train loss:0.03703942042680754\n",
      "train loss:0.003332970508153028\n",
      "train loss:0.008388391830884735\n",
      "train loss:0.012585458337825865\n",
      "train loss:0.012688836994268047\n",
      "train loss:0.0076870789090181905\n",
      "train loss:0.005979806941371111\n",
      "train loss:0.016514061208571594\n",
      "=== epoch:8, train acc:0.995, test acc:0.966 ===\n",
      "train loss:0.02967223684517695\n",
      "train loss:0.007541516831685801\n",
      "train loss:0.013326822484051934\n",
      "train loss:0.018900727362739043\n",
      "train loss:0.029336307039926988\n",
      "train loss:0.009974036638338108\n",
      "train loss:0.006143780931489988\n",
      "train loss:0.018734949228811512\n",
      "train loss:0.017123118622944734\n",
      "train loss:0.008092799418627467\n",
      "train loss:0.013176042274086242\n",
      "train loss:0.007749143846578112\n",
      "train loss:0.002746978208802843\n",
      "train loss:0.007851191007793044\n",
      "train loss:0.004926887798647248\n",
      "train loss:0.0029374602940785547\n",
      "train loss:0.008041217252617507\n",
      "train loss:0.01363497253791781\n",
      "train loss:0.001877794587438716\n",
      "train loss:0.005597488155535399\n",
      "train loss:0.007902408695761002\n",
      "train loss:0.009745410092457937\n",
      "train loss:0.004117208328617731\n",
      "train loss:0.01997237147150025\n",
      "train loss:0.004377124143860619\n",
      "train loss:0.005843259234726604\n",
      "train loss:0.029451004314347887\n",
      "train loss:0.004669113583159082\n",
      "train loss:0.0052045479858280775\n",
      "train loss:0.014162527656685084\n",
      "train loss:0.011863984946965856\n",
      "train loss:0.00758067763709281\n",
      "train loss:0.009823432691691765\n",
      "train loss:0.01786694256605475\n",
      "train loss:0.01950351052055085\n",
      "train loss:0.010660036080069497\n",
      "train loss:0.0038643035826975447\n",
      "train loss:0.013871451965015\n",
      "train loss:0.011312256581026447\n",
      "train loss:0.039709008238878664\n",
      "train loss:0.028245448755359108\n",
      "train loss:0.01153406564045149\n",
      "train loss:0.011465917214374123\n",
      "train loss:0.009157240630732397\n",
      "train loss:0.002840124199064342\n",
      "train loss:0.013193166509645093\n",
      "train loss:0.014201052111102312\n",
      "train loss:0.009528884854590103\n",
      "train loss:0.006839278237257797\n",
      "train loss:0.00898716427808836\n",
      "=== epoch:9, train acc:0.996, test acc:0.962 ===\n",
      "train loss:0.0020309876690399126\n",
      "train loss:0.02530108155921458\n",
      "train loss:0.008626498307285388\n",
      "train loss:0.01532559609357145\n",
      "train loss:0.0376974600542419\n",
      "train loss:0.006798396623821752\n",
      "train loss:0.006487811226394204\n",
      "train loss:0.008369677701995048\n",
      "train loss:0.007938665515197684\n",
      "train loss:0.007978150274810575\n",
      "train loss:0.015758391433773868\n",
      "train loss:0.03985635053122088\n",
      "train loss:0.0017250416083687359\n",
      "train loss:0.0032855729200163015\n",
      "train loss:0.009035971758770002\n",
      "train loss:0.004243279813945711\n",
      "train loss:0.0051677853258218645\n",
      "train loss:0.0034461211347571797\n",
      "train loss:0.04861119327430164\n",
      "train loss:0.016843853579364857\n",
      "train loss:0.00808417546699696\n",
      "train loss:0.0036351047715282025\n",
      "train loss:0.0068206443538665175\n",
      "train loss:0.014560063989794932\n",
      "train loss:0.006228305827628916\n",
      "train loss:0.0021102018657810683\n",
      "train loss:0.007950744201162487\n",
      "train loss:0.015683805012004944\n",
      "train loss:0.006978096645649912\n",
      "train loss:0.02456220837209443\n",
      "train loss:0.0036832263273138877\n",
      "train loss:0.035873482233491995\n",
      "train loss:0.0009383721087282837\n",
      "train loss:0.03786722864831282\n",
      "train loss:0.006380433299909018\n",
      "train loss:0.005848063743978285\n",
      "train loss:0.013960890217070749\n",
      "train loss:0.0384820214204635\n",
      "train loss:0.006429759016919678\n",
      "train loss:0.026556798060907334\n",
      "train loss:0.015286381326537413\n",
      "train loss:0.0074201610439749\n",
      "train loss:0.031208262746092598\n",
      "train loss:0.00439345236127534\n",
      "train loss:0.0016671318155218019\n",
      "train loss:0.012316773903523315\n",
      "train loss:0.005580997700185855\n",
      "train loss:0.007728102476823422\n",
      "train loss:0.01219993927651324\n",
      "train loss:0.0060166273935004354\n",
      "=== epoch:10, train acc:0.998, test acc:0.967 ===\n",
      "train loss:0.0053951854552143\n",
      "train loss:0.00655943127471634\n",
      "train loss:0.013007461266766118\n",
      "train loss:0.012743295493865311\n",
      "train loss:0.005816258234537416\n",
      "train loss:0.013380969859483146\n",
      "train loss:0.0026579110767749664\n",
      "train loss:0.008520866039155701\n",
      "train loss:0.007547750649281229\n",
      "train loss:0.011641040068601297\n",
      "train loss:0.0053735114192740895\n",
      "train loss:0.004910519167870154\n",
      "train loss:0.012721411212098249\n",
      "train loss:0.0030667460866400493\n",
      "train loss:0.017045119671560336\n",
      "train loss:0.022286435782401193\n",
      "train loss:0.0061049847444598244\n",
      "train loss:0.01892427687637501\n",
      "train loss:0.024591860811545286\n",
      "train loss:0.004280389076517119\n",
      "train loss:0.0005593174947056806\n",
      "train loss:0.003383208572927747\n",
      "train loss:0.004369854839002028\n",
      "train loss:0.005245576691611428\n",
      "train loss:0.008301616426145929\n",
      "train loss:0.005175406518465655\n",
      "train loss:0.003405322062309067\n",
      "train loss:0.006326638613805986\n",
      "train loss:0.0020210019709656123\n",
      "train loss:0.005072715247900195\n",
      "train loss:0.006711447551758208\n",
      "train loss:0.0015120787438512515\n",
      "train loss:0.008765010043706039\n",
      "train loss:0.004595378222004968\n",
      "train loss:0.003972073544144846\n",
      "train loss:0.003789832378080388\n",
      "train loss:0.006924528325007636\n",
      "train loss:0.00855517440555628\n",
      "train loss:0.0005851377940127184\n",
      "train loss:0.006725351434600615\n",
      "train loss:0.0032368655778805084\n",
      "train loss:0.005708094041293844\n",
      "train loss:0.0027805295380495705\n",
      "train loss:0.0012749950099470223\n",
      "train loss:0.007134343802704165\n",
      "train loss:0.0024548326051646295\n",
      "train loss:0.003718503958296559\n",
      "train loss:0.0017390204815843073\n",
      "train loss:0.0027160056537316444\n",
      "train loss:0.0007641801273801281\n",
      "=== epoch:11, train acc:0.996, test acc:0.961 ===\n",
      "train loss:0.006395458289956873\n",
      "train loss:0.0033189901344187933\n",
      "train loss:0.0005383713199180671\n",
      "train loss:0.011755796690066775\n",
      "train loss:0.0013248185388928652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0034800492406390294\n",
      "train loss:0.0014217638281548669\n",
      "train loss:0.0015142207426249474\n",
      "train loss:0.0058096945667645405\n",
      "train loss:0.007962078768705663\n",
      "train loss:0.11334138967458099\n",
      "train loss:0.008715723803419131\n",
      "train loss:0.0037608723345842043\n",
      "train loss:0.007077315792135988\n",
      "train loss:0.0007251749418414377\n",
      "train loss:0.0034418254146501973\n",
      "train loss:0.002444895683605679\n",
      "train loss:0.004124439617140279\n",
      "train loss:0.0013929351609190564\n",
      "train loss:0.0067155880724658855\n",
      "train loss:0.0021014261605793168\n",
      "train loss:0.003915245228019922\n",
      "train loss:0.0011054552593910522\n",
      "train loss:0.03970288487671247\n",
      "train loss:0.0021649403558061174\n",
      "train loss:0.0010280540804237781\n",
      "train loss:0.00352958693046878\n",
      "train loss:0.0014961731626156574\n",
      "train loss:0.0053697748146607225\n",
      "train loss:0.01188376942426881\n",
      "train loss:0.002723777827153717\n",
      "train loss:0.00215493509393611\n",
      "train loss:0.004831129972034984\n",
      "train loss:0.0022067190999191435\n",
      "train loss:0.003071076766662232\n",
      "train loss:0.00523936309312307\n",
      "train loss:0.0032648074402301624\n",
      "train loss:0.003025226357001273\n",
      "train loss:0.002477971254537965\n",
      "train loss:0.0021693059641198563\n",
      "train loss:0.003025973876006403\n",
      "train loss:0.0034739867459010797\n",
      "train loss:0.0022199878163305206\n",
      "train loss:0.0008906636240847031\n",
      "train loss:0.002482886963271644\n",
      "train loss:0.008936615324754767\n",
      "train loss:0.0016461362408423665\n",
      "train loss:0.0021659838666386474\n",
      "train loss:0.007163836771385978\n",
      "train loss:0.0014197073911097321\n",
      "=== epoch:12, train acc:1.0, test acc:0.966 ===\n",
      "train loss:0.0022551436909168114\n",
      "train loss:0.0032119122159569168\n",
      "train loss:0.011337213329007617\n",
      "train loss:0.002405619466814095\n",
      "train loss:0.0043067860430235656\n",
      "train loss:0.0009789618906815975\n",
      "train loss:0.002988498760891733\n",
      "train loss:0.002668703278578102\n",
      "train loss:0.002037176818765289\n",
      "train loss:0.0012757471885316966\n",
      "train loss:0.006092328793937407\n",
      "train loss:0.0006654685352999382\n",
      "train loss:0.0010853907315272796\n",
      "train loss:0.0014570346959116103\n",
      "train loss:0.005589676840884187\n",
      "train loss:0.0014405370401901518\n",
      "train loss:0.0011178039100089294\n",
      "train loss:0.0006577180505427044\n",
      "train loss:0.008301864897432003\n",
      "train loss:0.005480770602617058\n",
      "train loss:0.0033036795034242054\n",
      "train loss:0.0016589330702363042\n",
      "train loss:0.0015513039151698617\n",
      "train loss:0.0003557903126818196\n",
      "train loss:0.004099752498257732\n",
      "train loss:0.001066110035940008\n",
      "train loss:0.0018608748360589098\n",
      "train loss:0.0004917933525090828\n",
      "train loss:0.000599167310725154\n",
      "train loss:0.0016459497214683454\n",
      "train loss:0.0013608721090915224\n",
      "train loss:0.0020395287282822744\n",
      "train loss:0.002334955025755474\n",
      "train loss:0.008317193816404996\n",
      "train loss:0.0018213658718536799\n",
      "train loss:0.005988744284434874\n",
      "train loss:0.0007448050379106259\n",
      "train loss:0.0009382597685854803\n",
      "train loss:0.00046050271496818915\n",
      "train loss:0.006591563293577761\n",
      "train loss:0.003566027456498232\n",
      "train loss:0.0023295090596039776\n",
      "train loss:0.0026200881608588623\n",
      "train loss:0.009201936572114305\n",
      "train loss:0.004337424376990685\n",
      "train loss:0.01934706226600325\n",
      "train loss:0.007029569466894988\n",
      "train loss:0.007399773084534262\n",
      "train loss:0.003227049725590875\n",
      "train loss:0.0026145298838117954\n",
      "=== epoch:13, train acc:0.998, test acc:0.964 ===\n",
      "train loss:0.0011559397283747975\n",
      "train loss:0.003964352492115082\n",
      "train loss:0.009490365878228301\n",
      "train loss:0.0029935675856904626\n",
      "train loss:0.008938155660862987\n",
      "train loss:0.005738819995877383\n",
      "train loss:0.00243440870891976\n",
      "train loss:0.0110613083090663\n",
      "train loss:0.011697112518367579\n",
      "train loss:0.028683137717215715\n",
      "train loss:0.0022169355047145737\n",
      "train loss:0.008539667021239556\n",
      "train loss:0.014897726071591505\n",
      "train loss:0.016626992872451497\n",
      "train loss:0.00404702402604962\n",
      "train loss:0.0033368026575440533\n",
      "train loss:0.009324085275945705\n",
      "train loss:0.010678831598970323\n",
      "train loss:0.0038425479243597935\n",
      "train loss:0.013596601925523501\n",
      "train loss:0.012177493499171313\n",
      "train loss:0.008148864968743985\n",
      "train loss:0.0030887167250540624\n",
      "train loss:0.00395533548217019\n",
      "train loss:0.001225050559925345\n",
      "train loss:0.005524490528291981\n",
      "train loss:0.002459267291308848\n",
      "train loss:0.0021956001851399258\n",
      "train loss:0.009141698621242068\n",
      "train loss:0.0005168022680450467\n",
      "train loss:0.003379298925428889\n",
      "train loss:0.0036754999068787132\n",
      "train loss:0.01163346748995992\n",
      "train loss:0.0018668712975841095\n",
      "train loss:0.004906663954283871\n",
      "train loss:0.03378924413752797\n",
      "train loss:0.031119653913392654\n",
      "train loss:0.009532014689131727\n",
      "train loss:0.010130452826729324\n",
      "train loss:0.009833657256102466\n",
      "train loss:0.017472966462270614\n",
      "train loss:0.0023856738508052414\n",
      "train loss:0.00209556344902386\n",
      "train loss:0.002377783472956374\n",
      "train loss:0.007431639359201043\n",
      "train loss:0.007566573816170912\n",
      "train loss:0.004312675693863519\n",
      "train loss:0.014181651826017107\n",
      "train loss:0.0062819247645343355\n",
      "train loss:0.025521432821793377\n",
      "=== epoch:14, train acc:0.989, test acc:0.956 ===\n",
      "train loss:0.005101973810180299\n",
      "train loss:0.0028620799325658215\n",
      "train loss:0.0069651992135281605\n",
      "train loss:0.002430163165438844\n",
      "train loss:0.003898169133545516\n",
      "train loss:0.0022504379037312054\n",
      "train loss:0.0018815188494649582\n",
      "train loss:0.002987243019360205\n",
      "train loss:0.002846853695604313\n",
      "train loss:0.027744120152911687\n",
      "train loss:0.004711463636676989\n",
      "train loss:0.005844174603305212\n",
      "train loss:0.0032386095096387907\n",
      "train loss:0.004591078804994093\n",
      "train loss:0.006518150351939038\n",
      "train loss:0.0029272920804424125\n",
      "train loss:0.0030293252790160553\n",
      "train loss:0.003937530185137163\n",
      "train loss:0.0016322961747973434\n",
      "train loss:0.005444518871027308\n",
      "train loss:0.0008463053718433755\n",
      "train loss:0.0030498573289862974\n",
      "train loss:0.0031302778920571563\n",
      "train loss:0.004251051970113212\n",
      "train loss:0.0012759470398470449\n",
      "train loss:0.0012976348463558543\n",
      "train loss:0.0038361554460069423\n",
      "train loss:0.0019069432223446617\n",
      "train loss:0.004803499114686309\n",
      "train loss:0.0005422347434028182\n",
      "train loss:0.0026424541071077483\n",
      "train loss:0.001206412952941878\n",
      "train loss:0.004821870505081586\n",
      "train loss:0.0025654467296113625\n",
      "train loss:0.0022731932288256717\n",
      "train loss:0.0029803001950530913\n",
      "train loss:0.0005155836664356522\n",
      "train loss:0.0004461775387124372\n",
      "train loss:0.003717103176584839\n",
      "train loss:0.001239742602607092\n",
      "train loss:0.001106657601636273\n",
      "train loss:0.00039673034800888915\n",
      "train loss:0.0023844300981509057\n",
      "train loss:0.00025127832998381286\n",
      "train loss:0.0010868649901104308\n",
      "train loss:0.0004081614640476078\n",
      "train loss:0.0007379662457935695\n",
      "train loss:0.0011545281952153321\n",
      "train loss:0.001438338992620379\n",
      "train loss:0.0009595238328170196\n",
      "=== epoch:15, train acc:1.0, test acc:0.972 ===\n",
      "train loss:0.0012445118055170786\n",
      "train loss:0.011862929370022873\n",
      "train loss:0.0022543854530164176\n",
      "train loss:0.005827579910290965\n",
      "train loss:0.0007606533684865194\n",
      "train loss:0.010514580985508101\n",
      "train loss:0.0027666350027867846\n",
      "train loss:0.0006248116084819869\n",
      "train loss:0.0034768278936188044\n",
      "train loss:0.003744470111141961\n",
      "train loss:0.002636526129421394\n",
      "train loss:0.0008551921738222372\n",
      "train loss:0.004640241191582746\n",
      "train loss:0.0006245559148686293\n",
      "train loss:0.0013906398984943947\n",
      "train loss:0.00369644302374193\n",
      "train loss:0.0006489905148886125\n",
      "train loss:0.0020569416229904327\n",
      "train loss:0.015169483739461658\n",
      "train loss:0.00318523786709373\n",
      "train loss:0.0018541109197976297\n",
      "train loss:0.0010604364442654765\n",
      "train loss:0.0032496990277072206\n",
      "train loss:0.0019818872814278844\n",
      "train loss:0.0003001863129754169\n",
      "train loss:0.0006245698937191882\n",
      "train loss:0.001365554173428549\n",
      "train loss:0.0013096516444740247\n",
      "train loss:0.0022723529717926126\n",
      "train loss:0.004225646774811219\n",
      "train loss:0.0016906109236387357\n",
      "train loss:0.0008146175635794146\n",
      "train loss:0.001275706851765797\n",
      "train loss:0.001281434728016344\n",
      "train loss:0.0021223311518541667\n",
      "train loss:0.002311935875302149\n",
      "train loss:0.0021271180809269365\n",
      "train loss:0.001592777366531287\n",
      "train loss:0.0008382209961945036\n",
      "train loss:0.0007210171174399646\n",
      "train loss:0.00046342774312744373\n",
      "train loss:0.000988886522925443\n",
      "train loss:0.00042741106391103607\n",
      "train loss:0.00015391746404086354\n",
      "train loss:0.0013739929383819467\n",
      "train loss:0.0008037375879917302\n",
      "train loss:0.0004954163470948437\n",
      "train loss:0.003818355324861153\n",
      "train loss:0.0005198426001811542\n",
      "train loss:0.0013321747178911395\n",
      "=== epoch:16, train acc:1.0, test acc:0.975 ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0004036267789770384\n",
      "train loss:0.00020178835118794046\n",
      "train loss:0.0008675149208067916\n",
      "train loss:0.0015120290178127658\n",
      "train loss:0.0004431329451897654\n",
      "train loss:0.0015038361878914452\n",
      "train loss:0.00041978736909106443\n",
      "train loss:0.00043659808918074646\n",
      "train loss:0.0007514469185979139\n",
      "train loss:0.00033924626620982385\n",
      "train loss:0.00041690093417623766\n",
      "train loss:0.0016565932170341177\n",
      "train loss:0.0017253622037285404\n",
      "train loss:0.00038424352597489595\n",
      "train loss:0.00023934980827554933\n",
      "train loss:5.238429229448409e-05\n",
      "train loss:0.00011479031698968315\n",
      "train loss:0.0012202819184315796\n",
      "train loss:0.0015846396428287274\n",
      "train loss:5.069187528651577e-05\n",
      "train loss:0.0003965753601690849\n",
      "train loss:0.001612077495441267\n",
      "train loss:4.6504799273295275e-05\n",
      "train loss:0.001181808112071948\n",
      "train loss:0.0025586929650616447\n",
      "train loss:0.0025637985824864514\n",
      "train loss:0.0010138513025071878\n",
      "train loss:0.0004013057764777468\n",
      "train loss:0.000466163897949281\n",
      "train loss:0.0008307036371564647\n",
      "train loss:0.0001105250811918135\n",
      "train loss:0.001443480523637968\n",
      "train loss:0.000832686968406577\n",
      "train loss:0.001506979154430828\n",
      "train loss:0.0011548393512360363\n",
      "train loss:0.00016458213599809276\n",
      "train loss:0.00045046993225844156\n",
      "train loss:0.0006742299212591535\n",
      "train loss:0.0019827944051136882\n",
      "train loss:0.00043874692967392514\n",
      "train loss:8.008653131517811e-05\n",
      "train loss:0.00015671924684087385\n",
      "train loss:0.0006013959794955231\n",
      "train loss:7.562541724232861e-05\n",
      "train loss:0.0005775942117047146\n",
      "train loss:4.6755324851193676e-05\n",
      "train loss:0.0007122942718698082\n",
      "train loss:0.0008633343944675479\n",
      "train loss:0.00010238142001523117\n",
      "train loss:0.00011576956477873548\n",
      "=== epoch:17, train acc:1.0, test acc:0.972 ===\n",
      "train loss:0.00031926685104072304\n",
      "train loss:0.0017501437047131429\n",
      "train loss:0.00029776316057558613\n",
      "train loss:0.0007742087316229962\n",
      "train loss:0.00032953945792488004\n",
      "train loss:0.003810991389908218\n",
      "train loss:0.00016693394644232585\n",
      "train loss:0.0002909514071050144\n",
      "train loss:0.00032834444351524346\n",
      "train loss:0.0002456044326017374\n",
      "train loss:0.0006634195784779737\n",
      "train loss:0.00014936178684157658\n",
      "train loss:0.0019004506035401262\n",
      "train loss:0.00015566922684454628\n",
      "train loss:0.0003756965217330984\n",
      "train loss:0.0004516920205029187\n",
      "train loss:0.000242155810356421\n",
      "train loss:0.0006001609480875324\n",
      "train loss:0.000336867237927919\n",
      "train loss:0.00019343188383430076\n",
      "train loss:0.00023958032388413477\n",
      "train loss:0.0004903441687210481\n",
      "train loss:0.00015300112882826391\n",
      "train loss:0.0007611434941357891\n",
      "train loss:0.000734199994281112\n",
      "train loss:0.0011350591927099189\n",
      "train loss:0.00012042043543656569\n",
      "train loss:0.00011209882601179588\n",
      "train loss:7.984089391491394e-05\n",
      "train loss:0.0001156881267151202\n",
      "train loss:0.00011233400552991588\n",
      "train loss:0.00027272151512814453\n",
      "train loss:0.0004023529271073414\n",
      "train loss:7.045811047153589e-05\n",
      "train loss:0.00010459505466644941\n",
      "train loss:0.0008150828948125199\n",
      "train loss:0.00042644009158455655\n",
      "train loss:0.00018625771354137066\n",
      "train loss:0.00041120480980764046\n",
      "train loss:0.00024678563160981053\n",
      "train loss:0.0003447601533249195\n",
      "train loss:7.629530850056486e-05\n",
      "train loss:0.0005591084269143962\n",
      "train loss:0.00010799578141193375\n",
      "train loss:0.0003376692555635833\n",
      "train loss:0.0001550795042182782\n",
      "train loss:0.00012052419081494266\n",
      "train loss:7.92857764718728e-05\n",
      "train loss:0.000369823451746352\n",
      "train loss:0.00017974341219605735\n",
      "=== epoch:18, train acc:1.0, test acc:0.975 ===\n",
      "train loss:5.352288508528619e-05\n",
      "train loss:0.00021914897222519763\n",
      "train loss:0.000860544842588878\n",
      "train loss:0.00034986640289909435\n",
      "train loss:0.00039573807084887285\n",
      "train loss:0.000322778229870498\n",
      "train loss:0.00019813157495313316\n",
      "train loss:0.00010388921877437883\n",
      "train loss:0.00015266107344502218\n",
      "train loss:5.854127791854027e-05\n",
      "train loss:0.00014902560207107028\n",
      "train loss:0.00023354130310196584\n",
      "train loss:0.0006079458302900912\n",
      "train loss:9.379534018992527e-05\n",
      "train loss:2.1674923373262027e-05\n",
      "train loss:0.00016285345835687098\n",
      "train loss:0.00037446256150363975\n",
      "train loss:0.00022067203862909625\n",
      "train loss:0.00026024210275051615\n",
      "train loss:5.48148440878943e-05\n",
      "train loss:0.00018133805099170778\n",
      "train loss:4.132939940666392e-05\n",
      "train loss:0.001781379725577853\n",
      "train loss:0.0004836846095897816\n",
      "train loss:0.0005280583886908545\n",
      "train loss:0.00010873895031605419\n",
      "train loss:0.00010678486370231244\n",
      "train loss:6.890127368445888e-05\n",
      "train loss:0.00018692591021473367\n",
      "train loss:3.1710876121460814e-05\n",
      "train loss:0.0002218005969424613\n",
      "train loss:0.00033839588227618263\n",
      "train loss:0.00015953265735437955\n",
      "train loss:7.337235311067826e-05\n",
      "train loss:0.00015532329819135587\n",
      "train loss:0.00022086099276356436\n",
      "train loss:0.0003690978304483059\n",
      "train loss:0.00024196679452420197\n",
      "train loss:0.00034415371403350337\n",
      "train loss:0.00019797288099761094\n",
      "train loss:0.0006846424492548721\n",
      "train loss:0.0002625186455592935\n",
      "train loss:9.018825210008453e-05\n",
      "train loss:0.00023222477206893288\n",
      "train loss:0.0001557892433424267\n",
      "train loss:0.00012388073932615063\n",
      "train loss:0.00015439774756800814\n",
      "train loss:8.91379020481715e-05\n",
      "train loss:0.00016976343264380053\n",
      "train loss:0.0001697295021483499\n",
      "=== epoch:19, train acc:1.0, test acc:0.975 ===\n",
      "train loss:9.760002350673231e-05\n",
      "train loss:8.838493734363908e-05\n",
      "train loss:7.879732173347727e-05\n",
      "train loss:4.620412423095956e-05\n",
      "train loss:5.972552170888312e-05\n",
      "train loss:0.00020635058386502417\n",
      "train loss:0.0002554591111951528\n",
      "train loss:0.00025559276436571305\n",
      "train loss:0.000169717584750252\n",
      "train loss:0.0002936974546172354\n",
      "train loss:0.000432417485393207\n",
      "train loss:0.00013381696318500184\n",
      "train loss:0.00014983818307310232\n",
      "train loss:7.147174270335203e-05\n",
      "train loss:6.530035280424251e-05\n",
      "train loss:0.00014573464963366876\n",
      "train loss:0.00023650619731149452\n",
      "train loss:0.000415797437493212\n",
      "train loss:1.5317150140208628e-05\n",
      "train loss:0.0003291453868340955\n",
      "train loss:0.00025755662751459534\n",
      "train loss:0.0005000259149488558\n",
      "train loss:7.887229535376816e-05\n",
      "train loss:0.0006889240853659989\n",
      "train loss:9.787208009232057e-05\n",
      "train loss:0.0002863383134996656\n",
      "train loss:9.232548769914586e-05\n",
      "train loss:0.0014928008281312607\n",
      "train loss:0.00012086685656121438\n",
      "train loss:0.00042398122424099744\n",
      "train loss:0.000218303952508234\n",
      "train loss:0.00019086368830791912\n",
      "train loss:0.00012573650257971956\n",
      "train loss:0.00020023339355692654\n",
      "train loss:4.9077288433336824e-05\n",
      "train loss:1.8448885722472044e-05\n",
      "train loss:0.0011114133267430765\n",
      "train loss:0.0001499278507825467\n",
      "train loss:0.0001081793700453295\n",
      "train loss:0.00023979460264772997\n",
      "train loss:7.560931879917834e-05\n",
      "train loss:8.492804396727563e-05\n",
      "train loss:6.229538652578161e-05\n",
      "train loss:0.0001213411948855369\n",
      "train loss:0.00030190974015950335\n",
      "train loss:8.585884528921241e-05\n",
      "train loss:6.915021575581412e-05\n",
      "train loss:0.00012414565577844453\n",
      "train loss:0.0001461860947427701\n",
      "train loss:0.0001219105068136947\n",
      "=== epoch:20, train acc:1.0, test acc:0.976 ===\n",
      "train loss:0.00025199113188141743\n",
      "train loss:0.00033981451241866145\n",
      "train loss:0.00020527111710046074\n",
      "train loss:0.00010142722835196401\n",
      "train loss:0.00034550000856175406\n",
      "train loss:7.235488758993343e-05\n",
      "train loss:5.2218357418430925e-05\n",
      "train loss:0.00030152090743073987\n",
      "train loss:0.00028013368360953585\n",
      "train loss:6.257429083760771e-05\n",
      "train loss:0.00017623869184260456\n",
      "train loss:6.034449223038232e-05\n",
      "train loss:0.0002153476202609586\n",
      "train loss:0.00016662917426962028\n",
      "train loss:0.00039337154652256933\n",
      "train loss:0.000996350399110479\n",
      "train loss:0.0008639286754322943\n",
      "train loss:0.00012508847333118244\n",
      "train loss:0.0001248773947733767\n",
      "train loss:0.00030701589207756096\n",
      "train loss:0.0004288874224515532\n",
      "train loss:7.045120818228149e-05\n",
      "train loss:0.00018216360760841437\n",
      "train loss:4.1269036905125156e-05\n",
      "train loss:0.0001108314062021777\n",
      "train loss:0.00012464261959763522\n",
      "train loss:0.00014202272355768147\n",
      "train loss:5.785124716616575e-05\n",
      "train loss:5.0931083944200045e-05\n",
      "train loss:0.0001893438083838794\n",
      "train loss:5.6618912924991245e-05\n",
      "train loss:0.00014551673285106737\n",
      "train loss:0.00020062147708483743\n",
      "train loss:0.00013037972420689963\n",
      "train loss:8.496328390031442e-05\n",
      "train loss:0.00014156253006638984\n",
      "train loss:0.00031652238473153663\n",
      "train loss:0.00010225878057862028\n",
      "train loss:4.6271658324851994e-05\n",
      "train loss:0.0003084823318645175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:4.9806411006708347e-05\n",
      "train loss:0.0001576733069521963\n",
      "train loss:0.00022058439406632462\n",
      "train loss:0.00014120341472162565\n",
      "train loss:0.0002436222374346879\n",
      "train loss:3.784329438335683e-05\n",
      "train loss:0.00017779323041792878\n",
      "train loss:6.521348397316048e-05\n",
      "train loss:0.00010377945688497908\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.972\n"
     ]
    }
   ],
   "source": [
    "network5 = TestConvNet5()\n",
    "trainer5 = Trainer(network5, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr':0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "\n",
    "trainer5.train()\n",
    "network5.save_params(\"params/test_convnet5_params.pkl\")\n",
    "with open(\"trainer5.pkl\", 'wb') as f:\n",
    "    pickle.dump(trainer5, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ebdfed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_accuracy_history(trainer):\n",
    "    # 그래프 그리기\n",
    "    markers = {'train': 'o', 'test': 's'}\n",
    "    x = np.arange(max_epochs)\n",
    "    plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "    plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def show_loss_history(trainer):\n",
    "    plt.plot(trainer.train_loss_list)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeea1edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoJklEQVR4nO3deZxcZZ3v8c+vqvclvXdWIAEjiwoJRMQBFEWF4AL4chxU1MG5ExlhLt47IOE6Cs7cuRMHdRyuLDJeFAYVHVlHgiCCOA5CSCDsYEJISHfS+95dvVU/949zOqmuVHWqO32qmjrf94t61amz1PPrk+L5ne15HnPOISIi4RXJdQAiIpJbSgQiIiGnRCAiEnJKBCIiIadEICISckoEIiIhF1giMLNbzKzNzF5Is9zM7Doz225mz5nZiUHFIiIi6QV5RvAj4Oxplq8FVvqvdcCNAcYiIiJpBJYInHO/A7qmWeVc4DbneQKoNrPFQcUjIiKpFeSw7KXA7oTPTf68vckrmtk6vLMGysvLTzrmmGOyEmC+6Bkao6VvmLH4BIXRCIsWlFBdVpjV8pt7hphIaMRuwKKqEipLCvEatzscMNnQ3eHw/0s9D2+Bv+kB8xLnt/ePMJGiBX3EjMqSApwD52834Zz/2StvYnKZ/13edmBmGGDmfY8ZGDb1sz+vNzaWsnwDSgqjTDhHfMIrK9V6QYmYsaS6hKJohMJohMKCCDbL73IORsbjjIxPMDI+wej4xL7P8Yns/U35rqGimEVVJbPadsuWLR3OuYZUy3KZCFL95lL+YpxzNwM3A6xZs8Zt3rw5yLjyyj3PNHPVXc9TPxbfN6+wMMrffvwdnLd66ZyWNRafoLk7xq6uId7oHOSNriF2dQ7xyCttLExTGfTPaQT7WcL7wmnWO7K+nKKCiPeKRlJOFxf4FWU0QnzC7avoRuMTjI7HE6YnK0Dv85g/r7VvJG35731rAxUlBVQWF1BRXEBFifdeWVJARXHhlM9lRVEmJmA0Ht8fQ1LZo/H9FfFk+f/4wCtpy48DMf8VMVi0oIRlNWUsrSllaXUpS2tKWeZPL6oqoaN/lB0dA7zeMciO9kFe7/BezT2xfd8ZAZYvKGFFfTlHNpTzy+f20BsbP6DsRQuKufuSU6f515kb51//X7Sk+Dd4M5ZfXlzAgpLZHcSZ2a50y3KZCJqAwxI+LwP25CiWvOScY8MDrxBLSAIAsbE4V9/3AoOj45QWRr1XkfdeVlRAaVGE0qKCfctKCiOYeVVr//AYuzqH9lXyb3QN8UbXILs6h9jTE5ty1F9cEOHw2jLGpzki/JcLVlEQiRCNQDThvSBiRMwoiPrvESOaZl40cVnEiESmLnvvtY+yp2f4gLKXVpfyyOVnzMm+ns6pGx6ZUlEmln/rF04OvPzb/rArZflLqkr4yV+eQlN3jOaeIZq7YzR1x2jqibHp9S5a+oanPZqvLCngyIYKTl5Ru6/SX1FfzvK6csqL91ct71xey1V3PT/ld1haGGX92mNZXFU6t39sCuvXHhvq8jORy0RwH3Cpmd0BvAvodc4dcFlIDs45x97eYba1DbC9bYDtbf1sax1ge/sAPUNjKbfpjY3z1btTPtCVUmlhlIKI0T8y9ciutryIw2vLOPHwGs5fvZTDa8s4oq6cw2vLaKwsJhKxaSvCc1fN7VlJKl8565iU/yNecdbRgZcNcMVZR8/L8r9y9jEsry9neX15yu3G4xO09A3T3B2juSfG3t5hGiqKWeFX+HXlRfsOEKZz3sNncF60DaJJCx5uhNXbDuVPy0jYy89EYInAzH4KnAHUm1kTcDVQCOCcuwnYCJwDbAeGgIuCiiVfxCccTd1DbG8bYFvbwL7K/rW2AQYSKuiaskJWNlZyzjsWc3+a0/LFVSXce8mpDI3GiY3FGRqNM+y/x8bixEbHiY3GiY1NeNNjccbijkVVJRxRW8ZhtWUcUVdGZQanqbmuCCcvgV374Kvs6YmxpLqUK846es4vjeVb+QXRCMtqylhWU3ZoAQy2zWz+XJvP5cfHYGIcJuLeu5tImI4nLIt7n0troXK6i52zY2+2bqjDdI8gNhrnmd3dPLmji02vd/HM7m6Gxyb2LW+sLGblwgpWNlZyVGMFK/1XXUXxvnUm7xEkV8L/GMA9grSuXZn6f4byRrhifhwR5bVc7/9rqtIve+96GBuEsZj3Gp2cHvJfifNiEC2EwjIoLIWiMn968nO5954871frD1L+0NQyR4emlr9vXsyrqGdqbHDm26Rz6pfhg9+Y1aZmtsU5tybVslxeGpIkAyPjbNnVzZM7Otn0ehfPNvUwFneYwXGLF3DBOw/n2MWVvKWxkrc0VlBVevCj8Zyfljo3/RFRx3aIRCBSABb13iNR75X42SbnzeK5lkOpCOPjMNwLwz0w0gfFC6CsDkqqMo8l1xVxto+I42PQ+iI0PQVNBzloe2wDFJSmrshLqmHBkqkVe3zMr5wH9yeJ4V7o35uQOIa85ZlU2o9tgIKS/WUU+eUUlnvlVy6eGpfN4on7P3wv/bL3/23S777AKyNSkHpe/VtnXn4GlAiy4J5nmlOelvfGxnjq9S427eziyR2dvLCnj/iEIxox3r60ii+cuoJ3HVnLSUfUZlTppzRdJTDYub/SnVIRT/Njn5iAWDcMdcBgBwx1+tOdCfP8+ZPzpvO9k2b29xRVQHFliteCFMsWeO/T7YPf/7P398R6vMp+ynSPV/mnEinwEkJZPZRPvtcnfE6YN135O3/vlRPrTlF+99Rlw31ehVBQDNGiA99TzSsoTl32pNFBr6I7FL3NfqX/FDRvgT3PwLh/c768cfptv949/e9ttpyD+KiXHL65PPvlJ5ouEbznimDLzpAuDQUs1aWZaMRYWFnM3r5hnIOiaIQTDqviXSvqOHlFLScdUTPlqYt9Rocg1pV5xRHrhu6dsws81RE6eEdf6Y60Jo+WkyvE//qX9OV8/Afpr4cmXzuNj3kV10gfjPTvf40O+NP+/JmevkeLoLTGOwIsrU4/XVzpfX+qZDc5b7h3ZmUns4hfXs2B5ZdUeX/b+CjER2B8xKvsUr6PePtrfAS6Xpu+zJIqWLDUO/pdsMSbnvK+2IvBzNv/e7b6lf5m74i/f+/+/bh4FSxb472WroHqw+Eb1enLvuYQ91cmprs0FYbyfbo0lEOn3/snvBztOeDSTPtwFT858zecvKKW1YdXU1IY9Y62B1qhZRN0vQ7dr3sV+eT0UGf6gizqVxbVXuVRVgd1b5k+Eaz9p6TKNr6/Ik7+7OJeJVRak3D0m1Dpl9WmP/qcLhEc/6fpl82Gc95R4L5E0Qf/+v706/+vvd5p/2wuOaUSH4OhrqnJ4RdfSL/+5+5NqOxrvGQzV7FMmq4iOvNq6NvjVeZ9zdD6Agy0cUCTnsIy79+6t9n7LQDUrIDlp8Gyd3qV/qK3p/4NlDemvzSWDWEvPwNKBAFxzvHk612cQk/K5Q3Wy2WVj8C2nfBkQqU/nvC8u0Wgapn3P9yxH/WOrsrqp1b4k9PpKpDn/z19kO/64mz/vPnLzLvUUVQOlYsOvn7RIT4Rkyxa6D3Vkfhkx3SJ4Mgz5rb8mTr9fx44Lz4G/S1eguhr3p8o+lvg+BVepb9sjZcYMpHrBwLCXn4GlAjmmHOOR19t4/pHX2PLrm52Ttca/IGveEdaNSu8o/e3fABqlkPtCm9e1WFQUJSt0IPzJjgiymsz3f/RQqg+zHtJKCgRzJH4hOP+5/dyw6PbeaWln6XVpfzdR4+BX0+z0d/8ESoa5/5SQKL5UAnn+ogo1/sg1+Xnev/LvKdEcIhGxuPc9XQz33/sNXZ2DnFUQznf+sTxnFf5EgWPfG76jQNoGHIAVQK53we5Ll/kIJQIZmlwZJyfbnqDf/3PHbT2jfCOpVXcdOGJfKh6L5GH/wp2/qd3mUdEZJ5TIpihnqFRbn18Fz98/HV6hsY45chavvWnJ3BabT/26FfhhTu9p2nO/ias+QL889tyf2lGRGQaSgQZGo9PcO1Dr3L7H3YxOBrnA8c28ldnvIWT6uPw2D/B5lu8Z+5PvxxOvQxKFngb6rKAiMxzSgQZevjlVr7/2A7Oecci/vuZKzmmNgpP3AA//hevOfvqz8IZV3mNb0RE3kSUCDLU1O11o/x/zj2W6ld+BrdvgIEWOPrD8IGroSE7PWmKiMw1JYIMtfYNc07h01T96Bro+CMsOxk+eSscfkquQxMROSRKBBkqb9nEDdFvgVsJf3Y7HPORYJ//FxHJEiWCDFX2vOpN/PkvM+u6QETkTSLg/lfzR/FwK3GieuxTRPKOEkEGnHNUjLQxUNQQfN/lIiJZplotA72xMRpcF8OlOhsQkfyjRJCB1r4RFlkX8XK1ERCR/KNEkIGW3hiLrItIdZYGexcRySI9NZSBrs4Oym2EsdpluQ5FRGTO6YwgA4MduwEor9dAHSKSf5QIMjDa0wxAYY3OCEQk/ygRZMD6vERApW4Wi0j+USLIQMFgizehRCAieUiJIAOlI20MRqugcLqR6EVE3pyUCA5iLD5BzVg7gyVqTCYi+UmJ4CDa+0dYaN2MlamjORHJT0oEB9HSN8xC69L9ARHJW0oEB9He00eD9VGgR0dFJE8pERxEf5vXmKxMjclEJE8pERxErMtrQ1Bep0QgIvlJieAgJnq9RBCpUodzIpKflAgOItq/15tYoJvFIpKfAk0EZna2mb1qZtvNbH2K5VVm9h9m9qyZvWhmFwUZz2wUxVoZtWIoqc51KCIigQgsEZhZFLgeWAscB3zKzI5LWu0S4CXn3AnAGcC3zawoqJhmo2K0jf6iBjDLdSgiIoEI8ozgZGC7c26Hc24UuAM4N2kdB1SamQEVQBcwHmBMMzIwMk6962K4VI3JRCR/BZkIlgK7Ez43+fMSfQ84FtgDPA9c5pybSP4iM1tnZpvNbHN7e3tQ8R6gpXeYxXQxUaFEICL5K8hEkOpaikv6fBawFVgCrAK+Z2YLDtjIuZudc2ucc2saGhrmOs60WntjNFo3kaolWStTRCTbgkwETUDiw/fL8I78E10E3OU824HXgWMCjGlGujv2UmzjFNeqDYGI5K8gE8FTwEozW+HfAL4AuC9pnTeAMwHMbCFwNLAjwJhmZKjjDQAqG5QIRCR/BTZ4vXNu3MwuBR4EosAtzrkXzexif/lNwN8DPzKz5/EuJV3pnOsIKqaZGuv2GpPpjEBE8llgiQDAObcR2Jg076aE6T3Ah4KM4VC4Pv9KlnoeFZE8ppbF0ygaamGCCFQszHUoIiKBUSKYRtlwG/0FtRAN9MRJRCSnlAjSiE84Fox3MFSsISpFJL8pEaTROTjCQroYLVdjMhHJb0oEabT2jrDYumCBGpOJSH5TIkijrauLBTZEUbXGIRCR/KZEkEZ/u9eYTENUiki+UyJIY7TL6y+vouHwHEciIhIsJYI04j1eY7KohqgUkTynRJBGZEBDVIpIOCgRpFESa2MwUgFF5bkORUQkUEoEaVSOtjJQlL2xD0REckWJIIXhsTi1E52MlKqPIRHJf0oEKbT0DrPIuolX6P6AiOQ/JYIUWnsGaKBHTwyJSCgoEaTQ095E1BzFtctyHYqISOCUCFIY6vAak1U2qlWxiOQ/JYIUxv3GZKV1SgQikv+UCFLp88YqtgW6RyAi+U+JIIXCwRbGKISyulyHIiISOCWCFEpH2ugrrAOzXIciIhI4JYIkzjmqx9oZKlZjMhEJByWCJN1DYzTSxZiGqBSRkFAiSNLSE2ORdavXUREJDSWCJJ0drZTaKIU1akwmIuGgRJBkYHKISrUhEJGQUCJIMtzdBMCCRg1RKSLhoESQZKLXa1WsS0MiEhZKBEmik0NUVuipIREJByWCJMVDrfRGqqGgKNehiIhkhRJBksrRdgaKGnMdhohI1igRJBgZj1M30cFImVoVi0h4KBEkaO8fYaF1aYhKEQkVJYIEbV291NoA0aoluQ5FRCRrAk0EZna2mb1qZtvNbH2adc4ws61m9qKZPRZkPAfT0+aNTFaixmQiEiIFQX2xmUWB64EPAk3AU2Z2n3PupYR1qoEbgLOdc2+YWU7v0sY6vFbFFQ1qTCYi4RHkGcHJwHbn3A7n3ChwB3Bu0jqfBu5yzr0B4JxrCzCegxrv8UYmq2zQGYGIhEeQiWApsDvhc5M/L9FbgRoz+62ZbTGzz6X6IjNbZ2abzWxze3t7QOGC6/NaFdsC3SMQkfAIMhGkGt7LJX0uAE4CPgycBXzNzN56wEbO3eycW+OcW9PQ0DD3kfqKBluIWSkULwisDBGR+SajRGBmd5rZh81sJomjCUi8xrIM2JNinV855wadcx3A74ATZlDGnCobaaO3oF5DVIpIqGRasd+Idz1/m5ltMLNjMtjmKWClma0wsyLgAuC+pHXuBU43swIzKwPeBbycYUxzyjlH1XgHsRK1KhaRcMkoETjnHnbOfQY4EdgJ/NrMHjezi8ysMM0248ClwIN4lfvPnXMvmtnFZnaxv87LwK+A54BNwA+ccy8c6h81G33D4zTQxVi5GpOJSLhk/PiomdUBFwKfBZ4BfgycBnweOCPVNs65jcDGpHk3JX2+Frh2JkEHoa13iOV087qGqBSRkMkoEZjZXcAxwL8BH3XO+X018zMz2xxUcNnU2dbMSotTVJ38YJOISH7L9Izge865R1ItcM6tmcN4cqa/zR+isl5tCEQkXDK9WXys3woYADOrMbMvBRNSbox2eU0eqhYuz20gIiJZlmki+EvnXM/kB+dcN/CXgUSUIxN93tWu4loNUSki4ZJpIoiY7X+43u9HKK+G8IoM7CVOBMqDa7AmIjIfZZoIHgR+bmZnmtn7gZ/iPfaZN0pjrfRE6yASzXUoIiJZlenN4iuBLwJ/hdd1xEPAD4IKKhcqRtsYKGmkLteBiIhkWUaJwDk3gde6+MZgw8mN8fgEtfFORkozaTAtIpJfMm1HsBL4R+A4oGRyvnPuyIDiyqqOgVEWWjfNlYtyHYqISNZleo/gh3hnA+PA+4Db8BqX5YW2jnYqLUa0Sk8MiUj4ZJoISp1zvwHMObfLOXcN8P7gwsquPr8xmR4dFZEwyvRm8bDfBfU2M7sUaAbyppvOWKfXmKyyUa2KRSR8Mj0j+DJQBvx3vIFkLsTrbC4vjHU1AVDVuDy3gYiI5MBBzwj8xmOfdM5dAQwAFwUeVbb1e62KI1XqeVREwuegZwTOuThwUmLL4nxTNNRCn1VCYWmuQxERybpM7xE8A9xrZv8ODE7OdM7dFUhUWVY20kZfYQMaqVhEwijTRFALdDL1SSEH5EUiqB5rJ1alNgQiEk6ZtizOv/sCvsERb4jK9vITch2KiEhOZNqy+Id4ZwBTOOe+MOcRZVlrdx/L6aOjckmuQxERyYlMLw39MmG6BDgf2DP34WRfd+tujjRHYY0ak4lIOGV6aejOxM9m9lPg4UAiyrLBDq8xmYaoFJGwyrRBWbKVwOFzGUiuDPuNyaoXHZHjSEREciPTewT9TL1H0II3RsGb3kSvd4WrrE5nBCISTpleGqoMOpBciQ7sYYQiiktrch2KiEhOZHRpyMzON7OqhM/VZnZeYFFlUUmsje5oHeRvw2kRkWlleo/gaudc7+QH51wPcHUgEWVZ5Wg7g8V505GqiMiMZZoIUq2X6aOn89bEhKN2ooPhUrUqFpHwyjQRbDaz75jZUWZ2pJn9M7AlyMCyoWtwhIV0M1GhRCAi4ZVpIvhrYBT4GfBzIAZcElRQ2dLetpdiG6OgemmuQxERyZlMnxoaBNYHHEvW9bXuBKBYj46KSIhl+tTQr82sOuFzjZk9GFhUWTLU6TUmW9CYF23jRERmJdNLQ/X+k0IAOOe6yYMxi8d7mgGoUiIQkRDLNBFMmNm+2tLMlpOiN9I3G+vbywRGoYaoFJEQy/QR0K8Cvzezx/zP7wHWBRNS9hQOtdBtNdRFC3MdiohIzmR0RuCc+xWwBngV78mhv8F7cuhNrXykjb7C+lyHISKSU5neLP5vwG/wEsDfAP8GXJPBdmeb2atmtt3M0j51ZGbvNLO4mX0is7DnRtV4O7GShdksUkRk3sn0HsFlwDuBXc659wGrgfbpNjCzKHA9sBY4DviUmR2XZr1vAll9Cml4LE6j62S8XI3JRCTcMk0Ew865YQAzK3bOvQIcfZBtTga2O+d2OOdGgTuAc1Os99fAnUBbhrHMifbObqpsCKo0RKWIhFumiaDJb0dwD/BrM7uXgw9VuRTYnfgd/rx9zGwp3rCXN033RWa2zsw2m9nm9vZpT0Qy1t22C4Ciag1RKSLhlmnL4vP9yWvM7FGgCvjVQTZL1a9z8iOn3wWudM7FbZpuoJ1zNwM3A6xZs2ZOHlsdaPNyVLmGqBSRkJtxD6LOuccOvhbgnQEk1rLLOPAsYg1wh58E6oFzzGzcOXfPTOOaqdEuLxFUL9QQlSISbkF2Jf0UsNLMVgDNwAXApxNXcM6tmJw2sx8Bv8xGEgCY6PNyUkWjzghEJNwCSwTOuXEzuxTvaaAocItz7kUzu9hfPu19gaBFBloYoIyK4rwdhVNEJCOBDi7jnNsIbEyalzIBOOf+PMhYkpXGWuguqKcim4WKiMxDmT41lHcqx9oZLHrT95snInLIQpkInHPUxjsZKVOrYhGRUCaC3sEYDXQzUaFeR0VEQpkIOlp2EzVHVENUioiEMxH0+Y3JSurUqlhEJJSJINbpJYIFDRqZTEQklIlgrNsbq7hm8fLcBiIiMg+EMhFY/17GKKC4Uo+PioiEMhEUDbXSZbUQCeWfLyIyRShrwvKRVnqLGnIdhojIvBDKRFA13qEhKkVEfKFLBGPjcRpcl4aoFBHxhS4RdHS0U2Yj2AINUSkiAiFMBN2tOwEoqlWrYhERCGEiGGx7A9AQlSIik0KXCEa6mwGoatQQlSIiEMJE4Hq9RFDdqO4lREQghIkgOthCNwuIFJXkOhQRkXkhdImgJNZKd0F9rsMQEZk3QpcINESliMhUoUsEdfEORsrUmExEZFKoEkH/wAC11o+r1BCVIiKTQpUIOlu8NgTRKrUqFhGZFKpE0N+2C4CSOj06KiIyKVSJYKjDH6JSbQhERPYJVSIY9xuT1S5Wq2IRkUmhSgSRvj0MUUxZZW2uQxERmTdClQgKh1rpjNSDWa5DERGZN0KVCMpH2ugvVKtiEZFEoUoE1eMdDGmIShGRKUKTCOLxOPUaolJE5AAFuQ4gcNeuhME2okDU4JQ9t8E1t0F5I1yxLdfRiYjkXP6fEQy2zWy+iEjI5H8iEBGRaQWaCMzsbDN71cy2m9n6FMs/Y2bP+a/HzeyEIOMREZEDBZYIzCwKXA+sBY4DPmVmxyWt9jrwXufc8cDfAzcHFY+IiKQW5BnBycB259wO59wocAdwbuIKzrnHnXPd/scngGUBxiMiIikEmQiWArsTPjf589L5C+CBVAvMbJ2ZbTazze3t7TOLojzNaGTp5ouIhEyQj4+m6sfBpVzR7H14ieC0VMudczfjXzZas2ZNyu9IS4+IiohMK8hE0AQclvB5GbAneSUzOx74AbDWOdcZYDwiIpJCkJeGngJWmtkKMysCLgDuS1zBzA4H7gI+65z7Y4CxiIhIGoGdETjnxs3sUuBBIArc4px70cwu9pffBHwdqANuMK9H0HHn3JqgYhIRkQOZczO75J5ra9ascZs3b851GCIibypmtiXdgXb+9zUkIgKMjY3R1NTE8PBwrkMJVElJCcuWLaOwsDDjbZQIRCQUmpqaqKysZPny5VieDk7lnKOzs5OmpiZWrFiR8Xbqa0hEQmF4eJi6urq8TQIAZkZdXd2Mz3qUCEQkNPI5CUyazd+oRCAiEnJKBCIiKdzzTDOnbniEFevv59QNj3DPM82H9H09PT3ccMMNM97unHPOoaen55DKPhglAhGRJPc808xVdz1Pc08MBzT3xLjqrucPKRmkSwTxeHza7TZu3Eh1dfWsy82EnhoSkdD5xn+8yEt7+tIuf+aNHkbjE1PmxcbifOUXz/HTTW+k3Oa4JQu4+qNvS/ud69ev57XXXmPVqlUUFhZSUVHB4sWL2bp1Ky+99BLnnXceu3fvZnh4mMsuu4x169YBsHz5cjZv3szAwABr167ltNNO4/HHH2fp0qXce++9lJaWzmIPTKUzAhGRJMlJ4GDzM7FhwwaOOuootm7dyrXXXsumTZv4h3/4B1566SUAbrnlFrZs2cLmzZu57rrr6Ow8sOu1bdu2cckll/Diiy9SXV3NnXfeOet4EumMQERCZ7ojd4BTNzxCc0/sgPlLq0v52RffPScxnHzyyVOe9b/uuuu4++67Adi9ezfbtm2jrq5uyjYrVqxg1apVAJx00kns3LlzTmLRGYGISJIrzjqa0sLolHmlhVGuOOvoOSujvLx83/Rvf/tbHn74Yf7whz/w7LPPsnr16pRtAYqLi/dNR6NRxsfH5yQWnRGIiCQ5b7U3hta1D77Knp4YS6pLueKso/fNn43Kykr6+/tTLuvt7aWmpoaysjJeeeUVnnjiiVmXMxtKBCIiKZy3eukhVfzJ6urqOPXUU3n7299OaWkpCxcu3Lfs7LPP5qabbuL444/n6KOP5pRTTpmzcjOh3kdFJBRefvlljj322FyHkRWp/tbpeh/VPQIRkZBTIhARCTklAhGRkFMiEBEJOSUCEZGQUyIQEQk5tSMQEUl27UoYbDtwfnkjXLFtVl/Z09PDT37yE770pS/NeNvvfve7rFu3jrKyslmVfTA6IxARSZYqCUw3PwOzHY8AvEQwNDQ067IPRmcEIhI+D6yHludnt+0PP5x6/qJ3wNoNaTdL7Ib6gx/8II2Njfz85z9nZGSE888/n2984xsMDg7yyU9+kqamJuLxOF/72tdobW1lz549vO9976O+vp5HH310dnFPQ4lARCQLNmzYwAsvvMDWrVt56KGH+MUvfsGmTZtwzvGxj32M3/3ud7S3t7NkyRLuv/9+wOuDqKqqiu985zs8+uij1NfXBxKbEoGIhM80R+4AXFOVftlF9x9y8Q899BAPPfQQq1evBmBgYIBt27Zx+umnc/nll3PllVfykY98hNNPP/2Qy8qEEoGISJY557jqqqv44he/eMCyLVu2sHHjRq666io+9KEP8fWvfz3weHSzWEQkWXnjzOZnILEb6rPOOotbbrmFgYEBAJqbm2lra2PPnj2UlZVx4YUXcvnll/P0008fsG0QdEYgIpJslo+ITiexG+q1a9fy6U9/mne/2xvtrKKigttvv53t27dzxRVXEIlEKCws5MYbbwRg3bp1rF27lsWLFwdys1jdUItIKKgbanVDLSIiaSgRiIiEnBKBiITGm+1S+GzM5m9UIhCRUCgpKaGzszOvk4Fzjs7OTkpKSma0nZ4aEpFQWLZsGU1NTbS3t+c6lECVlJSwbNmyGW2jRCAioVBYWMiKFStyHca8FOilITM728xeNbPtZrY+xXIzs+v85c+Z2YlBxiMiIgcKLBGYWRS4HlgLHAd8ysyOS1ptLbDSf60DbgwqHhERSS3IM4KTge3OuR3OuVHgDuDcpHXOBW5znieAajNbHGBMIiKSJMh7BEuB3Qmfm4B3ZbDOUmBv4kpmtg7vjAFgwMxenWVM9UDHLLfNhvkeH8z/GBXfoVF8h2Y+x3dEugVBJgJLMS/5ua1M1sE5dzNw8yEHZLY5XRPr+WC+xwfzP0bFd2gU36GZ7/GlE+SloSbgsITPy4A9s1hHREQCFGQieApYaWYrzKwIuAC4L2md+4DP+U8PnQL0Ouf2Jn+RiIgEJ7BLQ865cTO7FHgQiAK3OOdeNLOL/eU3ARuBc4DtwBBwUVDx+A758lLA5nt8MP9jVHyHRvEdmvkeX0pvum6oRURkbqmvIRGRkFMiEBEJubxMBPO5awszO8zMHjWzl83sRTO7LMU6Z5hZr5lt9V/Bj149tfydZva8X/YBw8HleP8dnbBftppZn5l9OWmdrO8/M7vFzNrM7IWEebVm9msz2+a/16TZdtrfa4DxXWtmr/j/hnebWXWabaf9PQQY3zVm1pzw73hOmm1ztf9+lhDbTjPbmmbbwPffIXPO5dUL78b0a8CRQBHwLHBc0jrnAA/gtWM4BXgyi/EtBk70pyuBP6aI7wzglznchzuB+mmW52z/pfi3bgGOyPX+A94DnAi8kDDvn4D1/vR64Jtp/oZpf68BxvchoMCf/maq+DL5PQQY3zXA5Rn8BnKy/5KWfxv4eq7236G+8vGMYF53beGc2+uce9qf7gdexmtN/WYyX7oGORN4zTm3KwdlT+Gc+x3QlTT7XOBWf/pW4LwUm2byew0kPufcQ865cf/jE3jteHIizf7LRM723yQzM+CTwE/nutxsycdEkK7bipmuEzgzWw6sBp5MsfjdZvasmT1gZm/LbmQ44CEz2+J375FsXuw/vLYp6f7ny+X+m7TQ+e1i/PfGFOvMl335BbyzvFQO9nsI0qX+patb0lxamw/773Sg1Tm3Lc3yXO6/jORjIpizri2CZGYVwJ3Al51zfUmLn8a73HEC8H+Be7IZG3Cqc+5EvN5hLzGz9yQtnw/7rwj4GPDvKRbnev/NxHzYl18FxoEfp1nlYL+HoNwIHAWswut/7Nsp1sn5/gM+xfRnA7nafxnLx0Qw77u2MLNCvCTwY+fcXcnLnXN9zrkBf3ojUGhm9dmKzzm3x39vA+7GO/1ONB+6BlkLPO2ca01ekOv9l6B18pKZ/96WYp1c/xY/D3wE+IzzL2gny+D3EAjnXKtzLu6cmwD+NU25ud5/BcDHgZ+lWydX+28m8jERzOuuLfzrif8PeNk595006yzy18PMTsb7d+rMUnzlZlY5OY13Q/GFpNXmQ9cgaY/Ccrn/ktwHfN6f/jxwb4p1Mvm9BsLMzgauBD7mnBtKs04mv4eg4ku873R+mnJztv98HwBecc41pVqYy/03I7m+Wx3EC++plj/iPU3wVX/excDF/rThDZrzGvA8sCaLsZ2Gd+r6HLDVf52TFN+lwIt4T0A8AfxJFuM70i/3WT+GebX//PLL8Cr2qoR5Od1/eElpLzCGd5T6F0Ad8Btgm/9e66+7BNg43e81S/Ftx7u+Pvk7vCk5vnS/hyzF92/+7+s5vMp98Xzaf/78H03+7hLWzfr+O9SXupgQEQm5fLw0JCIiM6BEICISckoEIiIhp0QgIhJySgQiIiGnRCASMPN6Q/1lruMQSUeJQEQk5JQIRHxmdqGZbfL7jf++mUXNbMDMvm1mT5vZb8yswV93lZk9kdCXf40//y1m9rDf4d3TZnaU//UVZvYL8/r//3FCy+cNZvaS/z3fytGfLiGnRCACmNmxwJ/hdRC2CogDnwHK8fo0OhF4DLja3+Q24Ern3PF4rV8n5/8YuN55Hd79CV5rVPB6mf0ycBxea9NTzawWr+uEt/nf87+D/BtF0lEiEPGcCZwEPOWPNHUmXoU9wf4OxW4HTjOzKqDaOfeYP/9W4D1+nzJLnXN3Azjnht3+Pnw2OeeanNeB2lZgOdAHDAM/MLOPAyn7+xEJmhKBiMeAW51zq/zX0c65a1KsN12fLKm6RJ40kjAdxxsZbByvJ8o78Qat+dXMQhaZG0oEIp7fAJ8ws0bYN97wEXj/j3zCX+fTwO+dc71At5md7s//LPCY88aVaDKz8/zvKDazsnQF+mNSVDmvq+wv4/W7L5J1BbkOQGQ+cM69ZGZ/izeSVASvl8lLgEHgbWa2BejFu48AXrfSN/kV/Q7gIn/+Z4Hvm9nf+d/xp9MUWwnca2YleGcT/2OO/yyRjKj3UZFpmNmAc64i13GIBEmXhkREQk5nBCIiIaczAhGRkFMiEBEJOSUCEZGQUyIQEQk5JQIRkZD7/wVLgjTbkmzaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for trainer in [trainer1, trainer2, trainer3, trainer4, trainer5]:\n",
    "    show_accuracy_history(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "821cc045",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for trainer in [trainer1, trainer2, trainer3, trainer4, trainer5]:\n",
    "    show_loss_history(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfedcbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
